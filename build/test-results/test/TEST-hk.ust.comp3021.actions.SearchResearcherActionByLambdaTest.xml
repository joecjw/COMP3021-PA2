<?xml version="1.0" encoding="UTF-8"?>
<testsuite name="hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest" tests="4" skipped="0" failures="1" errors="0" timestamp="2023-03-28T15:56:42" hostname="DESKTOP-MMB9NP2" time="0.358">
  <properties/>
  <testcase name="testSearchResearcherAction_ActionsSize()" classname="hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest" time="0.081"/>
  <testcase name="testSearchResearcherAction_SearchByKeywordSimilarity()" classname="hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest" time="0.245">
    <failure message="org.opentest4j.AssertionFailedError: expected: &lt;105&gt; but was: &lt;5&gt;" type="org.opentest4j.AssertionFailedError">org.opentest4j.AssertionFailedError: expected: &lt;105&gt; but was: &lt;5&gt;
	at app//org.junit.jupiter.api.AssertionFailureBuilder.build(AssertionFailureBuilder.java:151)
	at app//org.junit.jupiter.api.AssertionFailureBuilder.buildAndThrow(AssertionFailureBuilder.java:132)
	at app//org.junit.jupiter.api.AssertEquals.failNotEqual(AssertEquals.java:197)
	at app//org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:150)
	at app//org.junit.jupiter.api.AssertEquals.assertEquals(AssertEquals.java:145)
	at app//org.junit.jupiter.api.Assertions.assertEquals(Assertions.java:527)
	at app//hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest.testSearchResearcherAction_SearchByKeywordSimilarity(SearchResearcherActionByLambdaTest.java:91)
	at java.base@18.0.1.1/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base@18.0.1.1/java.lang.reflect.Method.invoke(Method.java:577)
	at app//org.junit.platform.commons.util.ReflectionUtils.invokeMethod(ReflectionUtils.java:727)
	at app//org.junit.jupiter.engine.execution.MethodInvocation.proceed(MethodInvocation.java:60)
	at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain$ValidatingInvocation.proceed(InvocationInterceptorChain.java:131)
	at app//org.junit.jupiter.engine.extension.SameThreadTimeoutInvocation.proceed(SameThreadTimeoutInvocation.java:45)
	at app//org.junit.jupiter.engine.extension.TimeoutExtension.intercept(TimeoutExtension.java:156)
	at app//org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestableMethod(TimeoutExtension.java:147)
	at app//org.junit.jupiter.engine.extension.TimeoutExtension.interceptTestMethod(TimeoutExtension.java:86)
	at app//org.junit.jupiter.engine.execution.InterceptingExecutableInvoker$ReflectiveInterceptorCall.lambda$ofVoidMethod$0(InterceptingExecutableInvoker.java:103)
	at app//org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.lambda$invoke$0(InterceptingExecutableInvoker.java:93)
	at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain$InterceptedInvocation.proceed(InvocationInterceptorChain.java:106)
	at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.proceed(InvocationInterceptorChain.java:64)
	at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.chainAndInvoke(InvocationInterceptorChain.java:45)
	at app//org.junit.jupiter.engine.execution.InvocationInterceptorChain.invoke(InvocationInterceptorChain.java:37)
	at app//org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:92)
	at app//org.junit.jupiter.engine.execution.InterceptingExecutableInvoker.invoke(InterceptingExecutableInvoker.java:86)
	at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.lambda$invokeTestMethod$7(TestMethodTestDescriptor.java:217)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.invokeTestMethod(TestMethodTestDescriptor.java:213)
	at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:138)
	at app//org.junit.jupiter.engine.descriptor.TestMethodTestDescriptor.execute(TestMethodTestDescriptor.java:68)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:151)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base@18.0.1.1/java.util.ArrayList.forEach(ArrayList.java:1511)
	at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at java.base@18.0.1.1/java.util.ArrayList.forEach(ArrayList.java:1511)
	at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.invokeAll(SameThreadHierarchicalTestExecutorService.java:41)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$6(NodeTestTask.java:155)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$8(NodeTestTask.java:141)
	at app//org.junit.platform.engine.support.hierarchical.Node.around(Node.java:137)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.lambda$executeRecursively$9(NodeTestTask.java:139)
	at app//org.junit.platform.engine.support.hierarchical.ThrowableCollector.execute(ThrowableCollector.java:73)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.executeRecursively(NodeTestTask.java:138)
	at app//org.junit.platform.engine.support.hierarchical.NodeTestTask.execute(NodeTestTask.java:95)
	at app//org.junit.platform.engine.support.hierarchical.SameThreadHierarchicalTestExecutorService.submit(SameThreadHierarchicalTestExecutorService.java:35)
	at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestExecutor.execute(HierarchicalTestExecutor.java:57)
	at app//org.junit.platform.engine.support.hierarchical.HierarchicalTestEngine.execute(HierarchicalTestEngine.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:107)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:88)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.lambda$execute$0(EngineExecutionOrchestrator.java:54)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.withInterceptedStreams(EngineExecutionOrchestrator.java:67)
	at org.junit.platform.launcher.core.EngineExecutionOrchestrator.execute(EngineExecutionOrchestrator.java:52)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:114)
	at org.junit.platform.launcher.core.DefaultLauncher.execute(DefaultLauncher.java:86)
	at org.junit.platform.launcher.core.DefaultLauncherSession$DelegatingLauncher.execute(DefaultLauncherSession.java:86)
	at org.junit.platform.launcher.core.SessionPerRequestLauncher.execute(SessionPerRequestLauncher.java:53)
	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.processAllTestClasses(JUnitPlatformTestClassProcessor.java:99)
	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor$CollectAllTestClassesExecutor.access$000(JUnitPlatformTestClassProcessor.java:79)
	at org.gradle.api.internal.tasks.testing.junitplatform.JUnitPlatformTestClassProcessor.stop(JUnitPlatformTestClassProcessor.java:75)
	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61)
	at java.base@18.0.1.1/jdk.internal.reflect.DirectMethodHandleAccessor.invoke(DirectMethodHandleAccessor.java:104)
	at java.base@18.0.1.1/java.lang.reflect.Method.invoke(Method.java:577)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36)
	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)
	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33)
	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94)
	at jdk.proxy1/jdk.proxy1.$Proxy2.stop(Unknown Source)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker$3.run(TestWorker.java:193)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.executeAndMaintainThreadName(TestWorker.java:129)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:100)
	at org.gradle.api.internal.tasks.testing.worker.TestWorker.execute(TestWorker.java:60)
	at org.gradle.process.internal.worker.child.ActionExecutionWorker.execute(ActionExecutionWorker.java:56)
	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:133)
	at org.gradle.process.internal.worker.child.SystemApplicationClassLoaderWorker.call(SystemApplicationClassLoaderWorker.java:71)
	at app//worker.org.gradle.process.internal.worker.GradleWorkerMain.run(GradleWorkerMain.java:69)
	at app//worker.org.gradle.process.internal.worker.GradleWorkerMain.main(GradleWorkerMain.java:74)
</failure>
  </testcase>
  <testcase name="testSearchResearcherAction_SearchByPaperWithinYear()" classname="hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest" time="0.008"/>
  <testcase name="testSearchResearcherAction_SearchByJournalPublishTimes()" classname="hk.ust.comp3021.actions.SearchResearcherActionByLambdaTest" time="0.02"/>
  <system-out><![CDATA[Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Guilherme Ottoni : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Guilherme Ottoni after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Guilherme Ottoni: C++CompilationDynamic languagesPHP
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Davin Tjong : [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Davin Tjong after removed: [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Davin Tjong: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Darko Stefanovic : [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Darko Stefanovic after removed: [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Darko Stefanovic: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Edmund Clarke : [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Edmund Clarke after removed: [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Edmund Clarke: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of James C. Browne : [@article{Sharygina2003,
   author = {Natasha Sharygina and James C. Browne},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Model checking software via abstraction of loop transitions},
   year = {2003},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of James C. Browne after removed: [@article{Sharygina2003,
   author = {Natasha Sharygina and James C. Browne},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Model checking software via abstraction of loop transitions},
   year = {2003},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of James C. Browne: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Diomidis Spinellis : [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Diomidis Spinellis after removed: [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Diomidis Spinellis: GradleJVM-based buildsMakeincremental buildsparallel builds
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stanislaw Jarzabek : [@article{Jarzabek2007,
   author = {Stanislaw Jarzabek},
   doi = {10.1201/9781420013115.ch2},
   journal = {Effective Software Maintenance and Evolution},
   title = {Static Program Analysis Methods},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stanislaw Jarzabek after removed: [@article{Jarzabek2007,
   author = {Stanislaw Jarzabek},
   doi = {10.1201/9781420013115.ch2},
   journal = {Effective Software Maintenance and Evolution},
   title = {Static Program Analysis Methods},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Stanislaw Jarzabek: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of P. Deloo : [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of P. Deloo after removed: [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of P. Deloo: abstract interpretationautomatic program verificationprogram logic
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Adrian Francalanza : [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Adrian Francalanza after removed: [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Adrian Francalanza: Heap SnapshotsProgram AnalysisScalability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Michael B. James : [@article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Michael B. James after removed: [@article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Michael B. James: Human-Computer InteractionProgram SynthesisType Inference
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shadaj Laddad : [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shadaj Laddad after removed: [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shadaj Laddad: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yijun Yu : [@article{Yu2012,
   author = {Yijun Yu},
   title = {Faster Compilation through Lighter Precompilation},
   year = {2012},
}
, @article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
, @article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yijun Yu after removed: [@article{Yu2012,
   author = {Yijun Yu},
   title = {Faster Compilation through Lighter Precompilation},
   year = {2012},
}
, @article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
, @article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Yijun Yu: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Enea Zaffanella : [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Enea Zaffanella after removed: [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Enea Zaffanella: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Neil Mitchell : [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Neil Mitchell after removed: [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Neil Mitchell: build systemsfunctional programming
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Tarlow : [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Tarlow after removed: [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Daniel Tarlow: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zheng Guo : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zheng Guo after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Zheng Guo: Abstract InterpretationProgram SynthesisType SystemsHuman-Computer InteractionProgram SynthesisType Inference
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Kai Tang : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Kai Tang after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Kai Tang: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Martin Pinzger : [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Martin Pinzger after removed: [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Martin Pinzger: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Samuel Z. Guyer : [@article{Guyer1999,
   abstract = {This paper introduces an annotation language and a compiler that together\ncan customize a library implementation for specific application needs.\nOur approach is distinguished by its ability to exploit high level,\ndomain-specific information in the customization process. In particular,\nthe annotations provide semantic information that enables our compiler\nto analyze and optimize library operations as if they were primitives\nof a domain-specific language. Thus, our approach yields many of\nthe performance benefits of domain-specific languages, without the\neffort of developing a new compiler for each domain.\n\nThis paper presents the annotation language, describes its role in\noptimization, and illustrates the benefits of the overall approach.\nUsing a partially implemented compiler, we show how our system can\nsignificantly improve the performance of two applications written\nusing the PLAPACK parallel linear algebra library.},
   author = {Samuel Z. Guyer and Calvin Lin},
   doi = {10.1145/331960.331970},
   journal = {Proceedings of the 2nd Conference on Domain-Specific Languages, DSL 1999},
   title = {An annotation language for optimizing software libraries},
   year = {1999},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Samuel Z. Guyer after removed: [@article{Guyer1999,
   abstract = {This paper introduces an annotation language and a compiler that together\ncan customize a library implementation for specific application needs.\nOur approach is distinguished by its ability to exploit high level,\ndomain-specific information in the customization process. In particular,\nthe annotations provide semantic information that enables our compiler\nto analyze and optimize library operations as if they were primitives\nof a domain-specific language. Thus, our approach yields many of\nthe performance benefits of domain-specific languages, without the\neffort of developing a new compiler for each domain.\n\nThis paper presents the annotation language, describes its role in\noptimization, and illustrates the benefits of the overall approach.\nUsing a partially implemented compiler, we show how our system can\nsignificantly improve the performance of two applications written\nusing the PLAPACK parallel linear algebra library.},
   author = {Samuel Z. Guyer and Calvin Lin},
   doi = {10.1145/331960.331970},
   journal = {Proceedings of the 2nd Conference on Domain-Specific Languages, DSL 1999},
   title = {An annotation language for optimizing software libraries},
   year = {1999},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Samuel Z. Guyer: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Christian Dietrich : [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Christian Dietrich after removed: [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Christian Dietrich: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Charles Zhang : [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Charles Zhang after removed: [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Charles Zhang: SMT solvingSparse analysispath sensitivityprogram dependence graph
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Martin Schaf : [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Martin Schaf after removed: [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Martin Schaf: Ami snipingAutovalueBuilder patternLightweight verificationLombokPluggable type systems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zhe Long Wang : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zhe Long Wang after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Zhe Long Wang: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zoltán Porkoláb : [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Zoltán Porkoláb after removed: [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Zoltán Porkoláb: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Igor Bogudlov : [@article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Igor Bogudlov after removed: [@article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Igor Bogudlov: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Valentin Rothberg : [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Valentin Rothberg after removed: [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Valentin Rothberg: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of P. Pellegrino : [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of P. Pellegrino after removed: [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of P. Pellegrino: abstract interpretationautomatic program verificationprogram logic
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Junwen Yang : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Junwen Yang after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Junwen Yang: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of M. Sagiv : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of M. Sagiv after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of M. Sagiv: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Peter O'Hearn : [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Peter O'Hearn after removed: [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Peter O'Hearn: Formal verificationLivenessProgram analysisSoftware model checkingTermination
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of George C. Necula : [@article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of George C. Necula after removed: [@article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of George C. Necula: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Peisen Yao : [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Peisen Yao after removed: [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Peisen Yao: SMT solvingSparse analysispath sensitivityprogram dependence graph
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hannah Arndt : [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hannah Arndt after removed: [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Hannah Arndt: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniele Cono D'elia : [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniele Cono D'elia after removed: [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Daniele Cono D'elia: Concolic executionSoftware testingStatic analysisSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Wei Ngan Chin : [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Wei Ngan Chin after removed: [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Wei Ngan Chin: AbstractionCombining analysisFixpoint analysisLoop invariantNumerical analysisSeparation logicShape analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Agostino Cortesi : [@article{Cortesi2008,
   abstract = {Interpretation, one of the most applied techniques for semantics based static analysis of software, is based on two main key-concepts: the correspondence between concrete and abstract semantics through Galois connections/insertions, and the feasibility of a fixed point computation of the abstract semantics, through the fast convergence of widening operators. The latter point is crucial to ensure the scalability of the analysis to large software systems. In this paper, we investigate which properties are necessary to support a systematic design of widening operators, by discussing and comparing different definitions in the literature, and by proposing various ways to combine them. In particular, we prove that, for Galois insertions, widening is preserved by abstraction, and we show how widening operators can be combined for the cartesian and reduced product of abstract domains.},
   author = {Agostino Cortesi},
   doi = {10.1109/SEFM.2008.20},
   journal = {Proceedings - 6th IEEE International Conference on Software Engineering and Formal Methods, SEFM 2008},
   keywords = {Abstract domains,Abstract interpretation,Static analysis,Widening operators},
   title = {Widening operators for abstract interpretation},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Agostino Cortesi after removed: [@article{Cortesi2008,
   abstract = {Interpretation, one of the most applied techniques for semantics based static analysis of software, is based on two main key-concepts: the correspondence between concrete and abstract semantics through Galois connections/insertions, and the feasibility of a fixed point computation of the abstract semantics, through the fast convergence of widening operators. The latter point is crucial to ensure the scalability of the analysis to large software systems. In this paper, we investigate which properties are necessary to support a systematic design of widening operators, by discussing and comparing different definitions in the literature, and by proposing various ways to combine them. In particular, we prove that, for Galois insertions, widening is preserved by abstraction, and we show how widening operators can be combined for the cartesian and reduced product of abstract domains.},
   author = {Agostino Cortesi},
   doi = {10.1109/SEFM.2008.20},
   journal = {Proceedings - 6th IEEE International Conference on Software Engineering and Formal Methods, SEFM 2008},
   keywords = {Abstract domains,Abstract interpretation,Static analysis,Widening operators},
   title = {Widening operators for abstract interpretation},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Agostino Cortesi: Abstract domainsAbstract interpretationStatic analysisWidening operators
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Craig Chambers : [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Craig Chambers after removed: [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Craig Chambers: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Baldoni : [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Baldoni after removed: [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Roberto Baldoni: Concolic executionSoftware testingStatic analysisSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of George Balatsouras : [@article{Smaragdakis2015,
   abstract = {During the past twenty-one years, over seventy-five papers and nine Ph.D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder, “Haven'trdquo; we solved this problem yet?''  With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.},
   author = {Yannis Smaragdakis and George Balatsouras},
   doi = {10.1561/2500000014},
   journal = {Foundations and Trends® in Programming Languages},
   title = {Pointer Analysis},
   year = {2015},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of George Balatsouras after removed: [@article{Smaragdakis2015,
   abstract = {During the past twenty-one years, over seventy-five papers and nine Ph.D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder, “Haven'trdquo; we solved this problem yet?''  With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.},
   author = {Yannis Smaragdakis and George Balatsouras},
   doi = {10.1561/2500000014},
   journal = {Foundations and Trends® in Programming Languages},
   title = {Pointer Analysis},
   year = {2015},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of George Balatsouras: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Isil Dillig : [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
, @article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Isil Dillig after removed: [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
, @article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Isil Dillig: Component-based synthesisData preparationProgram synthesisProgramming by exampleSMT-based deductionArray analysisHeap analysisMemory invariantsRelational static analysisStatic analysisdecomposition of multi-phase loopsinvariant generation
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Patrice Godefroid : [@article{Godefroid2011,
   abstract = {Whitebox fuzzing extends dynamic test generation based on sym- bolic execution and constraint solving from unit testing to whole- application security testing. Unfortunately, input-dependent loops may cause an explosion in the number of constraints to be solved and in the number of execution paths to be explored. In practice, whitebox fuzzers arbitrarily bound the number of constraints and paths due to input-dependent loops, at the risk of missing code and bugs. In thiswork, we investigate the use of simple loop-guard pattern- matching rules to automatically guess an input constraint defining the number of iterations of input-dependent loops during dynamic symbolic execution. We discover the loop structure of the program on the fly, detect induction variables, which are variables modified by a constant value during loop iterations, and infer simple partial loop invariants relating the value of such variables. Whenever a guess is confirmed later during the current dynamic symbolic ex- ecution, we then inject new constraints representing pre and post loop conditions, effectively summarizing sets of executions of that loop. These pre and post conditions are derived from partial loop invariants synthesized dynamically using pattern-matching rules on the loop guards and induction variables,without requiring any static analysis, theoremproving, or input-format specification. This tech- nique has been implemented in the whitebox fuzzer SAGE, scales to large programs with many nested loops, and we present results of experiments with aWindows 7 image parser},
   author = {Patrice Godefroid and Daniel Luchaup},
   doi = {10.1145/2001420.2001424},
   journal = {2011 International Symposium on Software Testing and Analysis, ISSTA 2011 - Proceedings},
   keywords = {loop invariant generation,program summarization,program testing and verification},
   title = {Automatic partial loop summarization in dynamic test generation},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Patrice Godefroid after removed: [@article{Godefroid2011,
   abstract = {Whitebox fuzzing extends dynamic test generation based on sym- bolic execution and constraint solving from unit testing to whole- application security testing. Unfortunately, input-dependent loops may cause an explosion in the number of constraints to be solved and in the number of execution paths to be explored. In practice, whitebox fuzzers arbitrarily bound the number of constraints and paths due to input-dependent loops, at the risk of missing code and bugs. In thiswork, we investigate the use of simple loop-guard pattern- matching rules to automatically guess an input constraint defining the number of iterations of input-dependent loops during dynamic symbolic execution. We discover the loop structure of the program on the fly, detect induction variables, which are variables modified by a constant value during loop iterations, and infer simple partial loop invariants relating the value of such variables. Whenever a guess is confirmed later during the current dynamic symbolic ex- ecution, we then inject new constraints representing pre and post loop conditions, effectively summarizing sets of executions of that loop. These pre and post conditions are derived from partial loop invariants synthesized dynamically using pattern-matching rules on the loop guards and induction variables,without requiring any static analysis, theoremproving, or input-format specification. This tech- nique has been implemented in the whitebox fuzzer SAGE, scales to large programs with many nested loops, and we present results of experiments with aWindows 7 image parser},
   author = {Patrice Godefroid and Daniel Luchaup},
   doi = {10.1145/2001420.2001424},
   journal = {2011 International Symposium on Software Testing and Analysis, ISSTA 2011 - Proceedings},
   keywords = {loop invariant generation,program summarization,program testing and verification},
   title = {Automatic partial loop summarization in dynamic test generation},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Patrice Godefroid: loop invariant generationprogram summarizationprogram testing and verification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Wies : [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Wies after removed: [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thomas Wies: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John Field : [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John Field after removed: [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of John Field: Abstract interpretationModel checkingPredicate abstractionSoftware componentsStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Franjo Ivančić : [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Franjo Ivančić after removed: [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Franjo Ivančić: Abstract interpretationLoop refinementModel checkingPath-sensitive analysisProgram understandingProgram verificationStatic analysisSynchronous sytems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Noll : [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
, @article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Noll after removed: [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
, @article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thomas Noll: Dynamic data structuresHyperedge replacement grammarsJava bytecodeVerification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bor Yuh Evan Chang : [@article{Chang2008,
   abstract = {Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion. Copyright © 2008 ACM.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/1328438.1328469},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {heap analysis,inductive definitions,materialization,separation logic,shape analysis,symbolic abstract domain},
   title = {Relational inductive shape analysis},
   year = {2008},
}
, @article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
, @article{Chang2013,
   abstract = {The aim of static analysis is to infer invariants about programs that are precise enough to establish semantic properties, such as the absence of run-time errors. Broadly speaking, there are two major branches of static analysis for imperative programs. Pointer and shape analyses focus on inferring properties of pointers, dynamically-allocated memory, and recursive data structures, while numeric analyses seek to derive invariants on numeric values. Although simultaneous inference of shapenumeric invariants is often needed, this case is especially challenging and is not particularly well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. In this paper, we study the construction of such shape-numeric, static analyzers. We set up an abstract interpretation framework that allows us to reason about simultaneous shape-numeric properties by combining shape and numeric abstractions into a modular, expressive abstract domain. Such a modular structure is highly desirable to make its formalization and implementation easier to do and get correct. To achieve this, we choose a concrete semantics that can be abstracted step-by-step, while preserving a high level of expressiveness. The structure of abstract operations (i.e., transfer, join, and comparison) follows the structure of this semantics. The advantage of this construction is to divide the analyzer in modules and functors that implement abstractions of distinct features. © B.-Y. E. Chang and X. Rival.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.4204/EPTCS.129.11},
   journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
   title = {Modular construction of shape-numeric analyzers},
   year = {2013},
}
, @article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
, @article{Rival2010,
   abstract = {Interprocedural program analysis is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, particularly in the presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records. We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack-much like how shape analyzers enable a fluid per program point abstraction of the heap. Copyright © 2011 ACM.},
   author = {Xavier Rival and Bor Yuh Evan Chang},
   doi = {10.1145/1926385.1926406},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Calling context,Context-sensitivity,Inductive definitions,Interprocedural analysis,Separation logic,Shape analysis,Symbolic abstract domain},
   title = {Calling context abstraction with shapes},
   year = {2010},
}
, @article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bor Yuh Evan Chang after removed: [@article{Chang2008,
   abstract = {Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion. Copyright © 2008 ACM.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/1328438.1328469},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {heap analysis,inductive definitions,materialization,separation logic,shape analysis,symbolic abstract domain},
   title = {Relational inductive shape analysis},
   year = {2008},
}
, @article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
, @article{Chang2013,
   abstract = {The aim of static analysis is to infer invariants about programs that are precise enough to establish semantic properties, such as the absence of run-time errors. Broadly speaking, there are two major branches of static analysis for imperative programs. Pointer and shape analyses focus on inferring properties of pointers, dynamically-allocated memory, and recursive data structures, while numeric analyses seek to derive invariants on numeric values. Although simultaneous inference of shapenumeric invariants is often needed, this case is especially challenging and is not particularly well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. In this paper, we study the construction of such shape-numeric, static analyzers. We set up an abstract interpretation framework that allows us to reason about simultaneous shape-numeric properties by combining shape and numeric abstractions into a modular, expressive abstract domain. Such a modular structure is highly desirable to make its formalization and implementation easier to do and get correct. To achieve this, we choose a concrete semantics that can be abstracted step-by-step, while preserving a high level of expressiveness. The structure of abstract operations (i.e., transfer, join, and comparison) follows the structure of this semantics. The advantage of this construction is to divide the analyzer in modules and functors that implement abstractions of distinct features. © B.-Y. E. Chang and X. Rival.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.4204/EPTCS.129.11},
   journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
   title = {Modular construction of shape-numeric analyzers},
   year = {2013},
}
, @article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
, @article{Rival2010,
   abstract = {Interprocedural program analysis is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, particularly in the presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records. We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack-much like how shape analyzers enable a fluid per program point abstraction of the heap. Copyright © 2011 ACM.},
   author = {Xavier Rival and Bor Yuh Evan Chang},
   doi = {10.1145/1926385.1926406},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Calling context,Context-sensitivity,Inductive definitions,Interprocedural analysis,Separation logic,Shape analysis,Symbolic abstract domain},
   title = {Calling context abstraction with shapes},
   year = {2010},
}
, @article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Bor Yuh Evan Chang: heap analysisinductive definitionsmaterializationseparation logicshape analysissymbolic abstract domainAbstract interpretationClumping of disjunctsDisjunctionsHeap abstractionSeparation logicsSilhouetteStatic analysisCalling contextContext-sensitivityInductive definitionsInterprocedural analysisSeparation logicShape analysisSymbolic abstract domain
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Aarti Gupta : [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Aarti Gupta after removed: [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Aarti Gupta: Abstract interpretationLoop refinementModel checkingPath-sensitive analysisProgram understandingProgram verificationStatic analysisSynchronous sytems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Riccardo Casero : [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Riccardo Casero after removed: [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Riccardo Casero: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Justo : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Justo after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of David Justo: Abstract InterpretationProgram SynthesisType Systems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ilya Sergey : [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ilya Sergey after removed: [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Ilya Sergey: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thodoris Sotiropoulos : [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thodoris Sotiropoulos after removed: [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thodoris Sotiropoulos: GradleJVM-based buildsMakeincremental buildsparallel builds
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Homayoun Dayani-Fard : [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Homayoun Dayani-Fard after removed: [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Homayoun Dayani-Fard: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Liang Zou : [@article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Liang Zou after removed: [@article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Liang Zou: Disjunctive loop summarypath dependency automatonpath interleavingLoop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Chenglong Wang : [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Chenglong Wang after removed: [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Chenglong Wang: Program SynthesisQuery by ExampleSQL
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yannis Smaragdakis : [@article{Smaragdakis2015,
   abstract = {During the past twenty-one years, over seventy-five papers and nine Ph.D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder, “Haven'trdquo; we solved this problem yet?''  With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.},
   author = {Yannis Smaragdakis and George Balatsouras},
   doi = {10.1561/2500000014},
   journal = {Foundations and Trends® in Programming Languages},
   title = {Pointer Analysis},
   year = {2015},
}
, @article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yannis Smaragdakis after removed: [@article{Smaragdakis2015,
   abstract = {During the past twenty-one years, over seventy-five papers and nine Ph.D. theses have been published on pointer analysis. Given the tomes of work on this topic one may wonder, “Haven'trdquo; we solved this problem yet?''  With input from many researchers in the field, this paper describes issues related to pointer analysis and remaining open problems.},
   author = {Yannis Smaragdakis and George Balatsouras},
   doi = {10.1561/2500000014},
   journal = {Foundations and Trends® in Programming Languages},
   title = {Pointer Analysis},
   year = {2015},
}
, @article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Yannis Smaragdakis: Heap SnapshotsProgram AnalysisScalability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of T. Reps : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of T. Reps after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of T. Reps: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E T Communications : [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E T Communications after removed: [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of E T Communications: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Deepak Goyal : [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Deepak Goyal after removed: [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Deepak Goyal: Abstract interpretationModel checkingPredicate abstractionSoftware componentsStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bihuan Chen : [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bihuan Chen after removed: [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Bihuan Chen: Disjunctive SummaryLoop SummarizationDisjunctive loop summarypath dependency automatonpath interleavingLoop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ludwig Füracker : [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ludwig Füracker after removed: [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Ludwig Füracker: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Huisong Li : [@article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Huisong Li after removed: [@article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Huisong Li: Abstract interpretationClumping of disjunctsDisjunctionsHeap abstractionSeparation logicsSilhouetteStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Emmanuel Geay : [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Emmanuel Geay after removed: [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Emmanuel Geay: alias analysisprogram verificationtypestate
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Rajeev Alur : [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Rajeev Alur after removed: [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Rajeev Alur: Domain-specific languagesStatistical methodsSynthesisTransfer learning
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of J. Kreiker : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of J. Kreiker after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of J. Kreiker: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dan Quinlan : [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dan Quinlan after removed: [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Dan Quinlan: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Axel Simon : [@article{Simon2006,
   abstract = {The abstract domain of polyhedra is sufficiently expressive to be deployed in verification. One consequence of the richness of this domain is that long, possibly infinite, sequences of polyhedra can arise in the analysis of loops. Widening and narrowing have been proposed to infer a single polyhedron that summarises such a sequence of polyhedra. Motivated by precision losses encountered in verification, we explain how the classic widening/narrowing approach can be refined by an improved extrapolation strategy. The insight is to record inequalities that are thus far found to be unsatisfiable in the analysis of a loop. These so-called landmarks hint at the amount of widening necessary to reach stability. This extrapolation strategy, which refines widening with thresholds, can infer post-fixpoints that are precise enough not to require narrowing. Un- like previous techniques, our approach interacts well with other domains, is fully automatic, conceptually simple and precise on complex loops.},
   author = {Axel Simon and Andy King},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Widening polyhedra with landmarks},
   year = {2006},
}
, @article{Simon2004,
   abstract = {Suppose $<A_i, \vec\{c\},
   author = {Axel Simon and Andy King},
   doi = {10.1080/00207160310001650034},
   journal = {International Journal of Computer Mathematics},
   keywords = {Computational geometry,Convex hull},
   title = {Convex hull of planar H-polyhedra},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Axel Simon after removed: [@article{Simon2006,
   abstract = {The abstract domain of polyhedra is sufficiently expressive to be deployed in verification. One consequence of the richness of this domain is that long, possibly infinite, sequences of polyhedra can arise in the analysis of loops. Widening and narrowing have been proposed to infer a single polyhedron that summarises such a sequence of polyhedra. Motivated by precision losses encountered in verification, we explain how the classic widening/narrowing approach can be refined by an improved extrapolation strategy. The insight is to record inequalities that are thus far found to be unsatisfiable in the analysis of a loop. These so-called landmarks hint at the amount of widening necessary to reach stability. This extrapolation strategy, which refines widening with thresholds, can infer post-fixpoints that are precise enough not to require narrowing. Un- like previous techniques, our approach interacts well with other domains, is fully automatic, conceptually simple and precise on complex loops.},
   author = {Axel Simon and Andy King},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Widening polyhedra with landmarks},
   year = {2006},
}
, @article{Simon2004,
   abstract = {Suppose $<A_i, \vec\{c\},
   author = {Axel Simon and Andy King},
   doi = {10.1080/00207160310001650034},
   journal = {International Journal of Computer Mathematics},
   keywords = {Computational geometry,Convex hull},
   title = {Convex hull of planar H-polyhedra},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Axel Simon: Computational geometryConvex hull
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Camil Demetrescu : [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Camil Demetrescu after removed: [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Camil Demetrescu: Concolic executionSoftware testingStatic analysisSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shan Lu : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shan Lu after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shan Lu: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Michael James : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Michael James after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Michael James: Abstract InterpretationProgram SynthesisType Systems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Eric Goubault : [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
, @article{Goubault2011,
   abstract = {We define several abstract semantics for the static analysis of finite precision computations, that bound not only the ranges of values taken by numerical variables of a program, but also the difference with the result of the same sequence of operations in an idealized real number semantics. These domains point out with more or less detail (control point, block, function for instance) sources of numerical errors in the program and the way they were propagated by further computations, thus allowing to evaluate not only the rounding error, but also sensitivity to inputs or parameters of the program. We describe two classes of abstractions, a non relational one based on intervals, and a weakly relational one based on parametrized zonotopic abstract domains called affine sets, especially well suited for sensitivity analysis and test generation. These abstract domains are implemented in the Fluctuat static analyzer, and we finally present some experiments. ? 2011 Springer-Verlag.},
   author = {Eric Goubault and Sylvie Putot},
   doi = {10.1007/978-3-642-18275-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static analysis of finite precision computations},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Eric Goubault after removed: [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
, @article{Goubault2011,
   abstract = {We define several abstract semantics for the static analysis of finite precision computations, that bound not only the ranges of values taken by numerical variables of a program, but also the difference with the result of the same sequence of operations in an idealized real number semantics. These domains point out with more or less detail (control point, block, function for instance) sources of numerical errors in the program and the way they were propagated by further computations, thus allowing to evaluate not only the rounding error, but also sensitivity to inputs or parameters of the program. We describe two classes of abstractions, a non relational one based on intervals, and a weakly relational one based on parametrized zonotopic abstract domains called affine sets, especially well suited for sensitivity analysis and test generation. These abstract domains are implemented in the Fluctuat static analyzer, and we finally present some experiments. ? 2011 Springer-Verlag.},
   author = {Eric Goubault and Sylvie Putot},
   doi = {10.1007/978-3-642-18275-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static analysis of finite precision computations},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Eric Goubault: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lin Xu : [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lin Xu after removed: [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Lin Xu: D213 [Software Engineering]: Reusable Software-Reuse ModelsD26 [Software Engineer-ing]: Programming Environments-Integrated EnvironmentsI22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation Languages Keywords reuse program synthesis mining *
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of François Bourdoncle : [@article{Bourdoncle1993,
   abstract = {Abstract interpretation is a formal method that enables the static and automatic determination of run-time properties of programs. This method uses a characterization of program invariants as least and greatest fixed points of continuous functions over complete lattices of program properties. In this paper, we study precise and efficient chaotic iteration strategies for computing such fixed points when lattices are of infinite height and speedup techniques, known as widening and narrowing, have to be used. These strategies are based on a weak topological ordering of the dependency graph of the system of semantic equations associated with the program and minimize the loss in precision due to the use of widening operators. We discuss complexity and implementation issues and give precise upper bounds on the complexity of the intraprocedural and interprocedural abstract interpretation of higher-order programs based on the structure of their control flow graph.},
   author = {François Bourdoncle},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient chaotic iteration strategies with widenings},
   year = {1993},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of François Bourdoncle after removed: [@article{Bourdoncle1993,
   abstract = {Abstract interpretation is a formal method that enables the static and automatic determination of run-time properties of programs. This method uses a characterization of program invariants as least and greatest fixed points of continuous functions over complete lattices of program properties. In this paper, we study precise and efficient chaotic iteration strategies for computing such fixed points when lattices are of infinite height and speedup techniques, known as widening and narrowing, have to be used. These strategies are based on a weak topological ordering of the dependency graph of the system of semantic equations associated with the program and minimize the loss in precision due to the use of widening operators. We discuss complexity and implementation issues and give precise upper bounds on the complexity of the intraprocedural and interprocedural abstract interpretation of higher-order programs based on the structure of their control flow graph.},
   author = {François Bourdoncle},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient chaotic iteration strategies with widenings},
   year = {1993},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of François Bourdoncle: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stefanos Chaliasos : [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stefanos Chaliasos after removed: [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Stefanos Chaliasos: GradleJVM-based buildsMakeincremental buildsparallel builds
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lindsay Groves : [@article{Friggens2015,
   abstract = {Canonical abstraction is a static analysis technique that represents states as 3-valued logical structures, and produces finite abstract systems. Despite providing a finite bound, these abstractions may still suffer from the state explosion problem. Notably, for concurrent programs with arbitrary interleaving, if threads in a state are abstracted based on their location, then the number of locations will be a combinatorial factor in the size of the statespace. We present an approach using canonical abstraction that avoids this state explosion by "collapsing" all of the threads in a state into a single abstract representative. Properties of threads that would be lost by the abstraction, but are needed for verification, are retained by defining conditional "soft invariant" instrumentation predicates. This technique is used to adapt previous models for verifying linearizability of nonblocking concurrent data structure algorithms, resulting in exponentially smaller statespaces.},
   author = {David Friggens and Lindsay Groves},
   title = {Collapsing Threads Safely with Soft Invariants},
   year = {2015},
   url = {http://arxiv.org/abs/1512.09186},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lindsay Groves after removed: [@article{Friggens2015,
   abstract = {Canonical abstraction is a static analysis technique that represents states as 3-valued logical structures, and produces finite abstract systems. Despite providing a finite bound, these abstractions may still suffer from the state explosion problem. Notably, for concurrent programs with arbitrary interleaving, if threads in a state are abstracted based on their location, then the number of locations will be a combinatorial factor in the size of the statespace. We present an approach using canonical abstraction that avoids this state explosion by "collapsing" all of the threads in a state into a single abstract representative. Properties of threads that would be lost by the abstraction, but are needed for verification, are retained by defining conditional "soft invariant" instrumentation predicates. This technique is used to adapt previous models for verifying linearizability of nonblocking concurrent data structure algorithms, resulting in exponentially smaller statespaces.},
   author = {David Friggens and Lindsay Groves},
   title = {Collapsing Threads Safely with Soft Invariants},
   year = {2015},
   url = {http://arxiv.org/abs/1512.09186},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Lindsay Groves: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stephen J. Fink : [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Stephen J. Fink after removed: [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Stephen J. Fink: alias analysisprogram verificationtypestate
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cristiano Calcagno : [@article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cristiano Calcagno after removed: [@article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Cristiano Calcagno: a program analysis iscompo-languagesor programpartsprogramreliabilityresult of a compositesimilarlysitional if the analysisthe meanings of itstheoryverification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of G. C. Gannod : [@article{Gannod2001,
   abstract = {A modularization is a partitioning of a software system into components based on a variety of criteria, each depending on the clustering approach and desired level of abstraction. Source-header dependency graphs are bipartite graphs that are formed by flattening include file dependencies and enumerating source file to header file dependencies. In this paper, we describe an approach for identifying candidate modularizations of software systems by analyzing connectivity properties of source-header dependency graphs. In addition, we apply the approach to a large software system to demonstrate its applicability.},
   author = {G. C. Gannod and B. D. Gannod},
   journal = {Reverse Engineering - Working Conference Proceedings},
   title = {An investigation into the connectivity properties of source-header dependency graphs},
   year = {2001},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of G. C. Gannod after removed: [@article{Gannod2001,
   abstract = {A modularization is a partitioning of a software system into components based on a variety of criteria, each depending on the clustering approach and desired level of abstraction. Source-header dependency graphs are bipartite graphs that are formed by flattening include file dependencies and enumerating source file to header file dependencies. In this paper, we describe an approach for identifying candidate modularizations of software systems by analyzing connectivity properties of source-header dependency graphs. In addition, we apply the approach to a large software system to demonstrate its applicability.},
   author = {G. C. Gannod and B. D. Gannod},
   journal = {Reverse Engineering - Working Conference Proceedings},
   title = {An investigation into the connectivity properties of source-header dependency graphs},
   year = {2001},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of G. C. Gannod: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roman Manevich : [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roman Manevich after removed: [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Roman Manevich: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Antoine Toubhans : [@article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Antoine Toubhans after removed: [@article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Antoine Toubhans: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Bagnara : [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Bagnara after removed: [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Roberto Bagnara: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Tara Krishnaswamy : [@article{Krishnaswamy2000,
   abstract = {This paper describes the crucial design and implementation issues that arise in building a fully automatic precompiled header mechanism for compiling industrial-strength C and C++ applications. The key challenges include designing the Makefile-transparent automation, determining the precompile-able region, capturing the compile environment and verifying it and addressing the correctness issues involved in using precompiled headers. The ensuing discussion treats the internals of the actual dumping and loading of precompiled headers as a black-box beyond a brief high-level description. An automatic precompiled header mechanism has been implemented in aCC, the HP ANSI C++ compiler, and the results of compiling real applications show that it achieves significant speedup in compile-times of real applications.},
   author = {Tara Krishnaswamy},
   journal = {Proceedings of the 1st Conference on Industrial Experiences with Systems Software, WIESS 2000},
   title = {Automatic precompiled headers: Speeding up C++ application build times},
   year = {2000},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Tara Krishnaswamy after removed: [@article{Krishnaswamy2000,
   abstract = {This paper describes the crucial design and implementation issues that arise in building a fully automatic precompiled header mechanism for compiling industrial-strength C and C++ applications. The key challenges include designing the Makefile-transparent automation, determining the precompile-able region, capturing the compile environment and verifying it and addressing the correctness issues involved in using precompiled headers. The ensuing discussion treats the internals of the actual dumping and loading of precompiled headers as a black-box beyond a brief high-level description. An automatic precompiled header mechanism has been implemented in aCC, the HP ANSI C++ compiler, and the results of compiling real applications show that it achieves significant speedup in compile-times of real applications.},
   author = {Tara Krishnaswamy},
   journal = {Proceedings of the 1st Conference on Industrial Experiences with Systems Software, WIESS 2000},
   title = {Automatic precompiled headers: Speeding up C++ application build times},
   year = {2000},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Tara Krishnaswamy: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Santanu Kumar Dash : [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Santanu Kumar Dash after removed: [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Santanu Kumar Dash: Information-theoretic ClusteringType Reinement
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joost-Pieter Katoen : [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joost-Pieter Katoen after removed: [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Joost-Pieter Katoen: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Luchaup : [@article{Godefroid2011,
   abstract = {Whitebox fuzzing extends dynamic test generation based on sym- bolic execution and constraint solving from unit testing to whole- application security testing. Unfortunately, input-dependent loops may cause an explosion in the number of constraints to be solved and in the number of execution paths to be explored. In practice, whitebox fuzzers arbitrarily bound the number of constraints and paths due to input-dependent loops, at the risk of missing code and bugs. In thiswork, we investigate the use of simple loop-guard pattern- matching rules to automatically guess an input constraint defining the number of iterations of input-dependent loops during dynamic symbolic execution. We discover the loop structure of the program on the fly, detect induction variables, which are variables modified by a constant value during loop iterations, and infer simple partial loop invariants relating the value of such variables. Whenever a guess is confirmed later during the current dynamic symbolic ex- ecution, we then inject new constraints representing pre and post loop conditions, effectively summarizing sets of executions of that loop. These pre and post conditions are derived from partial loop invariants synthesized dynamically using pattern-matching rules on the loop guards and induction variables,without requiring any static analysis, theoremproving, or input-format specification. This tech- nique has been implemented in the whitebox fuzzer SAGE, scales to large programs with many nested loops, and we present results of experiments with aWindows 7 image parser},
   author = {Patrice Godefroid and Daniel Luchaup},
   doi = {10.1145/2001420.2001424},
   journal = {2011 International Symposium on Software Testing and Analysis, ISSTA 2011 - Proceedings},
   keywords = {loop invariant generation,program summarization,program testing and verification},
   title = {Automatic partial loop summarization in dynamic test generation},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Luchaup after removed: [@article{Godefroid2011,
   abstract = {Whitebox fuzzing extends dynamic test generation based on sym- bolic execution and constraint solving from unit testing to whole- application security testing. Unfortunately, input-dependent loops may cause an explosion in the number of constraints to be solved and in the number of execution paths to be explored. In practice, whitebox fuzzers arbitrarily bound the number of constraints and paths due to input-dependent loops, at the risk of missing code and bugs. In thiswork, we investigate the use of simple loop-guard pattern- matching rules to automatically guess an input constraint defining the number of iterations of input-dependent loops during dynamic symbolic execution. We discover the loop structure of the program on the fly, detect induction variables, which are variables modified by a constant value during loop iterations, and infer simple partial loop invariants relating the value of such variables. Whenever a guess is confirmed later during the current dynamic symbolic ex- ecution, we then inject new constraints representing pre and post loop conditions, effectively summarizing sets of executions of that loop. These pre and post conditions are derived from partial loop invariants synthesized dynamically using pattern-matching rules on the loop guards and induction variables,without requiring any static analysis, theoremproving, or input-format specification. This tech- nique has been implemented in the whitebox fuzzer SAGE, scales to large programs with many nested loops, and we present results of experiments with aWindows 7 image parser},
   author = {Patrice Godefroid and Daniel Luchaup},
   doi = {10.1145/2001420.2001424},
   journal = {2011 International Symposium on Software Testing and Analysis, ISSTA 2011 - Proceedings},
   keywords = {loop invariant generation,program summarization,program testing and verification},
   title = {Automatic partial loop summarization in dynamic test generation},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Daniel Luchaup: loop invariant generationprogram summarizationprogram testing and verification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E. Yahav : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E. Yahav after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of E. Yahav: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John C. Reynolds : [@article{Reynolds2002,
   abstract = {In joint work with Peter O'Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure. The simple imperative programming language is extended with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a "separating conjunction" that asserts that its subformulas hold for disjoint parts of the heap, and a closely related "separating implication". Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of structures with controlled sharing. In this paper, we survey the current development of this program logic, including extensions that permit unrestricted address arithmetic, dynamically allocated arrays, and recursive procedures. We also discuss promising future directions.},
   author = {John C. Reynolds},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Separation logic: A logic for shared mutable data structures},
   year = {2002},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John C. Reynolds after removed: [@article{Reynolds2002,
   abstract = {In joint work with Peter O'Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure. The simple imperative programming language is extended with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a "separating conjunction" that asserts that its subformulas hold for disjoint parts of the heap, and a closely related "separating implication". Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of structures with controlled sharing. In this paper, we survey the current development of this program logic, including extensions that permit unrestricted address arithmetic, dynamically allocated arrays, and recursive procedures. We also discuss promising future directions.},
   author = {John C. Reynolds},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Separation logic: A logic for shared mutable data structures},
   year = {2002},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of John C. Reynolds: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of V. A. Kreknin : [@article{Lvov2012,
   author = {M. S. Lvov and V. A. Kreknin},
   doi = {10.1007/s10559-012-9406-y},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Automatic generation problem,Eigenpolynomial of a linear operator,Polynomial loop invariant,Static program analysis},
   title = {Nonlinear invariants for linear loops and eigenpolynomials of linear operators},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of V. A. Kreknin after removed: [@article{Lvov2012,
   author = {M. S. Lvov and V. A. Kreknin},
   doi = {10.1007/s10559-012-9406-y},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Automatic generation problem,Eigenpolynomial of a linear operator,Polynomial loop invariant,Static program analysis},
   title = {Nonlinear invariants for linear loops and eigenpolynomials of linear operators},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of V. A. Kreknin: Automatic generation problemEigenpolynomial of a linear operatorPolynomial loop invariantStatic program analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiaohong Li : [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiaohong Li after removed: [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Xiaohong Li: Disjunctive SummaryLoop SummarizationLoop summarizationString constraintsSymbolic executionDisjunctive loop summarypath dependency automatonpath interleavingLoop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Radhia Cousot : [@article{Cousot2014,
   abstract = {Abstract interpretation is a theory of abstraction and constructive approximation of the mathematical structures used in the formal description of complex or infinite systems and the inference or verification of their combinatorial or undecidable properties. Developed in the late seventies, it has been since then used, implicitly or explicitly, to many aspects of computer science (such as static analysis and verification, contract inference, type inference, termination inference, model-checking, abstraction/refinement, program transformation (including watermarking, obfuscation, etc), combination of decision procedures, security, malware detection, database queries, etc) and more recently, to system biology and SAT/SMT solvers. Production-quality verification tools based on abstract interpretation are available and used in the advanced software, hardware, transportation, communication, and medical industries. The talk will consist in an introduction to the basic notions of abstract interpretation and the induced methodology for the systematic development of sound abstract interpretation-based tools. Examples of abstractions will be provided, from semantics to typing, grammars to safety, reachability to potential/definite termination, numerical to protein-protein abstractions, as well as applications (including those in industrial use) to software, hardware and system biology. This paper is a general discussion of abstract interpretation, with selected publications, which unfortunately are far from exhaustive both in the considered themes and the corresponding references.},
   author = {Patrick Cousot and Radhia Cousot},
   doi = {10.1145/2603088.2603165},
   journal = {Proceedings of the Joint Meeting of the 23rd EACSL Annual Conference on Computer Science Logic, CSL 2014 and the 29th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2014},
   keywords = {Abstract interpretation,Proof,Semantics,Static Analysis,Verification},
   title = {Abstract interpretation: Past, present and future},
   year = {2014},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Radhia Cousot after removed: [@article{Cousot2014,
   abstract = {Abstract interpretation is a theory of abstraction and constructive approximation of the mathematical structures used in the formal description of complex or infinite systems and the inference or verification of their combinatorial or undecidable properties. Developed in the late seventies, it has been since then used, implicitly or explicitly, to many aspects of computer science (such as static analysis and verification, contract inference, type inference, termination inference, model-checking, abstraction/refinement, program transformation (including watermarking, obfuscation, etc), combination of decision procedures, security, malware detection, database queries, etc) and more recently, to system biology and SAT/SMT solvers. Production-quality verification tools based on abstract interpretation are available and used in the advanced software, hardware, transportation, communication, and medical industries. The talk will consist in an introduction to the basic notions of abstract interpretation and the induced methodology for the systematic development of sound abstract interpretation-based tools. Examples of abstractions will be provided, from semantics to typing, grammars to safety, reachability to potential/definite termination, numerical to protein-protein abstractions, as well as applications (including those in industrial use) to software, hardware and system biology. This paper is a general discussion of abstract interpretation, with selected publications, which unfortunately are far from exhaustive both in the considered themes and the corresponding references.},
   author = {Patrick Cousot and Radhia Cousot},
   doi = {10.1145/2603088.2603165},
   journal = {Proceedings of the Joint Meeting of the 23rd EACSL Annual Conference on Computer Science Logic, CSL 2014 and the 29th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2014},
   keywords = {Abstract interpretation,Proof,Semantics,Static Analysis,Verification},
   title = {Abstract interpretation: Past, present and future},
   year = {2014},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Radhia Cousot: Abstract interpretationProofSemanticsStatic AnalysisVerification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Qingkai Shi : [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Qingkai Shi after removed: [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Qingkai Shi: SMT solvingSparse analysispath sensitivityprogram dependence graph
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jacob Van Geffen : [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jacob Van Geffen after removed: [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jacob Van Geffen: Component-based synthesisData preparationProgram synthesisProgramming by exampleSMT-based deduction
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Deepak Kapur : [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Deepak Kapur after removed: [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Deepak Kapur: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Irene Finocchi : [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Irene Finocchi after removed: [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Irene Finocchi: Concolic executionSoftware testingStatic analysisSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yu Feng : [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yu Feng after removed: [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Yu Feng: Component-based synthesisData preparationProgram synthesisProgramming by exampleSMT-based deduction
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Wei Le : [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Wei Le after removed: [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Wei Le: Disjunctive SummaryLoop SummarizationLoop summarizationString constraintsSymbolic executionDisjunctive loop summarypath dependency automatonpath interleaving
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Patrick Knab : [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Patrick Knab after removed: [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Patrick Knab: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Conor Power : [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Conor Power after removed: [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Conor Power: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mark Williams : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mark Williams after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Mark Williams: C++CompilationDynamic languagesPHP
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hongxu Chen : [@article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hongxu Chen after removed: [@article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Hongxu Chen: Loop summarizationString constraintsSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Rahul Sharma : [@article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Rahul Sharma after removed: [@article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Rahul Sharma: Static analysisdecomposition of multi-phase loopsinvariant generation
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nikos Gorogiannis : [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nikos Gorogiannis after removed: [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Nikos Gorogiannis: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Cao : [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Cao after removed: [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of David Cao: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E.T. Sianturi : [@article{Sianturi2019,
   abstract = {ΕΙΣ ΤΟΝ ΑΙΩΝΑ},
   author = {E.T. Sianturi},
   journal = {Αγαη},
   keywords = {ΕΡΨΣ-ΑΓΑΠΗ},
   title = {No TitleΕΛΕΝΗ},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of E.T. Sianturi after removed: [@article{Sianturi2019,
   abstract = {ΕΙΣ ΤΟΝ ΑΙΩΝΑ},
   author = {E.T. Sianturi},
   journal = {Αγαη},
   keywords = {ΕΡΨΣ-ΑΓΑΠΗ},
   title = {No TitleΕΛΕΝΗ},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of E.T. Sianturi: ΕΡΨΣ-ΑΓΑΠΗ
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cole Schlesinger : [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cole Schlesinger after removed: [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Cole Schlesinger: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jun Sun : [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jun Sun after removed: [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jun Sun: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Noam Rinetzky : [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
, @article{Rinetzky2001,
   author = {Noam Rinetzky and Mooly Sagiv},
   doi = {10.1007/3-540-45306-7_10},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for recursive programs},
   year = {2001},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Noam Rinetzky after removed: [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
, @article{Rinetzky2001,
   author = {Noam Rinetzky and Mooly Sagiv},
   doi = {10.1007/3-540-45306-7_10},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for recursive programs},
   year = {2001},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Noam Rinetzky: Loop SummarisationOptimisationRefactoringStringsSymbolic ExecutionSynthesis3-valued logicAbstract interpretationShape analysisStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Qi Gao : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Qi Gao after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Qi Gao: C++CompilationDynamic languagesPHP
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiaofei Xie : [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiaofei Xie after removed: [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Xiaofei Xie: Disjunctive SummaryLoop SummarizationLoop summarizationString constraintsSymbolic executionDisjunctive loop summarypath dependency automatonpath interleavingLoop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nadia Polikarpova : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
, @article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nadia Polikarpova after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
, @article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Nadia Polikarpova: Abstract InterpretationProgram SynthesisType SystemsDomain-specific languagesProbabilistic modelsProgram SynthesisHuman-Computer InteractionProgram SynthesisType Inference
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shang Wei Lin : [@article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shang Wei Lin after removed: [@article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shang Wei Lin: Loop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bertrand Jeannet : [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
, @article{Jeannet2009,
   abstract = {This article describes Apron, a freely available library dedi- cated to the static analysis of the numerical variables of programs by ab- stract interpretation. Its goal is threefold: provide analysis implementers with ready-to-use numerical abstractions under a unified API, encour- age the research in numerical abstract domains by providing a platform for integration and comparison, and provide teaching and demonstration tools to disseminate knowledge on abstract interpretation.},
   author = {Bertrand Jeannet and Antoine Miné},
   doi = {10.1007/978-3-642-02658-4_52},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Apron: A library of numerical abstract domains for static analysis},
   year = {2009},
}
, @article{Jeannet2007,
   author = {Bertrand Jeannet},
   journal = {October},
   title = {by Bertrand Jeannet and the APRON team},
   year = {2007},
}
, @article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
, @article{Schrammel2010,
   abstract = {Acceleration methods are commonly used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with Boolean and numerical variables, e.g. Lustre programs, firstly requires the enumeration of the Boolean states in order to obtain a control graph with numerical variables only. Secondly, acceleration methods have to deal with the non-determinism introduced by numerical input variables. In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to numerical input variables. © 2010 Elsevier B.V. All rights reserved.},
   author = {Peter Schrammel and Bertrand Jeannet},
   doi = {10.1016/j.entcs.2010.09.009},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Static analysis,abstract interpretation,acceleration,linear relation analysis},
   title = {Extending abstract acceleration methods to data-flow programs with numerical inputs},
   year = {2010},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bertrand Jeannet after removed: [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
, @article{Jeannet2009,
   abstract = {This article describes Apron, a freely available library dedi- cated to the static analysis of the numerical variables of programs by ab- stract interpretation. Its goal is threefold: provide analysis implementers with ready-to-use numerical abstractions under a unified API, encour- age the research in numerical abstract domains by providing a platform for integration and comparison, and provide teaching and demonstration tools to disseminate knowledge on abstract interpretation.},
   author = {Bertrand Jeannet and Antoine Miné},
   doi = {10.1007/978-3-642-02658-4_52},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Apron: A library of numerical abstract domains for static analysis},
   year = {2009},
}
, @article{Jeannet2007,
   author = {Bertrand Jeannet},
   journal = {October},
   title = {by Bertrand Jeannet and the APRON team},
   year = {2007},
}
, @article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
, @article{Schrammel2010,
   abstract = {Acceleration methods are commonly used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with Boolean and numerical variables, e.g. Lustre programs, firstly requires the enumeration of the Boolean states in order to obtain a control graph with numerical variables only. Secondly, acceleration methods have to deal with the non-determinism introduced by numerical input variables. In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to numerical input variables. © 2010 Elsevier B.V. All rights reserved.},
   author = {Peter Schrammel and Bertrand Jeannet},
   doi = {10.1016/j.entcs.2010.09.009},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Static analysis,abstract interpretation,acceleration,linear relation analysis},
   title = {Extending abstract acceleration methods to data-flow programs with numerical inputs},
   year = {2010},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Bertrand Jeannet: Static analysisabstract interpretationaccelerationlinear relation analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Timotej Kapus : [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Timotej Kapus after removed: [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Timotej Kapus: Loop SummarisationOptimisationRefactoringStringsSymbolic ExecutionSynthesis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mirko Cesarini : [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mirko Cesarini after removed: [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Mirko Cesarini: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Chang Xu : [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Chang Xu after removed: [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Chang Xu: Build systemBypath compilationIncremental build
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Swarat Chaudhuri : [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Swarat Chaudhuri after removed: [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Swarat Chaudhuri: Component-based synthesisData preparationProgram synthesisProgramming by exampleSMT-based deduction
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ruzica Piskac : [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
, @article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ruzica Piskac after removed: [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
, @article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Ruzica Piskac: Pro-gram SynthesisReactive SynthesisSyntax-Guided Synthesis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Alvin Cheung : [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
, @article{Ahmad2018,
   abstract = {MapReduce is a popular programming paradigm for developing large-scale, data-intensive computation. Many frameworks that implement this paradigm have recently been developed. To leverage these frameworks, however, developers must become familiar with their APIs and rewrite existing code. We present Casper, a new tool that automatically translates sequential Java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps: (1) Casper uses program synthesis to search for a program summary (i.e., a functional specification) of each code fragment. The summary is expressed using a high-level intermediate language resembling the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. (2) Casper generates executable code from the summary, using either the Hadoop, Spark, or Flink API. We evaluated Casper by automatically converting realworld, sequential Java benchmarks to MapReduce. The resulting benchmarks perform up to 48.2× faster compared to the original.},
   author = {Maaz Bin Safeer Ahmad and Alvin Cheung},
   doi = {10.1145/3183713.3196891},
   journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
   title = {Automatically leveraging MapReduce frameworks for data-intensive applications},
   year = {2018},
}
, @article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Alvin Cheung after removed: [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
, @article{Ahmad2018,
   abstract = {MapReduce is a popular programming paradigm for developing large-scale, data-intensive computation. Many frameworks that implement this paradigm have recently been developed. To leverage these frameworks, however, developers must become familiar with their APIs and rewrite existing code. We present Casper, a new tool that automatically translates sequential Java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps: (1) Casper uses program synthesis to search for a program summary (i.e., a functional specification) of each code fragment. The summary is expressed using a high-level intermediate language resembling the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. (2) Casper generates executable code from the summary, using either the Hadoop, Spark, or Flink API. We evaluated Casper by automatically converting realworld, sequential Java benchmarks to MapReduce. The resulting benchmarks perform up to 48.2× faster compared to the original.},
   author = {Maaz Bin Safeer Ahmad and Alvin Cheung},
   doi = {10.1145/3183713.3196891},
   journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
   title = {Automatically leveraging MapReduce frameworks for data-intensive applications},
   year = {2018},
}
, @article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Alvin Cheung: Program SynthesisQuery by ExampleSQL
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of François Irigoin : [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
, @article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of François Irigoin after removed: [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
, @article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of François Irigoin: abstract interpretationautomatic invariant detectionbenchmarklinear relation analysisloop invariantmodel checkingstatic program analysistransformerAbstract interpretationfixed point computationloop invariant
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Norbert Pataki : [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
, @article{Babati2017,
   author = {Bence Babati and Norbert Pataki},
   doi = {10.15439/2017f358},
   journal = {Communiation Papers of the 2017 Federated Conference on Computer Science and Information Systems},
   title = {Analysis of Include Dependencies in C++ Source Code},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Norbert Pataki after removed: [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
, @article{Babati2017,
   author = {Bence Babati and Norbert Pataki},
   doi = {10.15439/2017f358},
   journal = {Communiation Papers of the 2017 Federated Conference on Computer Science and Information Systems},
   title = {Analysis of Include Dependencies in C++ Source Code},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Norbert Pataki: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Doug Kimelman : [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Doug Kimelman after removed: [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Doug Kimelman: D213 [Software Engineering]: Reusable Software-Reuse ModelsD26 [Software Engineer-ing]: Programming Environments-Integrated EnvironmentsI22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation Languages Keywords reuse program synthesis mining *
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dino Distefano : [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dino Distefano after removed: [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Dino Distefano: Formal verificationLivenessProgram analysisSoftware model checkingTerminationa program analysis iscompo-languagesor programpartsprogramreliabilityresult of a compositesimilarlysitional if the analysisthe meanings of itstheoryverification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shuxian Wang : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shuxian Wang after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shuxian Wang: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xavier Rival : [@article{Chang2008,
   abstract = {Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion. Copyright © 2008 ACM.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/1328438.1328469},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {heap analysis,inductive definitions,materialization,separation logic,shape analysis,symbolic abstract domain},
   title = {Relational inductive shape analysis},
   year = {2008},
}
, @article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
, @article{Chang2013,
   abstract = {The aim of static analysis is to infer invariants about programs that are precise enough to establish semantic properties, such as the absence of run-time errors. Broadly speaking, there are two major branches of static analysis for imperative programs. Pointer and shape analyses focus on inferring properties of pointers, dynamically-allocated memory, and recursive data structures, while numeric analyses seek to derive invariants on numeric values. Although simultaneous inference of shapenumeric invariants is often needed, this case is especially challenging and is not particularly well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. In this paper, we study the construction of such shape-numeric, static analyzers. We set up an abstract interpretation framework that allows us to reason about simultaneous shape-numeric properties by combining shape and numeric abstractions into a modular, expressive abstract domain. Such a modular structure is highly desirable to make its formalization and implementation easier to do and get correct. To achieve this, we choose a concrete semantics that can be abstracted step-by-step, while preserving a high level of expressiveness. The structure of abstract operations (i.e., transfer, join, and comparison) follows the structure of this semantics. The advantage of this construction is to divide the analyzer in modules and functors that implement abstractions of distinct features. © B.-Y. E. Chang and X. Rival.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.4204/EPTCS.129.11},
   journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
   title = {Modular construction of shape-numeric analyzers},
   year = {2013},
}
, @article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
, @article{Rival2010,
   abstract = {Interprocedural program analysis is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, particularly in the presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records. We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack-much like how shape analyzers enable a fluid per program point abstraction of the heap. Copyright © 2011 ACM.},
   author = {Xavier Rival and Bor Yuh Evan Chang},
   doi = {10.1145/1926385.1926406},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Calling context,Context-sensitivity,Inductive definitions,Interprocedural analysis,Separation logic,Shape analysis,Symbolic abstract domain},
   title = {Calling context abstraction with shapes},
   year = {2010},
}
, @article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xavier Rival after removed: [@article{Chang2008,
   abstract = {Shape analyses are concerned with precise abstractions of the heap to capture detailed structural properties. To do so, they need to build and decompose summaries of disjoint memory regions. Unfortunately, many data structure invariants require relations be tracked across disjoint regions, such as intricate numerical data invariants or structural invariants concerning back and cross pointers. In this paper, we identify issues inherent to analyzing relational structures and design an abstract domain that is parameterized both by an abstract domain for pure data properties and by user-supplied specifications of the data structure invariants to check. Particularly, it supports hybrid invariants about shape and data and features a generic mechanism for materializing summaries at the beginning, middle, or end of inductive structures. Around this domain, we build a shape analysis whose interesting components include a pre-analysis on the user-supplied specifications that guides the abstract interpretation and a widening operator over the combined shape and data domain. We then demonstrate our techniques on the proof of preservation of the red-black tree invariants during insertion. Copyright © 2008 ACM.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/1328438.1328469},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {heap analysis,inductive definitions,materialization,separation logic,shape analysis,symbolic abstract domain},
   title = {Relational inductive shape analysis},
   year = {2008},
}
, @article{Chang2007,
   abstract = {Developer-supplied data structure specifications are important to shape analyses, as they tell the analysis what information should be tracked in order to obtain the desired shape invariants. We observe that data structure checking code (e.g., used in testing or dynamic analysis) provides shape information that can also be used in static analysis. In this paper, we propose a lightweight, automatic shape analysis based on these developer-supplied structural invariant checkers. In particular, we set up a parametric abstract domain, which is instantiated with such checker specifications to summarize memory regions using both notions of complete and partial checker evaluations. The analysis then automatically derives a strategy for canonicalizing or weakening shape invariants. © Springer-Verlag Berlin Heidelberg 2007.},
   author = {Bor Yuh Evan Chang and Xavier Rival and George C. Necula},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Shape analysis with structural invariant checkers},
   year = {2007},
}
, @article{Chang2013,
   abstract = {The aim of static analysis is to infer invariants about programs that are precise enough to establish semantic properties, such as the absence of run-time errors. Broadly speaking, there are two major branches of static analysis for imperative programs. Pointer and shape analyses focus on inferring properties of pointers, dynamically-allocated memory, and recursive data structures, while numeric analyses seek to derive invariants on numeric values. Although simultaneous inference of shapenumeric invariants is often needed, this case is especially challenging and is not particularly well explored. Notably, simultaneous shape-numeric inference raises complex issues in the design of the static analyzer itself. In this paper, we study the construction of such shape-numeric, static analyzers. We set up an abstract interpretation framework that allows us to reason about simultaneous shape-numeric properties by combining shape and numeric abstractions into a modular, expressive abstract domain. Such a modular structure is highly desirable to make its formalization and implementation easier to do and get correct. To achieve this, we choose a concrete semantics that can be abstracted step-by-step, while preserving a high level of expressiveness. The structure of abstract operations (i.e., transfer, join, and comparison) follows the structure of this semantics. The advantage of this construction is to divide the analyzer in modules and functors that implement abstractions of distinct features. © B.-Y. E. Chang and X. Rival.},
   author = {Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.4204/EPTCS.129.11},
   journal = {Electronic Proceedings in Theoretical Computer Science, EPTCS},
   title = {Modular construction of shape-numeric analyzers},
   year = {2013},
}
, @article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
, @article{Rival2010,
   abstract = {Interprocedural program analysis is often performed by computing procedure summaries. While possible, computing adequate summaries is difficult, particularly in the presence of recursive procedures. In this paper, we propose a complementary framework for interprocedural analysis based on a direct abstraction of the calling context. Specifically, our approach exploits the inductive structure of a calling context by treating it directly as a stack of activation records. We then build an abstraction based on separation logic with inductive definitions. A key element of this abstract domain is the use of parameters to refine the meaning of such call stack summaries and thus express relations across activation records and with the heap. In essence, we define an abstract interpretation-based analysis framework for recursive programs that permits a fluid per call site abstraction of the call stack-much like how shape analyzers enable a fluid per program point abstraction of the heap. Copyright © 2011 ACM.},
   author = {Xavier Rival and Bor Yuh Evan Chang},
   doi = {10.1145/1926385.1926406},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Calling context,Context-sensitivity,Inductive definitions,Interprocedural analysis,Separation logic,Shape analysis,Symbolic abstract domain},
   title = {Calling context abstraction with shapes},
   year = {2010},
}
, @article{Toubhans2014,
   abstract = {© Springer International Publishing Switzerland 2014. The breadth and depth of heap properties that can be inferred by the union of today’s shape analyses is quite astounding. Yet, achieving scalability while supporting a wide range of complex data structures in a generic way remains a long-standing challenge. In this paper, we propose a way to side-step this issue by defining a generic abstract domain combinator for combining memory abstractions on disjoint regions. In essence, our abstract domain construction is to the separating conjunction in separation logic as the reduced product construction is to classical, non-separating conjunction. This approach eases the design of the analysis as memory abstract domains can be re-used by applying our separating conjunction domain combinator. And more importantly, this combinator enables an analysis designer to easily create a combined domain that applies computationally-expensive abstract domains only where it is required.},
   author = {Antoine Toubhans and Bor Yuh Evan Chang and Xavier Rival},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An abstract domain combinator for separately conjoining memory abstractions},
   year = {2014},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Xavier Rival: heap analysisinductive definitionsmaterializationseparation logicshape analysissymbolic abstract domainAbstract interpretationClumping of disjunctsDisjunctionsHeap abstractionSeparation logicsSilhouetteStatic analysisCalling contextContext-sensitivityInductive definitionsInterprocedural analysisSeparation logicShape analysisSymbolic abstract domain
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Richard Vuduc : [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Richard Vuduc after removed: [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Richard Vuduc: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andreas Podelski : [@article{Podelski2004,
   abstract = { Proof rules for program verification rely on auxiliary assertions. We propose a (sound and relatively complete) proof rule whose auxiliary assertions are transition invariants. A transition invariant of a program is a binary relation over program states that contains the transitive closure of the transition relation of the program. A relation is disjunctively well-founded if it is a finite union of well-founded relations. We characterize the validity of termination or another liveness property by the existence of a disjunctively well-founded transition invariant. The main contribution of our proof rule lies in its potential for automation via abstract interpretation.},
   author = {Andreas Podelski and Andrey Rybalchenko},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Transition invariants},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andreas Podelski after removed: [@article{Podelski2004,
   abstract = { Proof rules for program verification rely on auxiliary assertions. We propose a (sound and relatively complete) proof rule whose auxiliary assertions are transition invariants. A transition invariant of a program is a binary relation over program states that contains the transitive closure of the transition relation of the program. A relation is disjunctively well-founded if it is a finite union of well-founded relations. We characterize the validity of termination or another liveness property by the existence of a disjunctively well-founded transition invariant. The main contribution of our proof rule lies in its potential for automation via abstract interpretation.},
   author = {Andreas Podelski and Andrey Rybalchenko},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Transition invariants},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Andreas Podelski: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sandrine Blazy : [@article{Blazy2015,
   abstract = {Summary: This book constitutes the refereed proceedings of the 22nd International Static Analysis Symposium, SAS 2015, held in Saint-Malo, France, in September 2015. The 18 papers presented in this volume were carefully reviewed and selected from 44 submissions. All fields of static analysis as a fundamental tool for program verification, bug detection, compiler optimization, program understanding, and software maintenance are addressed, featuring theoretical, practical, and application advances in the area.},
   author = {Sandrine Blazy and Thomas Jensen},
   doi = {10.1007/978-3-662-48288-9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static Analysis: 22nd International Symposium, SAS 2015 Saint-Malo, France, September 9-11, 2015 Proceedings},
   year = {2015},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sandrine Blazy after removed: [@article{Blazy2015,
   abstract = {Summary: This book constitutes the refereed proceedings of the 22nd International Static Analysis Symposium, SAS 2015, held in Saint-Malo, France, in September 2015. The 18 papers presented in this volume were carefully reviewed and selected from 44 submissions. All fields of static analysis as a fundamental tool for program verification, bug detection, compiler optimization, program understanding, and software maintenance are addressed, featuring theoretical, practical, and application advances in the area.},
   author = {Sandrine Blazy and Thomas Jensen},
   doi = {10.1007/978-3-662-48288-9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static Analysis: 22nd International Symposium, SAS 2015 Saint-Malo, France, September 9-11, 2015 Proceedings},
   year = {2015},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Sandrine Blazy: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bill McCloskey : [@article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Bill McCloskey after removed: [@article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Bill McCloskey: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sharon Lee : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sharon Lee after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Sharon Lee: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Calvin Lin : [@article{Guyer1999,
   abstract = {This paper introduces an annotation language and a compiler that together\ncan customize a library implementation for specific application needs.\nOur approach is distinguished by its ability to exploit high level,\ndomain-specific information in the customization process. In particular,\nthe annotations provide semantic information that enables our compiler\nto analyze and optimize library operations as if they were primitives\nof a domain-specific language. Thus, our approach yields many of\nthe performance benefits of domain-specific languages, without the\neffort of developing a new compiler for each domain.\n\nThis paper presents the annotation language, describes its role in\noptimization, and illustrates the benefits of the overall approach.\nUsing a partially implemented compiler, we show how our system can\nsignificantly improve the performance of two applications written\nusing the PLAPACK parallel linear algebra library.},
   author = {Samuel Z. Guyer and Calvin Lin},
   doi = {10.1145/331960.331970},
   journal = {Proceedings of the 2nd Conference on Domain-Specific Languages, DSL 1999},
   title = {An annotation language for optimizing software libraries},
   year = {1999},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Calvin Lin after removed: [@article{Guyer1999,
   abstract = {This paper introduces an annotation language and a compiler that together\ncan customize a library implementation for specific application needs.\nOur approach is distinguished by its ability to exploit high level,\ndomain-specific information in the customization process. In particular,\nthe annotations provide semantic information that enables our compiler\nto analyze and optimize library operations as if they were primitives\nof a domain-specific language. Thus, our approach yields many of\nthe performance benefits of domain-specific languages, without the\neffort of developing a new compiler for each domain.\n\nThis paper presents the annotation language, describes its role in\noptimization, and illustrates the benefits of the overall approach.\nUsing a partially implemented compiler, we show how our system can\nsignificantly improve the performance of two applications written\nusing the PLAPACK parallel linear algebra library.},
   author = {Samuel Z. Guyer and Calvin Lin},
   doi = {10.1145/331960.331970},
   journal = {Proceedings of the 2nd Conference on Domain-Specific Languages, DSL 1999},
   title = {An annotation language for optimizing software libraries},
   year = {1999},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Calvin Lin: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hongyu Zhao : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Hongyu Zhao after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Hongyu Zhao: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Syed S Albiz : [@article{Albiz2009,
   author = {Syed S Albiz and Patrick Lam},
   title = {Implementation and Use of Data Structures in Java Programs},
   year = {2009},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Syed S Albiz after removed: [@article{Albiz2009,
   author = {Syed S Albiz and Patrick Lam},
   title = {Implementation and Use of Data Structures in Java Programs},
   year = {2009},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Syed S Albiz: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiangyu Zhou : [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Xiangyu Zhou after removed: [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Xiangyu Zhou: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Radu Rugina : [@article{Hackett2005,
   abstract = {This paper proposes a novel approach to shape analysis: using local reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the smaller granularity of the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses.We also show that the analysis can be used to enable the static detection of memory errors in programs with explicit deallocation. We have built a prototype tool that detects memory leaks and accesses through dangling pointers in C programs. The experiments indicate that the analysis is sufficiently precise to detect errors with low false positive rates; and is sufficiently lightweight to scale to larger programs. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less than 2 minutes and has produced 97 warnings, 38 of which were actual errors.},
   author = {Brian Hackett and Radu Rugina},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Memory leaks,Memory management,Shape analysis,Static error detection},
   title = {Region-based shape analysis with tracked locations},
   year = {2005},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Radu Rugina after removed: [@article{Hackett2005,
   abstract = {This paper proposes a novel approach to shape analysis: using local reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the smaller granularity of the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses.We also show that the analysis can be used to enable the static detection of memory errors in programs with explicit deallocation. We have built a prototype tool that detects memory leaks and accesses through dangling pointers in C programs. The experiments indicate that the analysis is sufficiently precise to detect errors with low false positive rates; and is sufficiently lightweight to scale to larger programs. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less than 2 minutes and has produced 97 warnings, 38 of which were actual errors.},
   author = {Brian Hackett and Radu Rugina},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Memory leaks,Memory management,Shape analysis,Static error detection},
   title = {Region-based shape analysis with tracked locations},
   year = {2005},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Radu Rugina: Memory leaksMemory managementShape analysisStatic error detection
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Kroening : [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Daniel Kroening after removed: [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Daniel Kroening: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sicheng Pan : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sicheng Pan after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Sicheng Pan: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Reinhard Wilhelm : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Reinhard Wilhelm after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Reinhard Wilhelm: 3-valued logicAbstract interpretationAlgorithmsAlias analysisConstraint solvingDestructive updatingLanguagesPointer analysisShape analysisStatic analysisTheoryVerification3-valued logicAbstract interpretationShape analysisStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Oren Ish-Shalom : [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Oren Ish-Shalom after removed: [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Oren Ish-Shalom: Loop SummarisationOptimisationRefactoringStringsSymbolic ExecutionSynthesis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shmuel Ur : [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shmuel Ur after removed: [@article{Quinlan2006,
   abstract = {Testing forms a critical part of the development process for large-scale software, and there is growing need for automated tools that can read, represent, analyze, and transform the application's source code to help carry out testing tasks. However, the support required to compile applications written in common general purpose languages is generally inaccessible to the testing research community. In this paper, we report on an extensible, open-source compiler infrastructure called ROSE, which is currently in development at Lawrence Livermore National Laboratory. ROSE specifically targets developers who wish to build source-based tools that implement customized analyses and optimizations for large-scale C, C++, and Fortran90 scientific computing applications (on the order of a million lines of code or more). However, much of this infrastructure can also be used to address problems in testing, and ROSE is by design broadly accessible to those without a formal compiler background. This paper details the interactions between testing of applications and the ways in which compiler technology can aid in the understanding of those applications. We emphasize the particular aspects of ROSE, such as support for the general analysis of whole programs, that are particularly well-suited to the testing research community and the scale of the problems that community solves. © Springer-Verlag Berlin Heidelberg 2006.},
   author = {Dan Quinlan and Shmuel Ur and Richard Vuduc},
   doi = {10.1007/11678779_9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {An extensible open-source compiler infrastructure for testing},
   year = {2006},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shmuel Ur: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sylvie Putot : [@article{Goubault2011,
   abstract = {We define several abstract semantics for the static analysis of finite precision computations, that bound not only the ranges of values taken by numerical variables of a program, but also the difference with the result of the same sequence of operations in an idealized real number semantics. These domains point out with more or less detail (control point, block, function for instance) sources of numerical errors in the program and the way they were propagated by further computations, thus allowing to evaluate not only the rounding error, but also sensitivity to inputs or parameters of the program. We describe two classes of abstractions, a non relational one based on intervals, and a weakly relational one based on parametrized zonotopic abstract domains called affine sets, especially well suited for sensitivity analysis and test generation. These abstract domains are implemented in the Fluctuat static analyzer, and we finally present some experiments. ? 2011 Springer-Verlag.},
   author = {Eric Goubault and Sylvie Putot},
   doi = {10.1007/978-3-642-18275-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static analysis of finite precision computations},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sylvie Putot after removed: [@article{Goubault2011,
   abstract = {We define several abstract semantics for the static analysis of finite precision computations, that bound not only the ranges of values taken by numerical variables of a program, but also the difference with the result of the same sequence of operations in an idealized real number semantics. These domains point out with more or less detail (control point, block, function for instance) sources of numerical errors in the program and the way they were propagated by further computations, thus allowing to evaluate not only the rounding error, but also sensitivity to inputs or parameters of the program. We describe two classes of abstractions, a non relational one based on intervals, and a weakly relational one based on parametrized zonotopic abstract domains called affine sets, especially well suited for sensitivity analysis and test generation. These abstract domains are implemented in the Fluctuat static analyzer, and we finally present some experiments. ? 2011 Springer-Verlag.},
   author = {Eric Goubault and Sylvie Putot},
   doi = {10.1007/978-3-642-18275-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static analysis of finite precision computations},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Sylvie Putot: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Kihong Heo : [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Kihong Heo after removed: [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Kihong Heo: Domain-specific languagesStatistical methodsSynthesisTransfer learning
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andy King : [@article{Simon2006,
   abstract = {The abstract domain of polyhedra is sufficiently expressive to be deployed in verification. One consequence of the richness of this domain is that long, possibly infinite, sequences of polyhedra can arise in the analysis of loops. Widening and narrowing have been proposed to infer a single polyhedron that summarises such a sequence of polyhedra. Motivated by precision losses encountered in verification, we explain how the classic widening/narrowing approach can be refined by an improved extrapolation strategy. The insight is to record inequalities that are thus far found to be unsatisfiable in the analysis of a loop. These so-called landmarks hint at the amount of widening necessary to reach stability. This extrapolation strategy, which refines widening with thresholds, can infer post-fixpoints that are precise enough not to require narrowing. Un- like previous techniques, our approach interacts well with other domains, is fully automatic, conceptually simple and precise on complex loops.},
   author = {Axel Simon and Andy King},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Widening polyhedra with landmarks},
   year = {2006},
}
, @article{Simon2004,
   abstract = {Suppose $<A_i, \vec\{c\},
   author = {Axel Simon and Andy King},
   doi = {10.1080/00207160310001650034},
   journal = {International Journal of Computer Mathematics},
   keywords = {Computational geometry,Convex hull},
   title = {Convex hull of planar H-polyhedra},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andy King after removed: [@article{Simon2006,
   abstract = {The abstract domain of polyhedra is sufficiently expressive to be deployed in verification. One consequence of the richness of this domain is that long, possibly infinite, sequences of polyhedra can arise in the analysis of loops. Widening and narrowing have been proposed to infer a single polyhedron that summarises such a sequence of polyhedra. Motivated by precision losses encountered in verification, we explain how the classic widening/narrowing approach can be refined by an improved extrapolation strategy. The insight is to record inequalities that are thus far found to be unsatisfiable in the analysis of a loop. These so-called landmarks hint at the amount of widening necessary to reach stability. This extrapolation strategy, which refines widening with thresholds, can infer post-fixpoints that are precise enough not to require narrowing. Un- like previous techniques, our approach interacts well with other domains, is fully automatic, conceptually simple and precise on complex loops.},
   author = {Axel Simon and Andy King},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Widening polyhedra with landmarks},
   year = {2006},
}
, @article{Simon2004,
   abstract = {Suppose $<A_i, \vec\{c\},
   author = {Axel Simon and Andy King},
   doi = {10.1080/00207160310001650034},
   journal = {International Journal of Computer Mathematics},
   keywords = {Computational geometry,Convex hull},
   title = {Convex hull of planar H-polyhedra},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Andy King: Computational geometryConvex hull
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Vini Kanvar : [@article{Kanvar2017,
   abstract = {A points-To analysis computes a sound abstraction of heap memory conventionally using a name-based abstraction that summarizes runtime memory by grouping locations using the names of allocation sites: All concrete heap locations allocated by the same statement are grouped together. The locations in the same group are treated alike i.e., a pointer to any one location of the group is assumed to point to every location in the group leading to an over-Approximation of points-To relations. We propose an access-based abstraction that partitions each name-based group of locations into equivalence classes at every program point using an additional criterion of the sets of access paths (chains of pointer indirections) reaching the locations in the memory. The intuition is that the locations that are both allocated and accessed alike should be grouped into the same equivalence class. Since the access paths in the memory could reach different locations at different program points, our groupings change flow sensitively unlike the name-based groupings. This creates a more precise view of the memory. Theoretically, it is strictly more precise than the name-based abstraction except in some trivial cases; practically it is far more precise. Our empirical measurements show the benefits of our tool Access-Based Heap Analyzer (ABHA) on SPEC CPU 2006 and heap manipulating SV-COMP benchmarks. ABHA, which is field-, flow-, and context-sensitive, scales to 20 kLoC and can improve the precision even up to 99% (in terms of the number of aliases). Additionally, ABHA allows any user-defined summarization of an access path to be plugged in; we have implemented and evaluated four summarization techniques. ABHA can also act as a front-end to TVLA, a parametrized shape analyzer, in order to automate its parametrization by generating predicates that capture the program behaviour more accurately.},
   author = {Vini Kanvar and Uday P. Khedker},
   doi = {10.1145/3092255.3092267},
   journal = {International Symposium on Memory Management, ISMM},
   keywords = {Access path,Alias,Allocation site,Heap abstraction,Static points-To analysis,Summarization},
   title = {What's in a name? Going beyond allocation site names in heap analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Vini Kanvar after removed: [@article{Kanvar2017,
   abstract = {A points-To analysis computes a sound abstraction of heap memory conventionally using a name-based abstraction that summarizes runtime memory by grouping locations using the names of allocation sites: All concrete heap locations allocated by the same statement are grouped together. The locations in the same group are treated alike i.e., a pointer to any one location of the group is assumed to point to every location in the group leading to an over-Approximation of points-To relations. We propose an access-based abstraction that partitions each name-based group of locations into equivalence classes at every program point using an additional criterion of the sets of access paths (chains of pointer indirections) reaching the locations in the memory. The intuition is that the locations that are both allocated and accessed alike should be grouped into the same equivalence class. Since the access paths in the memory could reach different locations at different program points, our groupings change flow sensitively unlike the name-based groupings. This creates a more precise view of the memory. Theoretically, it is strictly more precise than the name-based abstraction except in some trivial cases; practically it is far more precise. Our empirical measurements show the benefits of our tool Access-Based Heap Analyzer (ABHA) on SPEC CPU 2006 and heap manipulating SV-COMP benchmarks. ABHA, which is field-, flow-, and context-sensitive, scales to 20 kLoC and can improve the precision even up to 99% (in terms of the number of aliases). Additionally, ABHA allows any user-defined summarization of an access path to be plugged in; we have implemented and evaluated four summarization techniques. ABHA can also act as a front-end to TVLA, a parametrized shape analyzer, in order to automate its parametrization by generating predicates that capture the program behaviour more accurately.},
   author = {Vini Kanvar and Uday P. Khedker},
   doi = {10.1145/3092255.3092267},
   journal = {International Symposium on Memory Management, ISMM},
   keywords = {Access path,Alias,Allocation site,Heap abstraction,Static points-To analysis,Summarization},
   title = {What's in a name? Going beyond allocation site names in heap analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Vini Kanvar: Access pathAliasAllocation siteHeap abstractionStatic points-To analysisSummarization
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Tal Lev-Ami : [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Tal Lev-Ami after removed: [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Tal Lev-Ami: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Herbert Bos : [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Herbert Bos after removed: [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Herbert Bos: Data structuresDynamic binary analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cong Quy Trinh : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Cong Quy Trinh after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Cong Quy Trinh: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andrew Paroski : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andrew Paroski after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Andrew Paroski: C++CompilationDynamic languagesPHP
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jonathan Heinen : [@article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jonathan Heinen after removed: [@article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jonathan Heinen: Dynamic data structuresHyperedge replacement grammarsJava bytecodeVerification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dimitris Mitropoulos : [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Dimitris Mitropoulos after removed: [@article{Sotiropoulos2020,
   abstract = {Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).},
   author = {Thodoris Sotiropoulos and Stefanos Chaliasos and Dimitris Mitropoulos and Diomidis Spinellis},
   doi = {10.1145/3428212},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Gradle,JVM-based builds,Make,incremental builds,parallel builds},
   title = {A model for detecting faults in build specifications},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Dimitris Mitropoulos: GradleJVM-based buildsMakeincremental buildsparallel builds
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Alex Aiken : [@article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Alex Aiken after removed: [@article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Alex Aiken: Array analysisHeap analysisMemory invariantsRelational static analysisStatic analysisdecomposition of multi-phase loopsinvariant generation
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andreas Ziegler : [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Andreas Ziegler after removed: [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Andreas Ziegler: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Mandelin : [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of David Mandelin after removed: [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of David Mandelin: D213 [Software Engineering]: Reusable Software-Reuse ModelsD26 [Software Engineer-ing]: Programming Environments-Integrated EnvironmentsI22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation Languages Keywords reuse program synthesis mining *
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ruben Martins : [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ruben Martins after removed: [@article{Feng2017,
   abstract = {This paper presents a novel component-based synthesis algorithm that marries the power of type-directed search with lightweight SMT-based deduction and partial evaluation. Given a set of components together with their over-approximate first-order specifications, our method first generates a program sketch over a subset of the components and checks its feasibility using an SMT solver. Since a program sketch typically represents many concrete programs, the use of SMT-based deduction greatly increases the scalability of the algorithm. Once a feasible program sketch is found, our algorithm completes the sketch in a bottom-up fashion, using partial evaluation to further increase the power of deduction for rejecting partially-filled program sketches. We apply the proposed synthesis methodology for automating a large class of data preparation tasks that commonly arise in data science. We have evaluated our synthesis algorithm on dozens of data wrangling and consolidation tasks obtained from on-line forums, and we show that our approach can automatically solve a large class of problems encountered by R users.},
   author = {Yu Feng and Ruben Martins and Jacob Van Geffen and Isil Dillig and Swarat Chaudhuri},
   doi = {10.1145/3062341.3062351},
   journal = {ACM SIGPLAN Notices},
   keywords = {Component-based synthesis,Data preparation,Program synthesis,Programming by example,SMT-based deduction},
   title = {Component-based synthesis of table consolidation and transformation tasks from examples},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Ruben Martins: Component-based synthesisData preparationProgram synthesisProgramming by exampleSMT-based deduction
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Miltiadis Allamanis : [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Miltiadis Allamanis after removed: [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Miltiadis Allamanis: Information-theoretic ClusteringType Reinement
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Franck Védrine : [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Franck Védrine after removed: [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Franck Védrine: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mikolas Janota : [@article{Janota2007,
   abstract = {Abstract. Many automated techniques for invariant generation are based on the idea that the invariant should show that something “bad” will not happen in the analyzed program. In this article we present an algorithm for loop invariant generation in programs with assertions using a weakest precondition calculus. We have realized the algorithm in the extended static checker ESC/Java2. Challenges stemming from our initial experience with the implementation are also discussed.},
   author = {Mikolas Janota},
   journal = {Jml},
   keywords = {Conference item,JML,algorithm,java modeling language},
   title = {Assertion-based loop invariant generation},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mikolas Janota after removed: [@article{Janota2007,
   abstract = {Abstract. Many automated techniques for invariant generation are based on the idea that the invariant should show that something “bad” will not happen in the analyzed program. In this article we present an algorithm for loop invariant generation in programs with assertions using a weakest precondition calculus. We have realized the algorithm in the extended static checker ESC/Java2. Challenges stemming from our initial experience with the implementation are also discussed.},
   author = {Mikolas Janota},
   journal = {Jml},
   keywords = {Conference item,JML,algorithm,java modeling language},
   title = {Assertion-based loop invariant generation},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Mikolas Janota: Conference itemJMLalgorithmjava modeling language
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of B. D. Gannod : [@article{Gannod2001,
   abstract = {A modularization is a partitioning of a software system into components based on a variety of criteria, each depending on the clustering approach and desired level of abstraction. Source-header dependency graphs are bipartite graphs that are formed by flattening include file dependencies and enumerating source file to header file dependencies. In this paper, we describe an approach for identifying candidate modularizations of software systems by analyzing connectivity properties of source-header dependency graphs. In addition, we apply the approach to a large software system to demonstrate its applicability.},
   author = {G. C. Gannod and B. D. Gannod},
   journal = {Reverse Engineering - Working Conference Proceedings},
   title = {An investigation into the connectivity properties of source-header dependency graphs},
   year = {2001},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of B. D. Gannod after removed: [@article{Gannod2001,
   abstract = {A modularization is a partitioning of a software system into components based on a variety of criteria, each depending on the clustering approach and desired level of abstraction. Source-header dependency graphs are bipartite graphs that are formed by flattening include file dependencies and enumerating source file to header file dependencies. In this paper, we describe an approach for identifying candidate modularizations of software systems by analyzing connectivity properties of source-header dependency graphs. In addition, we apply the approach to a large software system to demonstrate its applicability.},
   author = {G. C. Gannod and B. D. Gannod},
   journal = {Reverse Engineering - Working Conference Proceedings},
   title = {An investigation into the connectivity properties of source-header dependency graphs},
   year = {2001},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of B. D. Gannod: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sarah Spall : [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Sarah Spall after removed: [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Sarah Spall: build systemsfunctional programming
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Katja Gräfenhain : [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Katja Gräfenhain after removed: [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Katja Gräfenhain: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Homy Dayani-Fard : [@article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Homy Dayani-Fard after removed: [@article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Homy Dayani-Fard: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Emilio Coppa : [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Emilio Coppa after removed: [@article{Baldoni2018,
   abstract = {Many security and software testing applications require checking whether certain properties of a program hold for any possible usage scenario. For instance, a tool for identifying software vulnerabilities may need to rule out the existence of any backdoor to bypass a program's authentication. One approach would be to test the program using different, possibly random inputs. As the backdoor may only be hit for very specific program workloads, automated exploration of the space of possible inputs is of the essence. Symbolic execution provides an elegant solution to the problem, by systematically exploring many possible execution paths at the same time without necessarily requiring concrete inputs. Rather than taking on fully specified input values, the technique abstractly represents them as symbols, resorting to constraint solvers to construct actual instances that would cause property violations. Symbolic execution has been incubated in dozens of tools developed over the last four decades, leading to major practical breakthroughs in a number of prominent software reliability applications. The goal of this survey is to provide an overview of the main ideas, challenges, and solutions developed in the area, distilling them for a broad audience. The present survey has been accepted for publication at ACM Computing Surveys. If you are considering citing this survey, we would appreciate if you could use the following BibTeX entry: http://goo.gl/Hf5Fvc},
   author = {Roberto Baldoni and Emilio Coppa and Daniele Cono D'elia and Camil Demetrescu and Irene Finocchi},
   doi = {10.1145/3182657},
   journal = {ACM Computing Surveys},
   keywords = {Concolic execution,Software testing,Static analysis,Symbolic execution},
   title = {A survey of symbolic execution techniques},
   year = {2018},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Emilio Coppa: Concolic executionSoftware testingStatic analysisSymbolic execution
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jie Li : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jie Li after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jie Li: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jason Evans : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jason Evans after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jason Evans: C++CompilationDynamic languagesPHP
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ganesan Ramalingam : [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Ganesan Ramalingam after removed: [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Ganesan Ramalingam: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John Mylopoulos : [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
, @article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of John Mylopoulos after removed: [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
, @article{Yu2003,
   abstract = {The development of large software systems involves a continual lengthy build process that may include preprocessing, compilation and linking of tens of thousands of source code files. In many cases, much of this build time is wasted because of false dependencies between implementation files and their respective header files. We present a graph algorithm and a programming tool that discovers and removes false dependencies among files. We show experimentally that the resulting preprocessed code is more compact, thereby contributing to faster build processes. },
   author = {Yijun Yu and Homy Dayani-Fard and John Mylopoulos},
   journal = {Proceedings of the 2003 Conference of the Centre for Advanced Studies on Collaborative Research},
   title = {Removing False Code Dependencies to Speedup Software Build Processes},
   year = {2003},
   url = {http://dl.acm.org/citation.cfm?id=961322.961375},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of John Mylopoulos: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joseph M. Hellerstein : [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joseph M. Hellerstein after removed: [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Joseph M. Hellerstein: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joshua Wu : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Joshua Wu after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Joshua Wu: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yanyan Jiang : [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yanyan Jiang after removed: [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Yanyan Jiang: Build systemBypath compilationIncremental build
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jörg Bauer : [@article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jörg Bauer after removed: [@article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jörg Bauer: 3-valued logicAbstract interpretationShape analysisStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nurit Dor : [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Nurit Dor after removed: [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Nurit Dor: alias analysisprogram verificationtypestate
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Byron Cook : [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Byron Cook after removed: [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Byron Cook: Formal verificationLivenessProgram analysisSoftware model checkingTerminationabstract interpretationconcurrent programmingshape analysisstatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mooly Sagiv : [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
, @article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
, @article{Rinetzky2001,
   author = {Noam Rinetzky and Mooly Sagiv},
   doi = {10.1007/3-540-45306-7_10},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for recursive programs},
   year = {2001},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
, @article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mooly Sagiv after removed: [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
, @article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
, @article{Rinetzky2001,
   author = {Noam Rinetzky and Mooly Sagiv},
   doi = {10.1007/3-540-45306-7_10},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for recursive programs},
   year = {2001},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
, @article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Mooly Sagiv: 3-valued logicAbstract interpretationAlgorithmsAlias analysisConstraint solvingDestructive updatingLanguagesPointer analysisShape analysisStatic analysisTheoryVerificationAbstract interpretationModel checkingPredicate abstractionSoftware componentsStatic analysis3-valued logicAbstract interpretationShape analysisStatic analysis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of N. Rinetzky : [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of N. Rinetzky after removed: [@article{Kreiker2013,
   abstract = {We present a framework for interprocedural shape analysis, which is context- and flow-sensitive with the ability to perform destructive pointer updates. We limit our attention to cutpoint-free programs—programs in which reasoning on a procedure call only requires consideration of context reachable from the actual parameters. For such programs, we show that our framework is able to perform an efficient modular analysis. Technically, our analysis computes procedure summaries as transformers from inputs to outputs while ignoring parts of the heap not relevant to the procedure. This makes the analysis modular in the heap and thus allows reusing the effect of a procedure at different call-sites and even between different contexts occurring at the same call-site. We have implemented a prototype of our framework and used it to verify interesting properties of cutpoint-free programs, including partial correctness of a recursive quicksort implementation.},
   author = {J. Kreiker and T. Reps and N. Rinetzky and M. Sagiv and Reinhard Wilhelm and E. Yahav},
   doi = {10.1007/978-3-642-37651-1_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Interprocedural shape analysis for effectively cutpoint-free programs},
   year = {2013},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of N. Rinetzky: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thanh Vu Nguyen : [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thanh Vu Nguyen after removed: [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thanh Vu Nguyen: Dynamic invariant analysisSeparation logic
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shivani Doshi : [@article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Shivani Doshi after removed: [@article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Shivani Doshi: Human-Computer InteractionProgram SynthesisType Inference
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Manuel Hermenegildo : [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Manuel Hermenegildo after removed: [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Manuel Hermenegildo: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Giacobazzi : [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Roberto Giacobazzi after removed: [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Roberto Giacobazzi: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jean Yang : [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jean Yang after removed: [@article{Guo2022,
   abstract = {With the rise of software-as-a-service and microservice architectures, RESTful APIs are now ubiquitous in mobile and web applications. A service can have tens or hundreds of API methods, making it a challenge for programmers to find the right combination of methods to solve their task. We present APIphany, a component-based synthesizer for programs that compose calls to RESTful APIs. The main innovation behind APIphany is the use of precise semantic types, both to specify user intent and to direct the search. APIphany contributes three novel mechanisms to overcome challenges in adapting component-based synthesis to the REST domain: (1) a type inference algorithm for augmenting REST specifications with semantic types; (2) an efficient synthesis technique for "wrangling" semi-structured data, which is commonly required in working with RESTful APIs; and (3) a new form of simulated execution to avoid executing APIs calls during synthesis. We evaluate APIphany on three real-world APIs and 32 tasks extracted from GitHub repositories and StackOverflow. In our experiments, APIphany found correct solutions to 29 tasks, with 23 of them reported among top ten synthesis results.},
   author = {Zheng Guo and David Cao and Davin Tjong and Jean Yang and Cole Schlesinger and Nadia Polikarpova},
   doi = {10.1145/3519939.3523450},
   title = {Type-directed program synthesis for RESTful APIs},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jean Yang: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Harald C. Gall : [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Harald C. Gall after removed: [@article{Pinzger2008,
   abstract = {Many program comprehension tools use graphs to visualize and analyze source code. The main issue is that existing approaches create graphs overloaded with too much information. Graphs contain hundreds of nodes and even more edges that cross each other. Understanding these graphs and using them for a given program comprehension task is tedious, and in the worst case developers stop using the tools. In this paper we present D A4 Java, a graphbased approach for visualizing and analyzing static dependencies between Java source code entities. The main contribution of DA4Java is a set of features to incrementully compose graphs and remove irrelevant nodes and edges from graphs. This leads to graphs that contain significantly fewer nodes and edges and need less effort to understand. © 2008 IEEE.},
   author = {Martin Pinzger and Katja Gräfenhain and Patrick Knab and Harald C. Gall},
   doi = {10.1109/ICPC.2008.23},
   journal = {IEEE International Conference on Program Comprehension},
   title = {A tool for visual understanding of source code dependencies},
   year = {2008},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Harald C. Gall: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Henny B. Sipma : [@article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Henny B. Sipma after removed: [@article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Henny B. Sipma: Constraint ProgrammingGröbner BasesIdealsInvariant GenerationProgram AnalysisSymbolic ComputationVerification
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Informatics Head : [@article{Head2014,
   author = {Informatics Head},
   title = {Analysis and Methods for Supporting Generative Metaprogramming in Large Scale C ++ Projects},
   year = {2014},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Informatics Head after removed: [@article{Head2014,
   author = {Informatics Head},
   title = {Analysis and Methods for Supporting Generative Metaprogramming in Large Scale C ++ Projects},
   year = {2014},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Informatics Head: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Dillig : [@article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Dillig after removed: [@article{Dillig2010,
   abstract = {Many relational static analysis techniques for precise reasoning about heap contents perform an explicit case analysis of all possible heaps that can arise. We argue that such precise relational reasoning can be obtained in a more scalable and economical way by enforcing the memory invariant that every concrete memory location stores one unique value directly on the heap abstraction. Our technique combines the strengths of analyses for precise reasoning about heap contents with approaches that prioritize axiomatization of memory invariants, such as the theory of arrays. Furthermore, by avoiding an explicit case analysis, our technique is scalable and powerful enough to analyze real-world programs with intricate use of arrays and pointers; in particular, we verify the absence of buffer overruns, incorrect casts, and null pointer dereferences in OpenSSH (over 26,000 lines of code) after fixing 4 previously undiscovered bugs found by our system. Our experiments also show that the combination of reasoning about heap contents and enforcing existence and uniqueness invariants is crucial for this level of precision. },
   author = {Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1145/1932682.1869493},
   journal = {ACM SIGPLAN Notices},
   keywords = {Array analysis,Heap analysis,Memory invariants,Relational static analysis},
   title = {Symbolic heap abstraction with demand-driven axiomatization of memory invariants},
   year = {2010},
}
, @article{Sharma2011,
   abstract = {We present a novel static analysis technique that substantially improves the quality of invariants inferred by standard loop invariant generation techniques. Our technique decomposes multi-phase loops, which require disjunctive invariants, into a semantically equivalent sequence of single-phase loops, each of which requires simple, conjunctive invariants. We define splitter predicates which are used to identify phase transitions in loops, and we present an algorithm to find useful splitter predicates that enable the phase-reducing transformation. We show experimentally on a set of representative benchmarks from the literature and real code examples that our technique substantially increases the quality of invariants inferred by standard invariant generation techniques. Our technique is conceptually simple, easy to implement, and can be integrated into any automatic loop invariant generator.},
   author = {Rahul Sharma and Isil Dillig and Thomas Dillig and Alex Aiken},
   doi = {10.1007/978-3-642-22110-1_57},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Static analysis,decomposition of multi-phase loops,invariant generation},
   title = {Simplifying loop invariant generation using splitter predicates},
   year = {2011},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thomas Dillig: Array analysisHeap analysisMemory invariantsRelational static analysisStatic analysisdecomposition of multi-phase loopsinvariant generation
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yang Liu : [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Yang Liu after removed: [@article{Xie2016,
   abstract = {Loops are challenging structures for program analysis, especial-ly when loops contain multiple paths with complex interleaving executions among these paths. In this paper, we first propose a classification of multi-path loops to understand the complexity of the loop execution, which is based on the variable updates on the loop conditions and the execution order of the loop paths. Second-ly, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects on the variables. The key contribution is to use a path dependency automaton (PDA) to capture the execution dependency between the paths. A DFS-based algorithm is proposed to traverse the PDA to summarize the effect for all feasible executions in the loop. The experimental results show that Proteus is effective in three applications: Proteus can 1) compute a more precise bound than the existing loop bound analysis techniques; 2) significantly outperform state-of-the-art tools for loop verification; and 3) generate test cases for deep loops within one second, while KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1145/2950290.2950340},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Disjunctive Summary,Loop Summarization},
   title = {Proteus: Computing disjunctive loop summary via path dependency analysis},
   year = {2016},
}
, @article{Xie2015,
   abstract = {? 2015 ACM.Loops are important yet most challenging program constructs to analyze for various program analysis tasks. Existing loop analysis techniques mainly handle well loops that contain only integer variables with a single path in the loop body. The key challenge in summarizing a multiple-path loop is that a loop traversal can yield a large number of possibilities due to the different execution orders of these paths located in the loop; when a loop contains a conditional branch related to string content, we potentially need to track every character in the string for loop summarization, which is expensive. In this paper, we propose an approach, named S-Looper, to automatically summarize a type of loops related to a string traversal. This type of loops can contain multiple paths, and the branch conditions in the loop can be related to string content. Our approach is to identify patterns of the string based on the branch conditions along each path in the loop. Based on such patterns, we then generate a loop summary that describes the path conditions of a loop traversal as well as the symbolic values of each variable at the exit of a loop. Combined with vulnerability conditions, we are thus able to generate test inputs that traverse a loop in a specific way and lead to exploitation. Our experiments show that handling such string loops can largely improve the buffer overflow detection capabilities of the existing symbolic analysis tool. We also compared our techniques with KLEE and PEX, and show that we can generate test inputs more effectively and efficiently.},
   author = {Xiaofei Xie and Yang Liu and Wei Le and Xiaohong Li and Hongxu Chen},
   doi = {10.1145/2771783.2771815},
   journal = {2015 International Symposium on Software Testing and Analysis, ISSTA 2015 - Proceedings},
   keywords = {Loop summarization,String constraints,Symbolic execution},
   title = {S-Looper: Automatic summarization for multipath string loops},
   year = {2015},
}
, @article{Xie2019,
   abstract = {Analyzing loops is very important for various software engineering tasks such as bug detection, test case generation and program optimization. However, loops are very challenging structures for program analysis, especially when (nested) loops contain multiple paths that have complex interleaving relationships. In this paper, we propose the path dependency automaton (PDA) to capture the dependencies among the multiple paths in a loop. Based on the PDA, we first propose a loop classification to understand the complexity of loop summarization. Then, we propose a loop analysis framework, named Proteus, which takes a loop program and a set of variables of interest as inputs and summarizes path-sensitive loop effects (i.e., disjunctive loop summary) on the variables of interest. An algorithm is proposed to traverse the PDA to summarize the effect for all possible executions in the loop. We have evaluated Proteus using loops from five open-source projects and two well-known benchmarks and applying the disjunctive loop summary to three applications: loop bound analysis, program verification and test case generation. The evaluation results have demonstrated that Proteus can compute a more precise bound than the existing loop bound analysis techniques; Proteus can significantly outperform the state-of-the-art tools for loop program verification; and Proteus can help generate test cases for deep loops within one second, while symbolic execution tools KLEE and Pex either need much more time or fail.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Yang Liu and Wei Le and Xiaohong Li},
   doi = {10.1109/TSE.2017.2788018},
   journal = {IEEE Transactions on Software Engineering},
   keywords = {Disjunctive loop summary,path dependency automaton,path interleaving},
   title = {Automatic Loop Summarization via Path Dependency Analysis},
   year = {2019},
}
, @article{Xie2017,
   abstract = {Loop termination is an important problem for proving the correctness of a system and ensuring that the system always reacts. Existing loop termination analysis techniques mainly depend on the synthesis of ranking functions, which is often expensive. In this paper, we present a novel approach, named Loopster, which performs an efficient static analysis to decide the termination for loops based on path termination analysis and path dependency reasoning. Loopster adopts a divide-and-conquer approach: (1) we extract individual paths from a target multi-path loop and analyze the termination of each path, (2) analyze the dependencies between each two paths, and then (3) determine the overall termination of the target loop based on the relations among paths. We evaluate Loopster by applying it on the loop termination competition benchmark and three real-world projects. The results show that Loopster is effective in a majority of loops with better accuracy and 20 ×+ performance improvement compared to the state-of-the-art tools.},
   author = {Xiaofei Xie and Bihuan Chen and Liang Zou and Shang Wei Lin and Yang Liu and Xiaohong Li},
   doi = {10.1145/3106237.3106260},
   journal = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
   keywords = {Loop termination,Path dependency automaton,Reachability},
   title = {Loopster: Static loop termination analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Yang Liu: Disjunctive SummaryLoop SummarizationLoop summarizationString constraintsSymbolic executionDisjunctive loop summarypath dependency automatonpath interleavingLoop terminationPath dependency automatonReachability
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of N. Riva : [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of N. Riva after removed: [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of N. Riva: abstract interpretationautomatic program verificationprogram logic
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jiaxiao Zhou : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Jiaxiao Zhou after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Jiaxiao Zhou: Abstract InterpretationProgram SynthesisType Systems
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Ball : [@article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Thomas Ball after removed: [@article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Thomas Ball: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Manu Sridharan : [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Manu Sridharan after removed: [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Manu Sridharan: Ami snipingAutovalueBuilder patternLightweight verificationLombokPluggable type systemsTypestatefinite-state property
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lukáš Holík : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Lukáš Holík after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Lukáš Holík: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mark Santolucito : [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Mark Santolucito after removed: [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Mark Santolucito: Pro-gram SynthesisReactive SynthesisSyntax-Guided Synthesis
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Siddharth Krishna : [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Siddharth Krishna after removed: [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Siddharth Krishna: 
Similarity = 0.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Fabien Coelho : [@article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Paper List of Y after removed: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Fabien Coelho after removed: [@article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Keywords of Y: Algorithm design and analysisAssemblyConferencesFlow graphsHeuristic algorithmsLawLegal factorsMergingPartitioning algorithmsSufficient conditions
Keywords of Fabien Coelho: Abstract interpretationfixed point computationloop invariant
Similarity = 100.0


Paper List of Y: [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of M. Martel : [@article{Martel2003,
   abstract = {Many static analyses aim at assigning to each control point of a program an invariant property that characterizes any state of a trace corresponding to this point. The choice of the set of control points determines the states of an execution trace for which a common property must be found. We focus on sufficient conditions to substitute one control flow graph for another during an analysis. Next, we introduce a dynamic partitioning algorithm that improves the precision of the calculated invariants by deciding dynamically how to map the states of the traces to the control points, depending on the properties resulting from the first steps of the analysis. In particular, this algorithm enables the loops to be unfolded only if this improves the precision of the final invariants. Its correctness stems from the fact that it uses legal graph substitutions.},
   author = {M. Martel},
   doi = {10.1109/SCAM.2003.1238027},
   journal = {Proceedings - 3rd IEEE International Workshop on Source Code Analysis and Manipulation, SCAM 2003},
   keywords = {Algorithm design and analysis,Assembly,Conferences,Flow graphs,Heuristic algorithms,Law,Legal factors,Merging,Partitioning algorithms,Sufficient conditions},
   title = {Improving the static analysis of loops by dynamic partitioning techniques},
   year = {2003},
}
]
Paper List of Y after removed: []
Paper List of M. Martel after removed: []
Keywords of Y: 
Keywords of M. Martel: 
Similarity = 0.0


Paper List of Y: []
Paper List of Sam Tobin-Hochstadt : [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Sam Tobin-Hochstadt after removed: [@article{Spall2020,
   abstract = {Build scripts for most build systems describe the actions to run, and the dependencies between those actions - but often build scripts get those dependencies wrong. Most build scripts have both too few dependencies (leading to incorrect build outputs) and too many dependencies (leading to excessive rebuilds and reduced parallelism). Any programmer who has wondered why a small change led to excess compilation, or who resorted to a clean step, has suffered the ill effects of incorrect dependency specification. We outline a build system where dependencies are not specified, but instead captured by tracing execution. The consequence is that dependencies are always correct by construction and build scripts are easier to write. The simplest implementation of our approach would lose parallelism, but we are able to recover parallelism using speculation.},
   author = {Sarah Spall and Neil Mitchell and Sam Tobin-Hochstadt},
   doi = {10.1145/3428237},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {build systems,functional programming},
   title = {Build scripts with perfect dependencies},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Sam Tobin-Hochstadt: build systemsfunctional programming
Similarity = 0.0


Paper List of Y: []
Paper List of Francesco Ranzato : [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Francesco Ranzato after removed: [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Francesco Ranzato: 
Similarity = 0.0


Paper List of Y: []
Paper List of Anonymous Author : [@article{Author2018,
   abstract = {In the past decades, many software manufacturers have failed to adopt security patches timely because more and more vulnerabili-ties and bugs were discovered. To detect the unpatched binaries as soon as possible, both signature-based patch presence tests (SPPT) and software similarity based patch presence tests (SSPPT) have been proposed to check whether a certain patch has been applied to a released software binary. However, SPPTs only analyze function changes. Therefore, they cannot be applied to detect a large number of bug-fixing patches that are small in size and only modify function-irrelevant program elements. Meanwhile, SSPPT tools cannot precisely determine the presence of patches either due to the small size of patches.In this work, we propose PPTFI, a patch presence test for function-irrelevant patches. PPTFI first understands the function-irrelevant patches and then carefully extracts the code information and data information as patch signatures, which are later used to scan the target binaries. We have evaluated PPTFI over 62 different versions of 31 real-world function-irrelevant patches and 512 binaries in 16 different compilation environments, and the results show that PPFTI achieved the accuracy of 77.54%, whereas the state-of-the-art SPPT tools such as Fiber and BinXray cannot understand any of the function-irrelevant patches. Experimented on x86_64 platforms, PPTFI increases the accuracy of the state-of-the-art SSPPT tool, B2SFinder, by 13.79%.},
   author = {Anonymous Author},
   keywords = {patch presence test,patch semantics},
   title = {PPTFI: Patch Presence Test for Function-Irrelevant Patches},
   year = {2018},
   url = {https://doi.org/XXXXXXX.XXXXXXX},
}
, @article{Author2022,
   abstract = {The execution of smart contracts on the Ethereum blockchain consumes gas paid for by users submitting contracts' invocation requests. A contract execution proceeds as long as the users dedicate enough gas, within the limit set by Ethereum. If insufficient gas is provided, the contract execution halts and changes made during execution get reverted. Unfortunately, contracts may contain code patterns that increase execution cost, causing the contracts to run out of gas. These patterns can be manipulated by malicious attackers to induce unwanted behavior in the targeted victim contracts, e.g., Denial-of-Service (DoS) attacks. We call these gas-related vul-nerabilities. We propose eTainter, a static analyzer for detecting gas-related vulnerabilities based on taint tracking in the bytecode of smart contracts. We evaluate eTainter by comparing it with the prior work, MadMax, on a dataset of annotated contracts. The results show that eTainter outperforms MadMax in both precision and recall, and that eTainter has a precision of 90% based on manual inspection. We also use eTainter to perform large-scale analysis of 60,612 real-world contracts on the Ethereum blockchain. We find that gas-related vulnerabilities exist in 2,763 of these contracts, and that eTainter analyzes a contract in eight seconds, on average. CCS CONCEPTS • Security and privacy → Software and application security;},
   author = {Anonymous Author},
   doi = {10.1145/3533767.3534378},
   keywords = {Ethereum,Ethereum security,Solidity,taint analysis},
   title = {eTainter: Detecting Gas-Related Vulnerabilities in Smart Contracts},
   year = {2022},
   url = {https://doi.org/10.1145/3533767.3534378},
}
]
Paper List of Y after removed: []
Paper List of Anonymous Author after removed: [@article{Author2018,
   abstract = {In the past decades, many software manufacturers have failed to adopt security patches timely because more and more vulnerabili-ties and bugs were discovered. To detect the unpatched binaries as soon as possible, both signature-based patch presence tests (SPPT) and software similarity based patch presence tests (SSPPT) have been proposed to check whether a certain patch has been applied to a released software binary. However, SPPTs only analyze function changes. Therefore, they cannot be applied to detect a large number of bug-fixing patches that are small in size and only modify function-irrelevant program elements. Meanwhile, SSPPT tools cannot precisely determine the presence of patches either due to the small size of patches.In this work, we propose PPTFI, a patch presence test for function-irrelevant patches. PPTFI first understands the function-irrelevant patches and then carefully extracts the code information and data information as patch signatures, which are later used to scan the target binaries. We have evaluated PPTFI over 62 different versions of 31 real-world function-irrelevant patches and 512 binaries in 16 different compilation environments, and the results show that PPFTI achieved the accuracy of 77.54%, whereas the state-of-the-art SPPT tools such as Fiber and BinXray cannot understand any of the function-irrelevant patches. Experimented on x86_64 platforms, PPTFI increases the accuracy of the state-of-the-art SSPPT tool, B2SFinder, by 13.79%.},
   author = {Anonymous Author},
   keywords = {patch presence test,patch semantics},
   title = {PPTFI: Patch Presence Test for Function-Irrelevant Patches},
   year = {2018},
   url = {https://doi.org/XXXXXXX.XXXXXXX},
}
, @article{Author2022,
   abstract = {The execution of smart contracts on the Ethereum blockchain consumes gas paid for by users submitting contracts' invocation requests. A contract execution proceeds as long as the users dedicate enough gas, within the limit set by Ethereum. If insufficient gas is provided, the contract execution halts and changes made during execution get reverted. Unfortunately, contracts may contain code patterns that increase execution cost, causing the contracts to run out of gas. These patterns can be manipulated by malicious attackers to induce unwanted behavior in the targeted victim contracts, e.g., Denial-of-Service (DoS) attacks. We call these gas-related vul-nerabilities. We propose eTainter, a static analyzer for detecting gas-related vulnerabilities based on taint tracking in the bytecode of smart contracts. We evaluate eTainter by comparing it with the prior work, MadMax, on a dataset of annotated contracts. The results show that eTainter outperforms MadMax in both precision and recall, and that eTainter has a precision of 90% based on manual inspection. We also use eTainter to perform large-scale analysis of 60,612 real-world contracts on the Ethereum blockchain. We find that gas-related vulnerabilities exist in 2,763 of these contracts, and that eTainter analyzes a contract in eight seconds, on average. CCS CONCEPTS • Security and privacy → Software and application security;},
   author = {Anonymous Author},
   doi = {10.1145/3533767.3534378},
   keywords = {Ethereum,Ethereum security,Solidity,taint analysis},
   title = {eTainter: Detecting Gas-Related Vulnerabilities in Smart Contracts},
   year = {2022},
   url = {https://doi.org/10.1145/3533767.3534378},
}
]
Keywords of Y: 
Keywords of Anonymous Author: patch presence testpatch semanticsEthereumEthereum securitySoliditytaint analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Stephen Tu : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Stephen Tu after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Stephen Tu: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Asia Slowinska : [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Paper List of Y after removed: []
Paper List of Asia Slowinska after removed: [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Keywords of Y: 
Keywords of Asia Slowinska: Data structuresDynamic binary analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Manli Ran : [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Manli Ran after removed: [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Manli Ran: Ami snipingAutovalueBuilder patternLightweight verificationLombokPluggable type systems
Similarity = 0.0


Paper List of Y: []
Paper List of Antoine Miné : [@article{Jeannet2009,
   abstract = {This article describes Apron, a freely available library dedi- cated to the static analysis of the numerical variables of programs by ab- stract interpretation. Its goal is threefold: provide analysis implementers with ready-to-use numerical abstractions under a unified API, encour- age the research in numerical abstract domains by providing a platform for integration and comparison, and provide teaching and demonstration tools to disseminate knowledge on abstract interpretation.},
   author = {Bertrand Jeannet and Antoine Miné},
   doi = {10.1007/978-3-642-02658-4_52},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Apron: A library of numerical abstract domains for static analysis},
   year = {2009},
}
]
Paper List of Y after removed: []
Paper List of Antoine Miné after removed: [@article{Jeannet2009,
   abstract = {This article describes Apron, a freely available library dedi- cated to the static analysis of the numerical variables of programs by ab- stract interpretation. Its goal is threefold: provide analysis implementers with ready-to-use numerical abstractions under a unified API, encour- age the research in numerical abstract domains by providing a platform for integration and comparison, and provide teaching and demonstration tools to disseminate knowledge on abstract interpretation.},
   author = {Bertrand Jeannet and Antoine Miné},
   doi = {10.1007/978-3-642-02658-4_52},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Apron: A library of numerical abstract domains for static analysis},
   year = {2009},
}
]
Keywords of Y: 
Keywords of Antoine Miné: 
Similarity = 0.0


Paper List of Y: []
Paper List of Ying Zhang : [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Ying Zhang after removed: [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Ying Zhang: Build systemBypath compilationIncremental build
Similarity = 0.0


Paper List of Y: []
Paper List of Ondřej Lengál : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Ondřej Lengál after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Ondřej Lengál: 
Similarity = 0.0


Paper List of Y: []
Paper List of George Fourtounis : [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of George Fourtounis after removed: [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Keywords of Y: 
Keywords of George Fourtounis: Heap SnapshotsProgram AnalysisScalability
Similarity = 0.0


Paper List of Y: []
Paper List of Tomáš Vojnar : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Tomáš Vojnar after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Tomáš Vojnar: 
Similarity = 0.0


Paper List of Y: []
Paper List of Guolong Zheng : [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Guolong Zheng after removed: [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Guolong Zheng: Dynamic invariant analysisSeparation logic
Similarity = 0.0


Paper List of Y: []
Paper List of Shengchao Qin : [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Paper List of Y after removed: []
Paper List of Shengchao Qin after removed: [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Keywords of Y: 
Keywords of Shengchao Qin: AbstractionCombining analysisFixpoint analysisLoop invariantNumerical analysisSeparation logicShape analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Woosuk Lee : [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Woosuk Lee after removed: [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Woosuk Lee: Domain-specific languagesStatistical methodsSynthesisTransfer learning
Similarity = 0.0


Paper List of Y: []
Paper List of Mengzhu Sun : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: []
Paper List of Mengzhu Sun after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: 
Keywords of Mengzhu Sun: 
Similarity = 0.0


Paper List of Y: []
Paper List of Damien Zufferey : [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
]
Paper List of Y after removed: []
Paper List of Damien Zufferey after removed: [@article{Piskac2014,
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-319-08867-9_47},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Automating separation logic with trees and data},
   year = {2014},
}
, @article{Piskac2013,
   abstract = {Separation logic (SL) has gained widespread popularity because of its ability to succinctly express complex invariants of a program's heap con-figurations. Several specialized provers have been developed for decidable SL fragments. However, these provers cannot be easily extended or combined with solvers for other theories that are important in program verification, e.g., linear arithmetic. In this paper, we present a reduction of decidable SL fragments to a decidable first-order theory that fits well into the satisfiability modulo theories (SMT) framework. We show how to use this reduction to automate satisfiability, entailment, frame inference, and abduction problems for separation logic using SMT solvers. Our approach provides a simple method of integrating separation logic into existing verification tools that provide SMT backends, and an elegant way of combining SL fragments with other decidable first-order theories. We im-plemented this approach in a verification tool and applied it to heap-manipulating programs whose verification involves reasoning in theory combinations.},
   author = {Ruzica Piskac and Thomas Wies and Damien Zufferey},
   doi = {10.1007/978-3-642-39799-8_54},
   journal = {Cav},
   title = {Automating Separation Logic Using SMT (Technical Report)},
   year = {2013},
}
]
Keywords of Y: 
Keywords of Damien Zufferey: 
Similarity = 0.0


Paper List of Y: []
Paper List of Brian Hackett : [@article{Hackett2005,
   abstract = {This paper proposes a novel approach to shape analysis: using local reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the smaller granularity of the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses.We also show that the analysis can be used to enable the static detection of memory errors in programs with explicit deallocation. We have built a prototype tool that detects memory leaks and accesses through dangling pointers in C programs. The experiments indicate that the analysis is sufficiently precise to detect errors with low false positive rates; and is sufficiently lightweight to scale to larger programs. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less than 2 minutes and has produced 97 warnings, 38 of which were actual errors.},
   author = {Brian Hackett and Radu Rugina},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Memory leaks,Memory management,Shape analysis,Static error detection},
   title = {Region-based shape analysis with tracked locations},
   year = {2005},
}
]
Paper List of Y after removed: []
Paper List of Brian Hackett after removed: [@article{Hackett2005,
   abstract = {This paper proposes a novel approach to shape analysis: using local reasoning about individual heap locations instead of global reasoning about entire heap abstractions. We present an inter-procedural shape analysis algorithm for languages with destructive updates. The key feature is a novel memory abstraction that differs from traditional abstractions in two ways. First, we build the shape abstraction and analysis on top of a pointer analysis. Second, we decompose the shape abstraction into a set of independent configurations, each of which characterizes one single heap location. Our approach: 1) leads to simpler algorithm specifications, because of local reasoning about the single location; 2) leads to efficient algorithms, because of the smaller granularity of the abstraction; and 3) makes it easier to develop context-sensitive, demand-driven, and incremental shape analyses.We also show that the analysis can be used to enable the static detection of memory errors in programs with explicit deallocation. We have built a prototype tool that detects memory leaks and accesses through dangling pointers in C programs. The experiments indicate that the analysis is sufficiently precise to detect errors with low false positive rates; and is sufficiently lightweight to scale to larger programs. For a set of three popular C programs, the tool has analyzed about 70K lines of code in less than 2 minutes and has produced 97 warnings, 38 of which were actual errors.},
   author = {Brian Hackett and Radu Rugina},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Memory leaks,Memory management,Shape analysis,Static error detection},
   title = {Region-based shape analysis with tracked locations},
   year = {2005},
}
]
Keywords of Y: 
Keywords of Brian Hackett: Memory leaksMemory managementShape analysisStatic error detection
Similarity = 0.0


Paper List of Y: []
Paper List of Vivien Maisonneuve : [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
]
Paper List of Y after removed: []
Paper List of Vivien Maisonneuve after removed: [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
]
Keywords of Y: 
Keywords of Vivien Maisonneuve: abstract interpretationautomatic invariant detectionbenchmarklinear relation analysisloop invariantmodel checkingstatic program analysistransformer
Similarity = 0.0


Paper List of Y: []
Paper List of Gogul Balakrishnan : [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Paper List of Y after removed: []
Paper List of Gogul Balakrishnan after removed: [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
]
Keywords of Y: 
Keywords of Gogul Balakrishnan: Abstract interpretationLoop refinementModel checkingPath-sensitive analysisProgram understandingProgram verificationStatic analysisSynchronous sytems
Similarity = 0.0


Paper List of Y: []
Paper List of Dominik Steenken : [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
, @article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Paper List of Y after removed: []
Paper List of Dominik Steenken after removed: [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
, @article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Keywords of Y: 
Keywords of Dominik Steenken: Graph TransformationShape AnalysisThree-Vaued LogicGraph TransformationShape AnalysisThree-Vaued Logic
Similarity = 0.0


Paper List of Y: []
Paper List of Parosh Aziz Abdulla : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Parosh Aziz Abdulla after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Parosh Aziz Abdulla: 
Similarity = 0.0


Paper List of Y: []
Paper List of Alex Warshavsky : [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Paper List of Y after removed: []
Paper List of Alex Warshavsky after removed: [@article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Keywords of Y: 
Keywords of Alex Warshavsky: Abstract interpretationModel checkingPredicate abstractionSoftware componentsStatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Mae Milano : [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Paper List of Y after removed: []
Paper List of Mae Milano after removed: [@article{Laddad2022,
   abstract = {<p>Conflict-free replicated data types (CRDTs) are a promising tool for designing scalable, coordination-free distributed systems. However, constructing correct CRDTs is difficult, posing a challenge for even seasoned developers. As a result, CRDT development is still largely the domain of academics, with new designs often awaiting peer review and a manual proof of correctness. In this paper, we present Katara, a program synthesis-based system that takes sequential data type implementations and automatically synthesizes verified CRDT designs from them. Key to this process is a new formal definition of CRDT correctness that combines a reference sequential type with a lightweight ordering constraint that resolves conflicts between non-commutative operations. Our process follows the tradition of work in verified lifting, including an encoding of correctness into SMT logic using synthesized inductive invariants and hand-crafted grammars for the CRDT state and runtime. Katara is able to automatically synthesize CRDTs for a wide variety of scenarios, from reproducing classic CRDTs to synthesizing novel designs based on specifications in existing literature. Crucially, our synthesized CRDTs are fully, automatically verified, eliminating entire classes of common errors and reducing the process of producing a new CRDT from a painstaking paper proof of correctness to a lightweight specification.</p>},
   author = {Shadaj Laddad and Conor Power and Mae Milano and Alvin Cheung and Joseph M. Hellerstein},
   doi = {10.1145/3563336},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {Katara: synthesizing CRDTs with verified lifting},
   year = {2022},
   url = {https://dl.acm.org/doi/10.1145/3563336},
}
]
Keywords of Y: 
Keywords of Mae Milano: 
Similarity = 0.0


Paper List of Y: []
Paper List of Bernd Finkbeiner : [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Paper List of Y after removed: []
Paper List of Bernd Finkbeiner after removed: [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Keywords of Y: 
Keywords of Bernd Finkbeiner: Pro-gram SynthesisReactive SynthesisSyntax-Guided Synthesis
Similarity = 0.0


Paper List of Y: []
Paper List of David Grove : [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Paper List of Y after removed: []
Paper List of David Grove after removed: [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Keywords of Y: 
Keywords of David Grove: 
Similarity = 0.0


Paper List of Y: []
Paper List of Wonhyuk Choi : [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Paper List of Y after removed: []
Paper List of Wonhyuk Choi after removed: [@article{Choi2022,
   abstract = {While reactive synthesis and syntax-guided synthesis (Sy-GuS) have seen enormous progress in recent years, combining the two approaches has remained a challenge. In this work, we present the synthesis of reactive programs from Temporal Stream Logic modulo theories (TSL-MT), a framework that unites the two approaches to synthesize a single program. In our approach, reactive synthesis and SyGuS collaborate in the synthesis process, and generate executable code that implements both reactive and data-level properties. We present a tool, temos, that combines state-of-the-art methods in reactive synthesis and SyGuS to synthesize programs from TSL-MT specifications. We demonstrate the applicability of our approach over a set of benchmarks, and present a deep case study on synthesizing a music keyboard synthesizer. CCS Concepts: • Theory of computation → Modal and temporal logics.},
   author = {Wonhyuk Choi and Bernd Finkbeiner and Ruzica Piskac and Mark Santolucito},
   doi = {10.1145/3519939.3523429},
   keywords = {Pro-gram Synthesis,Reactive Synthesis,Syntax-Guided Synthesis},
   title = {Can Reactive Synthesis and Syntax-Guided Synthesis Be Friends?},
   year = {2022},
   url = {https://doi.org/10.1145/3519939.3523429},
}
]
Keywords of Y: 
Keywords of Wonhyuk Choi: Pro-gram SynthesisReactive SynthesisSyntax-Guided Synthesis
Similarity = 0.0


Paper List of Y: []
Paper List of Bence Babati : [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
, @article{Babati2017,
   author = {Bence Babati and Norbert Pataki},
   doi = {10.15439/2017f358},
   journal = {Communiation Papers of the 2017 Federated Conference on Computer Science and Information Systems},
   title = {Analysis of Include Dependencies in C++ Source Code},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Bence Babati after removed: [@article{Babati2016,
   author = {Bence Babati and Norbert Pataki and Zoltán Porkoláb},
   doi = {10.1109/Informatics.2015.7377804},
   journal = {2015 IEEE 13th International Scientific Conference on Informatics, INFORMATICS 2015 - Proceedings},
   title = {C/C++ Preprocessing with modern data storage devices},
   year = {2016},
}
, @article{Babati2017,
   author = {Bence Babati and Norbert Pataki},
   doi = {10.15439/2017f358},
   journal = {Communiation Papers of the 2017 Federated Conference on Computer Science and Information Systems},
   title = {Analysis of Include Dependencies in C++ Source Code},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Bence Babati: 
Similarity = 0.0


Paper List of Y: []
Paper List of Xiaoxuan Liu : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: []
Paper List of Xiaoxuan Liu after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: 
Keywords of Xiaoxuan Liu: 
Similarity = 0.0


Paper List of Y: []
Paper List of Marc Brockschmidt : [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Marc Brockschmidt after removed: [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Marc Brockschmidt: 
Similarity = 0.0


Paper List of Y: []
Paper List of Shachar Itzhaky : [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Shachar Itzhaky after removed: [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Shachar Itzhaky: Loop SummarisationOptimisationRefactoringStringsSymbolic ExecutionSynthesis
Similarity = 0.0


Paper List of Y: []
Paper List of Mark Marron : [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Paper List of Y after removed: []
Paper List of Mark Marron after removed: [@article{Marron2008,
   abstract = {The performance of heap analysis techniques has a significant impact on their utility in an optimizing compiler.Most shape analysis techniques perform interprocedural dataflow analysis in a context-sensitive manner, which can result in analyzing each procedure body many times (causing significant increases in runtime even if the analysis results are memoized). To improve the effectiveness of memoization (and thus speed up the analysis) project/extend operations are used to remove portions of the heap model that cannot be affected by the called procedure (effectively reducing the number of different contexts that a procedure needs to be analyzed with). This paper introduces project/extend operations that are capable of accurately modeling properties that are important when analyzing non-trivial programs (sharing, nullity information, destructive recursive functions, and composite data structures). The techniques we introduce are able to handle these features while significantly improving the effectiveness of memoizing analysis results (and thus improving analysis performance). Using a range of well known benchmarks (many of which have not been successfully analyzed using other existing shape analysis methods) we demonstrate that our approach results in significant improvements in both accuracy and efficiency over a baseline analysis.},
   author = {Mark Marron and Manuel Hermenegildo and Deepak Kapur and Darko Stefanovic},
   doi = {10.1007/978-3-540-78791-4_17},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Efficient context-sensitive shape analysis with graph based heap models},
   year = {2008},
}
]
Keywords of Y: 
Keywords of Mark Marron: 
Similarity = 0.0


Paper List of Y: []
Paper List of R. Ullio : [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of R. Ullio after removed: [@article{Ullio2012,
   abstract = {These are the notes to accompany a course at the Marktoberdorf PhD summer school in 2011. The course consists of an introduction to separation logic, with a slant towards its use in automatic program verification and analysis.},
   author = {R. Ullio and N. Riva and P. Pellegrino and P. Deloo},
   journal = {European Space Agency, (Special Publication) ESA SP},
   keywords = {abstract interpretation,automatic program verification,program logic},
   title = {LSD (Landing system development) impact simulation},
   year = {2012},
}
]
Keywords of Y: 
Keywords of R. Ullio: abstract interpretationautomatic program verificationprogram logic
Similarity = 0.0


Paper List of Y: []
Paper List of Ranjit Jhala : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Ranjit Jhala after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Ranjit Jhala: Abstract InterpretationProgram SynthesisType SystemsHuman-Computer InteractionProgram SynthesisType Inference
Similarity = 0.0


Paper List of Y: []
Paper List of Earl T. Barr : [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Earl T. Barr after removed: [@article{Dash2018,
   abstract = {Source code is bimodal: it combines a formal, algorithmic channel and a natural language channel of identiiers and comments. In this work, we model the bimodality of code with name lows, an assignment low graph augmented to track identiier names. Conceptual types are logically distinct types that do not always coincide with program types. Passwords and URLs are example conceptual types that can share the program type string. Our tool, RefiNym, is an unsupervised method that mines a lattice of conceptual types from name lows and reiies them into distinct nominal types. For string, RefiNym inds and splits conceptual types originally merged into a single type, reducing the number of same-type variables per scope from 8.7 to 2.2 while eliminating 21.9% of scopes that have more than one same-type variable in scope. This makes the code more self-documenting and frees the type system to prevent a developer from inadvertently assigning data across conceptual types. CCS CONCEPTS · Software and its engineering → Data types and structures;},
   author = {Santanu Kumar Dash and Miltiadis Allamanis and Earl T. Barr},
   doi = {10.1145/3236024.3236042},
   journal = {ESEC/FSE 2018 - Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
   keywords = {Information-theoretic Clustering,Type Reinement},
   title = {RefiNym: Using names to refine types},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Earl T. Barr: Information-theoretic ClusteringType Reinement
Similarity = 0.0


Paper List of Y: []
Paper List of Michael D. Ernst : [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Paper List of Y after removed: []
Paper List of Michael D. Ernst after removed: [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Keywords of Y: 
Keywords of Michael D. Ernst: Ami snipingAutovalueBuilder patternLightweight verificationLombokPluggable type systemsTypestatefinite-state property
Similarity = 0.0


Paper List of Y: []
Paper List of Chenguang Luo : [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Paper List of Y after removed: []
Paper List of Chenguang Luo after removed: [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Keywords of Y: 
Keywords of Chenguang Luo: AbstractionCombining analysisFixpoint analysisLoop invariantNumerical analysisSeparation logicShape analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Yi Li : [@article{Li2012,
   author = {Yi Li},
   doi = {10.3724/SP.J.1001.2012.03982},
   journal = {Ruan Jian Xue Bao/Journal of Software},
   keywords = {DISCOVERER,Nonlinear loop,Termination analysis,Trustworthy computing},
   title = {Termination analysis of nonlinear loops},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Yi Li after removed: [@article{Li2012,
   author = {Yi Li},
   doi = {10.3724/SP.J.1001.2012.03982},
   journal = {Ruan Jian Xue Bao/Journal of Software},
   keywords = {DISCOVERER,Nonlinear loop,Termination analysis,Trustworthy computing},
   title = {Termination analysis of nonlinear loops},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Yi Li: DISCOVERERNonlinear loopTermination analysisTrustworthy computing
Similarity = 0.0


Paper List of Y: []
Paper List of Zohar Manna : [@article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
]
Paper List of Y after removed: []
Paper List of Zohar Manna after removed: [@article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
]
Keywords of Y: 
Keywords of Zohar Manna: Constraint ProgrammingGröbner BasesIdealsInvariant GenerationProgram AnalysisSymbolic ComputationVerification
Similarity = 0.0


Paper List of Y: []
Paper List of Orna Kupferman : [@article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Paper List of Y after removed: []
Paper List of Orna Kupferman after removed: [@article{Ball2007,
   author = {Thomas Ball and Orna Kupferman and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Leaping loops in the presence of abstraction},
   year = {2007},
}
]
Keywords of Y: 
Keywords of Orna Kupferman: 
Similarity = 0.0


Paper List of Y: []
Paper List of Peter W. O'Hearn : [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Peter W. O'Hearn after removed: [@article{Gorogiannis2019,
   abstract = {RacerD is a static race detector that has been proven to be effective in engineering practice: it has seen thousands of data races fixed by developers before reaching production, and has supported the migration of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture. We prove a True Positives Theorem stating that, under certain assumptions, an idealized theoretical version of the analysis never reports a false positive. We also provide an empirical evaluation of an implementation of this analysis, versus the original RacerD. The theorem was motivated in the first case by the desire to understand the observation from production that RacerD was providing remarkably accurate signal to developers, and then the theorem guided further analyzer design decisions. Technically, our result can be seen as saying that the analysis computes an under-approximation of an over-approximation, which is the reverse of the more usual (over of under) situation in static analysis. Until now, static analyzers that are effective in practice but unsound have often been regarded as ad hoc; in contrast, we suggest that, in the future, theorems of this variety might be generally useful in understanding, justifying and designing effective static analyses for bug catching. 1 CONTEXT FOR THE TRUE POSITIVES THEOREM The purpose of this paper is to state and prove a theorem that has come about by reacting to surprising properties we observed of a static program analysis that has been in production at Facebook for over a year. The RacerD program analyzer searches for data races in Java programs, and it has had significantly more reported industrial impact than any other concurrency analysis that we are aware of. It was released as open source in October of 2017, and the OOPSLA'18 paper by Blackshear et al. (2018) describes its design, and gives more details about its deployment. They report, for example, that over 2,500 concurrent data races found by RacerD have been fixed by Facebook developers, and that it has been used to support the conversion of Facebook's Android app rendering infrastructure from a single-threaded to a multi-threaded architecture.},
   author = {Nikos Gorogiannis and Peter W. O'Hearn and Ilya Sergey},
   doi = {10.1145/3290370},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A true positives theorem for a static race detector},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Peter W. O'Hearn: 
Similarity = 0.0


Paper List of Y: []
Paper List of Iain Proctor : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Iain Proctor after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Iain Proctor: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Xin Qi : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Xin Qi after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Xin Qi: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Maaz Bin Safeer Ahmad : [@article{Ahmad2018,
   abstract = {MapReduce is a popular programming paradigm for developing large-scale, data-intensive computation. Many frameworks that implement this paradigm have recently been developed. To leverage these frameworks, however, developers must become familiar with their APIs and rewrite existing code. We present Casper, a new tool that automatically translates sequential Java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps: (1) Casper uses program synthesis to search for a program summary (i.e., a functional specification) of each code fragment. The summary is expressed using a high-level intermediate language resembling the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. (2) Casper generates executable code from the summary, using either the Hadoop, Spark, or Flink API. We evaluated Casper by automatically converting realworld, sequential Java benchmarks to MapReduce. The resulting benchmarks perform up to 48.2× faster compared to the original.},
   author = {Maaz Bin Safeer Ahmad and Alvin Cheung},
   doi = {10.1145/3183713.3196891},
   journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
   title = {Automatically leveraging MapReduce frameworks for data-intensive applications},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Maaz Bin Safeer Ahmad after removed: [@article{Ahmad2018,
   abstract = {MapReduce is a popular programming paradigm for developing large-scale, data-intensive computation. Many frameworks that implement this paradigm have recently been developed. To leverage these frameworks, however, developers must become familiar with their APIs and rewrite existing code. We present Casper, a new tool that automatically translates sequential Java programs into the MapReduce paradigm. Casper identifies potential code fragments to rewrite and translates them in two steps: (1) Casper uses program synthesis to search for a program summary (i.e., a functional specification) of each code fragment. The summary is expressed using a high-level intermediate language resembling the MapReduce paradigm and verified to be semantically equivalent to the original using a theorem prover. (2) Casper generates executable code from the summary, using either the Hadoop, Spark, or Flink API. We evaluated Casper by automatically converting realworld, sequential Java benchmarks to MapReduce. The resulting benchmarks perform up to 48.2× faster compared to the original.},
   author = {Maaz Bin Safeer Ahmad and Alvin Cheung},
   doi = {10.1145/3183713.3196891},
   journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
   title = {Automatically leveraging MapReduce frameworks for data-intensive applications},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Maaz Bin Safeer Ahmad: 
Similarity = 0.0


Paper List of Y: []
Paper List of Raffaele Gravina : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Raffaele Gravina after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Raffaele Gravina: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 0.0


Paper List of Y: []
Paper List of M. S. Lvov : [@article{Lvov2012,
   author = {M. S. Lvov and V. A. Kreknin},
   doi = {10.1007/s10559-012-9406-y},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Automatic generation problem,Eigenpolynomial of a linear operator,Polynomial loop invariant,Static program analysis},
   title = {Nonlinear invariants for linear loops and eigenpolynomials of linear operators},
   year = {2012},
}
, @article{Lvov2015,
   author = {M. S. Lvov},
   doi = {10.1007/s10559-015-9736-7},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Invariant polynomial,Linear loop,Loop invariant,Static analysis of programs},
   title = {Software–hardware systems: The structure of polynomial invariants of linear loops},
   year = {2015},
}
, @article{Lvov2010,
   author = {M. S. Lvov},
   doi = {10.1007/s10559-010-9242-x},
   journal = {Cybernetics and Systems Analysis},
   keywords = {automatic generation problem,polynomial loop invariants,static program analysis},
   title = {Polynomial invariants for linear loops},
   year = {2010},
}
]
Paper List of Y after removed: []
Paper List of M. S. Lvov after removed: [@article{Lvov2012,
   author = {M. S. Lvov and V. A. Kreknin},
   doi = {10.1007/s10559-012-9406-y},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Automatic generation problem,Eigenpolynomial of a linear operator,Polynomial loop invariant,Static program analysis},
   title = {Nonlinear invariants for linear loops and eigenpolynomials of linear operators},
   year = {2012},
}
, @article{Lvov2015,
   author = {M. S. Lvov},
   doi = {10.1007/s10559-015-9736-7},
   journal = {Cybernetics and Systems Analysis},
   keywords = {Invariant polynomial,Linear loop,Loop invariant,Static analysis of programs},
   title = {Software–hardware systems: The structure of polynomial invariants of linear loops},
   year = {2015},
}
, @article{Lvov2010,
   author = {M. S. Lvov},
   doi = {10.1007/s10559-010-9242-x},
   journal = {Cybernetics and Systems Analysis},
   keywords = {automatic generation problem,polynomial loop invariants,static program analysis},
   title = {Polynomial invariants for linear loops},
   year = {2010},
}
]
Keywords of Y: 
Keywords of M. S. Lvov: Automatic generation problemEigenpolynomial of a linear operatorPolynomial loop invariantStatic program analysisInvariant polynomialLinear loopLoop invariantStatic analysis of programsautomatic generation problempolynomial loop invariantsstatic program analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Hila Peleg : [@article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Hila Peleg after removed: [@article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Hila Peleg: Domain-specific languagesProbabilistic modelsProgram SynthesisHuman-Computer InteractionProgram SynthesisType Inference
Similarity = 0.0


Paper List of Y: []
Paper List of Heike Wehrheim : [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
, @article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Paper List of Y after removed: []
Paper List of Heike Wehrheim after removed: [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
, @article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Keywords of Y: 
Keywords of Heike Wehrheim: Graph TransformationShape AnalysisThree-Vaued LogicGraph TransformationShape AnalysisThree-Vaued Logic
Similarity = 0.0


Paper List of Y: []
Paper List of Denis Gopan : [@article{Gopan2007,
   abstract = {In static analysis, the semantics of the program is expressed as a set of equations. The equations are solved iteratively over some abstract domain. If the abstract domain is distributive and satisfies the ascending-chain condition, an iterative technique yields the most precise solution for the equations. However, if the above properties are not satisfied, the solution obtained is typically impre- cise. Moreover, due to the properties of widening operators, the precision loss is sensitive to the order in which the state-space is explored. In this paper, we introduce guided static analysis, a framework for controlling the exploration of the state-space of a program. The framework guides the state- space exploration by applying standard static-analysis techniques to a sequence of modified versions of the analyzed program. As such, the framework does not require any modifications to existing analysis techniques, and thus can be easily integrated into existing static-analysis tools. We present two instantiations of the framework, which improve the precision of widening in (i) loops with multiple phases and (ii) loops in which the transforma- tion performed on each iteration is chosen non-deterministically.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Guided static analysis},
   year = {2007},
}
, @article{Gopan2006,
   abstract = {We present lookahead widening, a novel technique for using existing widening and narrowing operators to improve the precision of static analysis. This technique is both self-contained and fully-automatic in the sense that it does not rely on separate analyzes or human involvement. We show how to integrate looka- head widening into existing analyzers with minimal effort. Experimental results indicate that the technique is able to achieve sizable precision improvements at reasonable costs.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Lookahead widening},
   year = {2006},
}
]
Paper List of Y after removed: []
Paper List of Denis Gopan after removed: [@article{Gopan2007,
   abstract = {In static analysis, the semantics of the program is expressed as a set of equations. The equations are solved iteratively over some abstract domain. If the abstract domain is distributive and satisfies the ascending-chain condition, an iterative technique yields the most precise solution for the equations. However, if the above properties are not satisfied, the solution obtained is typically impre- cise. Moreover, due to the properties of widening operators, the precision loss is sensitive to the order in which the state-space is explored. In this paper, we introduce guided static analysis, a framework for controlling the exploration of the state-space of a program. The framework guides the state- space exploration by applying standard static-analysis techniques to a sequence of modified versions of the analyzed program. As such, the framework does not require any modifications to existing analysis techniques, and thus can be easily integrated into existing static-analysis tools. We present two instantiations of the framework, which improve the precision of widening in (i) loops with multiple phases and (ii) loops in which the transforma- tion performed on each iteration is chosen non-deterministically.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Guided static analysis},
   year = {2007},
}
, @article{Gopan2006,
   abstract = {We present lookahead widening, a novel technique for using existing widening and narrowing operators to improve the precision of static analysis. This technique is both self-contained and fully-automatic in the sense that it does not rely on separate analyzes or human involvement. We show how to integrate looka- head widening into existing analyzers with minimal effort. Experimental results indicate that the technique is able to achieve sizable precision improvements at reasonable costs.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Lookahead widening},
   year = {2006},
}
]
Keywords of Y: 
Keywords of Denis Gopan: 
Similarity = 0.0


Paper List of Y: []
Paper List of Aziem Chawdhary : [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
]
Paper List of Y after removed: []
Paper List of Aziem Chawdhary after removed: [@article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
]
Keywords of Y: 
Keywords of Aziem Chawdhary: Formal verificationLivenessProgram analysisSoftware model checkingTermination
Similarity = 0.0


Paper List of Y: []
Paper List of Programme Doctoral : [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Programme Doctoral after removed: [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Programme Doctoral: 
Similarity = 0.0


Paper List of Y: []
Paper List of Periklis Andritsos : [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
]
Paper List of Y after removed: []
Paper List of Periklis Andritsos after removed: [@article{Yu2005,
   abstract = {Large-scale legacy programs take long time to compile, thereby hampering productivity. This paper presents algorithms that reduce compilation time by analyzing syntactic dependencies in fine-grain program units, and by removing redundancies as well as false dependencies. These algorithms are combined with parallel compilation techniques (compiler farms, compiler caches), to further reduce build time. We demonstrate through experiments their effectiveness in achieving significant speedup for both fresh and incremental builds.},
   author = {Yijun Yu and Homayoun Dayani-Fard and John Mylopoulos and Periklis Andritsos},
   doi = {10.1109/ICSM.2005.73},
   journal = {IEEE International Conference on Software Maintenance, ICSM},
   title = {Reducing build time through precompilations for evolving large software},
   year = {2005},
}
]
Keywords of Y: 
Keywords of Periklis Andritsos: 
Similarity = 0.0


Paper List of Y: []
Paper List of Yuxin Chen : [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Yuxin Chen after removed: [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Yuxin Chen: 
Similarity = 0.0


Paper List of Y: []
Paper List of Collection Analysis : [@article{Analysis2011,
   author = {Collection Analysis},
   title = {Reading Lists （ Updating ） Container / Collection Analysis Redundant Header File Analysis ( Unclassified )},
   year = {2011},
}
]
Paper List of Y after removed: []
Paper List of Collection Analysis after removed: [@article{Analysis2011,
   author = {Collection Analysis},
   title = {Reading Lists （ Updating ） Container / Collection Analysis Redundant Header File Analysis ( Unclassified )},
   year = {2011},
}
]
Keywords of Y: 
Keywords of Collection Analysis: 
Similarity = 0.0


Paper List of Y: []
Paper List of Scott Mac Vicar : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Scott Mac Vicar after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Scott Mac Vicar: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Quang Loc Le : [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Paper List of Y after removed: []
Paper List of Quang Loc Le after removed: [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Keywords of Y: 
Keywords of Quang Loc Le: 
Similarity = 0.0


Paper List of Y: []
Paper List of Daniel Wonisch : [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Paper List of Y after removed: []
Paper List of Daniel Wonisch after removed: [@article{Steenken2010,
   author = {Dominik Steenken and Heike Wehrheim and Dominik Steenken and Heike Wehrheim and Daniel Wonisch},
   journal = {Nordic Workshop on Programming Theory 2010},
   keywords = {Graph Transformation,Shape Analysis,Three-Vaued Logic},
   title = {Towards a Shape Analysis for Graph Transformation Systems},
   year = {2010},
   url = {http://arxiv.org/abs/1010.4423},
}
]
Keywords of Y: 
Keywords of Daniel Wonisch: Graph TransformationShape AnalysisThree-Vaued Logic
Similarity = 0.0


Paper List of Y: []
Paper List of Patricia M. Hill : [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Paper List of Y after removed: []
Paper List of Patricia M. Hill after removed: [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Keywords of Y: 
Keywords of Patricia M. Hill: 
Similarity = 0.0


Paper List of Y: []
Paper List of Andrey Rybalchenko : [@article{Podelski2004,
   abstract = { Proof rules for program verification rely on auxiliary assertions. We propose a (sound and relatively complete) proof rule whose auxiliary assertions are transition invariants. A transition invariant of a program is a binary relation over program states that contains the transitive closure of the transition relation of the program. A relation is disjunctively well-founded if it is a finite union of well-founded relations. We characterize the validity of termination or another liveness property by the existence of a disjunctively well-founded transition invariant. The main contribution of our proof rule lies in its potential for automation via abstract interpretation.},
   author = {Andreas Podelski and Andrey Rybalchenko},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Transition invariants},
   year = {2004},
}
]
Paper List of Y after removed: []
Paper List of Andrey Rybalchenko after removed: [@article{Podelski2004,
   abstract = { Proof rules for program verification rely on auxiliary assertions. We propose a (sound and relatively complete) proof rule whose auxiliary assertions are transition invariants. A transition invariant of a program is a binary relation over program states that contains the transitive closure of the transition relation of the program. A relation is disjunctively well-founded if it is a finite union of well-founded relations. We characterize the validity of termination or another liveness property by the existence of a disjunctively well-founded transition invariant. The main contribution of our proof rule lies in its potential for automation via abstract interpretation.},
   author = {Andreas Podelski and Andrey Rybalchenko},
   journal = {Proceedings - Symposium on Logic in Computer Science},
   title = {Transition invariants},
   year = {2004},
}
]
Keywords of Y: 
Keywords of Andrey Rybalchenko: 
Similarity = 0.0


Paper List of Y: []
Paper List of Jeffrey Dean : [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Paper List of Y after removed: []
Paper List of Jeffrey Dean after removed: [@article{Dean1995,
   abstract = {Optimizing compilers for object-oriented languages apply static class analysis and other techniques to try to deduce precise information about the possible classes of the receivers of messages; if successful, dynamically-dispatched messages can be replaced with direct procedure calls and potentially further optimized through inline-expansion. By examining the complete inheritance graph of a program, which we call class hierarchy analysis, the compiler can improve the quality of static class information and thereby improve run-time performance. In this paper we present class hierarchy analysis and describe techniques for implementing this analysis effectively in both statically- and dynamically-typed languages and also in the presence of multi-methods. We also discuss how class hierarchy analysis can be supported in an interactive programming environment and, to some extent, in the presence of separate compilation. Finally, we assess the bottom-line performance improvement due to class hierarchy analysis alone and in combination with two other “competing” optimizations, profile-guided receiver class prediction and method specialization.},
   author = {Jeffrey Dean and David Grove and Craig Chambers},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Optimization of object-oriented programs using static class hierarchy analysis},
   year = {1995},
}
]
Keywords of Y: 
Keywords of Jeffrey Dean: 
Similarity = 0.0


Paper List of Y: []
Paper List of Olivier Hermant : [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
]
Paper List of Y after removed: []
Paper List of Olivier Hermant after removed: [@article{Maisonneuve2014,
   abstract = {Using abstract interpretation, invariants are usually obtained by solving iteratively a system of equations linking preconditions according to program statements. However, it is also possible to abstract first the statements as transformers, and then propagate the preconditions using the transformers. The second approach is modular because procedures and loops can be abstracted once and for all, avoiding an iterative resolution over the call graph and all the control flow graphs. However, the transformer approach based on polyhedral abstract domains encurs two penalties: some invariant accuracy may be lost when computing transformers, and the execution time may increase exponentially because the dimension of a transformer is twice the dimension of a precondition. The purposes of this article are 1) to measure the benefits of the modular approach and its drawbacks in terms of execution time and accuracy using significant examples and a newly developed benchmark for loop invariant analysis, ALICe, 2) to present a new technique designed to reduce the accuracy loss when computing transformers, 3) to evaluate experimentally the accuracy gains this new technique and other previously discussed ones provide with ALICe test cases and 4) to compare the executions times and accuracies of different tools, ASPIC, ISL, PAGAI and PIPS. Our results suggest that the transformer-based approach used in PIPS, once improved with transformer lists, is as accurate as the other tools when dealing with the ALICe benchmark. Its modularity nevertheless leads to shorter execution times when dealing with nested loops and procedure calls found in real applications. © 2014 Elsevier B.V. All rights reserved.},
   author = {Vivien Maisonneuve and Olivier Hermant and François Irigoin},
   doi = {10.1016/j.entcs.2014.08.003},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {abstract interpretation,automatic invariant detection,benchmark,linear relation analysis,loop invariant,model checking,static program analysis,transformer},
   title = {Computing invariants with transformers: Experimental scalability and accuracy},
   year = {2014},
}
]
Keywords of Y: 
Keywords of Olivier Hermant: abstract interpretationautomatic invariant detectionbenchmarklinear relation analysisloop invariantmodel checkingstatic program analysistransformer
Similarity = 0.0


Paper List of Y: []
Paper List of Eran Yahav : [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Paper List of Y after removed: []
Paper List of Eran Yahav after removed: [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
]
Keywords of Y: 
Keywords of Eran Yahav: alias analysisprogram verificationtypestate
Similarity = 0.0


Paper List of Y: []
Paper List of Guanhua He : [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Paper List of Y after removed: []
Paper List of Guanhua He after removed: [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Keywords of Y: 
Keywords of Guanhua He: AbstractionCombining analysisFixpoint analysisLoop invariantNumerical analysisSeparation logicShape analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Flavio Lerda : [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Paper List of Y after removed: []
Paper List of Flavio Lerda after removed: [@article{Clarke2004,
   abstract = {We present a tool for the formal verification of ANSI-C programs using Bounded Model Checking (BMC). The emphasis is on usability: the tool supports almost all ANSI-C language features, including pointer constructs, dynamic memory allocation, recursion, and the float and double data types. From the perspective of the user, the verification is highly automated: the only input required is the BMC bound. The tool is integrated into a graphical user interface. This is essential for presenting long counterexample traces: the tool allows stepping through the trace in the same way a debugger allows stepping through a program. © Springer-Verlag 2004.},
   author = {Edmund Clarke and Daniel Kroening and Flavio Lerda},
   doi = {10.1007/978-3-540-24730-2_15},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {A tool for checking ANSI-C programs},
   year = {2004},
}
]
Keywords of Y: 
Keywords of Flavio Lerda: 
Similarity = 0.0


Paper List of Y: []
Paper List of Amey Karkare : [@article{Karkare2018,
   abstract = {© 2018 ACM. A major drawback of shape analysis techniques is the trade-off between speed and precision. We present TwAS: a novel method to combine two shape analysis techniques-a fastbutless precise technique with a slow but more precise one-to get the best of both (speed as well as precision). The novelty of our approach is the use of fast analysis to filter heap variables for which the shape information is already precise and can not be refined further This allows us to run the slow analysis on only a small portion of the program, thus improving its performance. We implemented TwAS in GCC as a dynamic plugin as an inter-procedural data-flow analysis and evaluated it on standard benchmarks against the component analyses. TwAS is able to achieve the same precision as the slow analysis at a marginal slowdown compared to the fast analysis. TwAS is able to improve precision for 5 out of 8 Olden benchmarks compared to the fast-but-imprecise analysis, while retaining the precision for the others. At the same time, TwAS is 4X - 2500X faster than the precise-but-slow analysis for these benchmarks, without any loss in precision.},
   author = {Amey Karkare},
   doi = {10.1145/3167132.3167330},
   journal = {Proceedings of the ACM Symposium on Applied Computing},
   keywords = {Dataflow analysis,Heap analysis,Shape analysis,Static analysis},
   title = {TwAS: Two-stage shape analysis for speed and precision},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Amey Karkare after removed: [@article{Karkare2018,
   abstract = {© 2018 ACM. A major drawback of shape analysis techniques is the trade-off between speed and precision. We present TwAS: a novel method to combine two shape analysis techniques-a fastbutless precise technique with a slow but more precise one-to get the best of both (speed as well as precision). The novelty of our approach is the use of fast analysis to filter heap variables for which the shape information is already precise and can not be refined further This allows us to run the slow analysis on only a small portion of the program, thus improving its performance. We implemented TwAS in GCC as a dynamic plugin as an inter-procedural data-flow analysis and evaluated it on standard benchmarks against the component analyses. TwAS is able to achieve the same precision as the slow analysis at a marginal slowdown compared to the fast analysis. TwAS is able to improve precision for 5 out of 8 Olden benchmarks compared to the fast-but-imprecise analysis, while retaining the precision for the others. At the same time, TwAS is 4X - 2500X faster than the precise-but-slow analysis for these benchmarks, without any loss in precision.},
   author = {Amey Karkare},
   doi = {10.1145/3167132.3167330},
   journal = {Proceedings of the ACM Symposium on Applied Computing},
   keywords = {Dataflow analysis,Heap analysis,Shape analysis,Static analysis},
   title = {TwAS: Two-stage shape analysis for speed and precision},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Amey Karkare: Dataflow analysisHeap analysisShape analysisStatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Thomas Reps : [@article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
, @article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Gopan2007,
   abstract = {In static analysis, the semantics of the program is expressed as a set of equations. The equations are solved iteratively over some abstract domain. If the abstract domain is distributive and satisfies the ascending-chain condition, an iterative technique yields the most precise solution for the equations. However, if the above properties are not satisfied, the solution obtained is typically impre- cise. Moreover, due to the properties of widening operators, the precision loss is sensitive to the order in which the state-space is explored. In this paper, we introduce guided static analysis, a framework for controlling the exploration of the state-space of a program. The framework guides the state- space exploration by applying standard static-analysis techniques to a sequence of modified versions of the analyzed program. As such, the framework does not require any modifications to existing analysis techniques, and thus can be easily integrated into existing static-analysis tools. We present two instantiations of the framework, which improve the precision of widening in (i) loops with multiple phases and (ii) loops in which the transforma- tion performed on each iteration is chosen non-deterministically.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Guided static analysis},
   year = {2007},
}
, @article{Gopan2006,
   abstract = {We present lookahead widening, a novel technique for using existing widening and narrowing operators to improve the precision of static analysis. This technique is both self-contained and fully-automatic in the sense that it does not rely on separate analyzes or human involvement. We show how to integrate looka- head widening into existing analyzers with minimal effort. Experimental results indicate that the technique is able to achieve sizable precision improvements at reasonable costs.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Lookahead widening},
   year = {2006},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Paper List of Y after removed: []
Paper List of Thomas Reps after removed: [@article{Bogudlov2007,
   abstract = {TVLA is a parametric framework for shape analysis that can be easily instantiated to create different kinds of analyzers for checking properties of programs that use linked data structures. We report on dramatic improvements in TVLA’s performance, which make the cost of parametric shape analysis comparable to that of the most efficient specialized shape-analysis tools (which restrict the class of data structures and programs analyzed) without sacrificing TVLA’s parametricity. The improvements were obtained by employing well-known techniques from the database community to reduce the cost of extracting information from shape descriptors and performing abstract interpretation of program statements and conditions. Compared to the prior version of TVLA, we obtained as much as 50-fold speedup.},
   author = {Igor Bogudlov and Tal Lev-Ami and Thomas Reps and Mooly Sagiv},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Revamping TVLA: Making parametric shape analysis competitive},
   year = {2007},
}
, @article{McCloskey2010,
   abstract = {We describe Deskcheck, a parametric static analyzer that is able to establish properties of programs that manipulate dynamically allocated memory, arrays, and integers. Deskcheck can verify quantified invariants over mixed abstract domains, e.g., heap and numeric domains. These domains need only minor extensions to work with our domain combination framework. The technique used for managing the communication between domains is reminiscent of the Nelson-Oppen technique for combining decision procedures, in that the two domains share a common predicate language to exchange shared facts. However, whereas the Nelson-Oppen technique is limited to a common predicate language of shared equalities, the technique described in this paper uses a common predicate language in which shared facts can be quantified predicates expressed in first-order logic with transitive closure. We explain how we used Deskcheck to establish memory safety of the thttpd web server’s cache data structure, which uses linked lists, a hash table, and reference counting in a single composite data structure. Our work addresses some of the most complex data-structure invariants considered in the shape-analysis literature.},
   author = {Bill McCloskey and Thomas Reps and Mooly Sagiv},
   doi = {10.1007/978-3-642-15769-1_6},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Statically inferring complex heap, array, and numeric invariants},
   year = {2010},
}
, @article{Sagiv2002,
   abstract = {Shape analysis concerns the problem of determining "shape invariants" for programs that perform destructive updating on dynamically allocated storage. This article presents a parametric framework for shape analysis that can be instantiated in different ways to create different shape-analysis algorithms that provide varying degrees of efficiency and precision. A key innovation of the work is that the stores that can possibly arise during execution are represented (conservatively) using 3-valued logical structures. The framework is instantiated in different ways by varying the predicates used in the 3-valued logic. The class of programs to which a given instantiation of the framework can be applied is not limited a priori (i.e., as in some work on shape analysis, to programs that manipulate only lists, trees, DAGS, etc.); each instantiation of the framework can be applied to any program, but may produce imprecise results (albeit conservative ones) due to the set of predicates employed.},
   author = {Mooly Sagiv and Thomas Reps and Reinhard Wilhelm},
   doi = {10.1145/514188.514190},
   journal = {ACM Transactions on Programming Languages and Systems},
   keywords = {3-valued logic,Abstract interpretation,Algorithms,Alias analysis,Constraint solving,Destructive updating,Languages,Pointer analysis,Shape analysis,Static analysis,Theory,Verification},
   title = {Parametric shape analysis via 3-valued logic},
   year = {2002},
}
, @article{Gopan2007,
   abstract = {In static analysis, the semantics of the program is expressed as a set of equations. The equations are solved iteratively over some abstract domain. If the abstract domain is distributive and satisfies the ascending-chain condition, an iterative technique yields the most precise solution for the equations. However, if the above properties are not satisfied, the solution obtained is typically impre- cise. Moreover, due to the properties of widening operators, the precision loss is sensitive to the order in which the state-space is explored. In this paper, we introduce guided static analysis, a framework for controlling the exploration of the state-space of a program. The framework guides the state- space exploration by applying standard static-analysis techniques to a sequence of modified versions of the analyzed program. As such, the framework does not require any modifications to existing analysis techniques, and thus can be easily integrated into existing static-analysis tools. We present two instantiations of the framework, which improve the precision of widening in (i) loops with multiple phases and (ii) loops in which the transforma- tion performed on each iteration is chosen non-deterministically.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Guided static analysis},
   year = {2007},
}
, @article{Gopan2006,
   abstract = {We present lookahead widening, a novel technique for using existing widening and narrowing operators to improve the precision of static analysis. This technique is both self-contained and fully-automatic in the sense that it does not rely on separate analyzes or human involvement. We show how to integrate looka- head widening into existing analyzers with minimal effort. Experimental results indicate that the technique is able to achieve sizable precision improvements at reasonable costs.},
   author = {Denis Gopan and Thomas Reps},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Lookahead widening},
   year = {2006},
}
, @article{Rinetzky2005,
   abstract = {The goal of this work is to develop compile-time algorithms for automatically verifying properties of imperative programs that manipulate dynamically allocated storage. The paper presents an analysis method that uses a characterization of a procedure's behavior in which parts of the heap not relevant to the procedure are ignored. The paper has two main parts: The first part introduces a non-standard concrete semantics, LSL, in which called procedures are only passed parts of the heap. In this semantics, objects are treated specially when they separate the "local heap" that can be mutated by a procedure from the rest of the heap, which---from the viewpoint of that procedure---is non-accessible and immutable. The second part concerns abstract interpretation of LSL and develops a new static-analysis algorithm using canonical abstraction.},
   author = {Noam Rinetzky and Jörg Bauer and Thomas Reps and Mooly Sagiv and Reinhard Wilhelm},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {3-valued logic,Abstract interpretation,Shape analysis,Static analysis},
   title = {A semantics for procedure local heaps and its abstractions},
   year = {2005},
}
]
Keywords of Y: 
Keywords of Thomas Reps: 3-valued logicAbstract interpretationAlgorithmsAlias analysisConstraint solvingDestructive updatingLanguagesPointer analysisShape analysisStatic analysisTheoryVerification3-valued logicAbstract interpretationShape analysisStatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Daniel Lohmann : [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Paper List of Y after removed: []
Paper List of Daniel Lohmann after removed: [@article{Dietrich2017,
   abstract = {Software projects that use a compiled language are built hundreds of thousands of times during their lifespan. Hence, the compiler is invoked over and over again on an incrementally changing source base. As previous work has shown, up to 97 percent of these invocations are re-dundant and do not lead to an altered compilation result. In order to avoid such redundant builds, many developers use caching tools that are based on textual hashing of the source files. However, these tools fail in the presence of modifications that leave the compilation result unchanged. Especially for C projects, where module-interface defi-nitions are imported textually with the C preprocessor, modifications to header files lead to many redundant com-pilations. In this paper, we present the cHash approach and com-piler extension to quickly detect modifications on the language level that will not lead to a changed compilation result. By calculating a hash over the abstract syntax tree, we achieve a high precision at comparatively low costs. While cHash is light-weight and build system agnostic, it can cancel 80 percent of all compiler invocations early and reduce the build-time of incremental builds by up to 51 percent. In comparison to the state-of-the-art CCache tool, cHash is at least 30 percent more precise in detecting redundant compilations.},
   author = {Christian Dietrich and Valentin Rothberg and Ludwig Füracker and Andreas Ziegler and Daniel Lohmann},
   journal = {Atc'17},
   title = {cHash: Detection of Redundant Compilations via AST Hashing},
   year = {2017},
   url = {https://www.usenix.org/conference/atc17/technical-sessions/presentation/dietrich},
}
]
Keywords of Y: 
Keywords of Daniel Lohmann: 
Similarity = 0.0


Paper List of Y: []
Paper List of Pushmeet Kohli : [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Pushmeet Kohli after removed: [@article{Brockschmidt2017,
   author = {Marc Brockschmidt and Yuxin Chen and Pushmeet Kohli and Siddharth Krishna and Daniel Tarlow},
   doi = {10.1007/978-3-319-66706-5_4},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Learning shape analysis},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Pushmeet Kohli: 
Similarity = 0.0


Paper List of Y: []
Paper List of G. Ramalingam : [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
, @article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Paper List of Y after removed: []
Paper List of G. Ramalingam after removed: [@article{Fink2008,
   abstract = {This article addresses the challenge of sound typestate verification, with acceptable precision, for real-world Java programs. We present a novel framework for verification of typestate properties, including several new techniques to precisely treat aliases without undue performance costs. In particular, we present a flow-sensitive, context-sensitive, integrated verifier that utilizes a parametric abstract domain combining typestate and aliasing information. To scale to real programs without compromising precision, we present a staged verification system in which faster verifiers run as early stages which reduce the workload for later, more precise, stages.},
   author = {Stephen J. Fink and Eran Yahav and Nurit Dor and G. Ramalingam and Emmanuel Geay},
   doi = {10.1145/1348250.1348255},
   journal = {ACM Transactions on Software Engineering and Methodology},
   keywords = {alias analysis,program verification,typestate},
   title = {Effective typestate verification in the presence of aliasing},
   year = {2008},
   url = {http://portal.acm.org/citation.cfm?doid=1348250.1348255},
}
, @article{Ramalingam2002,
   abstract = {We are concerned with the problem of statically certifying (verifying) whether the client of a software component conforms to the component's constraints for correct usage. We show how conformance certification can be efficiently carried out in a staged fashion for certain classes of first-order safety (FOS) specifications, which can express relationship requirements among potentially unbounded collections of runtime objects. In the first stage of the certification process, we systematically derive an abstraction that is used to model the component state during analysis of arbitrary clients. In general, the derived abstraction will utilize first-order predicates, rather than the propositions often used by model checkers. In the second stage, the generated abstraction is incorporated into a static analysis engine to produce a certifier. In the final stage, the resulting certifier is applied to a client to conservatively determine whether the client violates the component's constraints. Unlike verification approaches that analyze a specification and client code together, our technique can take advantage of computationally-intensive symbolic techniques during the abstraction generation phase, without affecting the performance of Client analysis. Using as a running example the Concurrent Modification Problem (CMP), which arises when certain classes defined by the Java Collections Framework are misused, we describe several different classes of certifiers with varying time/space/precision tradeoffs. Of particular note are precise, polynomial-time, flow- and context-sensitive certifiers for certain classes of FOS specifications and client programs. Finally, we evaluate a prototype implementation of a certifier for CMP on a variety of test programs. The results of the evaluation show that our approach, though conservative, yields very few " false alarms," with acceptable performance.},
   author = {G. Ramalingam and Alex Warshavsky and John Field and Deepak Goyal and Mooly Sagiv},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Abstract interpretation,Model checking,Predicate abstraction,Software components,Static analysis},
   title = {Deriving specialized program analyses for certifying component-client conformance},
   year = {2002},
}
]
Keywords of Y: 
Keywords of G. Ramalingam: alias analysisprogram verificationtypestateAbstract interpretationModel checkingPredicate abstractionSoftware componentsStatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Istvan Haller : [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Paper List of Y after removed: []
Paper List of Istvan Haller after removed: [@article{Haller2016,
   abstract = {Many existing techniques for reversing data structures in C/C++ binaries are limited to low-level programming constructs, such as individual variables or structs. Unfor- tunately, without detailed information about a program’s pointer structures, forensics and reverse engineering are exceedingly hard. To fill this gap, we propose MemPick, a tool that detects and classifies high-level data structures used in stripped binaries. By analyzing how links between memory objects evolve throughout the program execution, it distinguishes between many commonly used data structures, such as singly- or doubly-linked lists, many types of trees (e.g., AVL, red-black trees, B-trees), and graphs. We evaluate the technique on 10 real world applications, 4 file system implementations and 16 popular libraries. The results show that MemPick can identify the data structures with high accuracy.},
   author = {Istvan Haller and Asia Slowinska and Herbert Bos},
   doi = {10.1007/s10664-015-9363-y},
   journal = {Empirical Software Engineering},
   keywords = {Data structures,Dynamic binary analysis},
   title = {Scalable data structure detection and classification for C/C++ binaries},
   year = {2016},
   url = {http://dx.doi.org/10.1007/s10664-015-9363-y},
}
]
Keywords of Y: 
Keywords of Istvan Haller: Data structuresDynamic binary analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Ziteng Wang : [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Ziteng Wang after removed: [@article{Guo2020,
   abstract = {We consider the problem of type-directed component-based synthesis where, given a set of (typed) components and a query type, the goal is to synthesize a term that inhabits the query. Classical approaches based on proof search in intuitionistic logics do not scale up to the standard libraries of modern languages, which span hundreds or thousands of components. Recent graph reachability based methods proposed for Java do scale, but only apply to monomorphic data and components: polymorphic data and components infinitely explode the size of the graph that must be searched, rendering synthesis intractable. We introduce type-guided abstraction refinement (TYGAR), a new approach for scalable type-directed synthesis over polymorphic datatypes and components. Our key insight is that we can overcome the explosion by building a graph over abstract types which represent a potentially unbounded set of concrete types. We show how to use graph reachability to search for candidate terms over abstract types, and introduce a new algorithm that uses proofs of untypeability of ill-typed candidates to iteratively refine the abstraction until a well-typed result is found. We have implemented TYGAR in H+, a tool that takes as input a set of Haskell libraries and a query type, and returns a Haskell term that uses functions from the provided libraries to implement the query type. Our support for polymorphism allows H+ to work with higher-order functions and type classes, and enables more precise queries due to parametricity. We have evaluated H+ on 44 queries using a set of popular Haskell libraries with a total of 291 components. H+ returns an interesting solution within the first five results for 32 out of 44 queries. Our results show that TYGAR allows H+ to rapidly return well-typed terms, with the median time to first solution of just 1.4 seconds. Moreover, we observe that gains from iterative refinement over exhaustive enumeration are more pronounced on harder queries.},
   author = {Zheng Guo and Michael James and David Justo and Jiaxiao Zhou and Ziteng Wang and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3371080},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Abstract Interpretation,Program Synthesis,Type Systems},
   title = {Program synthesis by type-guided abstraction refinement},
   year = {2020},
}
, @article{James2020,
   abstract = {We present Hoogle+, a web-based API discovery tool for Haskell. A Hoogle+ user can specify a programming task using either a type, a set of input-output tests, or both. Given a specification, the tool returns a list of matching programs composed from functions in popular Haskell libraries, and annotated with automatically-generated examples of their behavior. These features of Hoogle+ are powered by three novel techniques. First, to enable efficient type-directed synthesis from tests only, we develop an algorithm that infers likely type specifications from tests. Second, to return high-quality programs even with ambiguous specifications, we develop a technique that automatically eliminates meaningless and repetitive synthesis results. Finally, we show how to extend this elimination technique to automatically generate informative inputs that can be used to demonstrate program behavior to the user. To evaluate the effectiveness of Hoogle+ compared with traditional API search techniques, we perform a user study with 30 participants of varying Haskell proficiency. The study shows that programmers equipped with Hoogle+ generally solve tasks faster and were able to solve 50% more tasks overall.},
   author = {Michael B. James and Zheng Guo and Ziteng Wang and Shivani Doshi and Hila Peleg and Ranjit Jhala and Nadia Polikarpova},
   doi = {10.1145/3428273},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Human-Computer Interaction,Program Synthesis,Type Inference},
   title = {Digging for fold: Synthesis-aided API discovery for Haskell},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Ziteng Wang: Abstract InterpretationProgram SynthesisType SystemsHuman-Computer InteractionProgram SynthesisType Inference
Similarity = 0.0


Paper List of Y: []
Paper List of Yongmei Jiang : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Yongmei Jiang after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Yongmei Jiang: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 0.0


Paper List of Y: []
Paper List of Peter Schrammel : [@article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
, @article{Schrammel2010,
   abstract = {Acceleration methods are commonly used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with Boolean and numerical variables, e.g. Lustre programs, firstly requires the enumeration of the Boolean states in order to obtain a control graph with numerical variables only. Secondly, acceleration methods have to deal with the non-determinism introduced by numerical input variables. In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to numerical input variables. © 2010 Elsevier B.V. All rights reserved.},
   author = {Peter Schrammel and Bertrand Jeannet},
   doi = {10.1016/j.entcs.2010.09.009},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Static analysis,abstract interpretation,acceleration,linear relation analysis},
   title = {Extending abstract acceleration methods to data-flow programs with numerical inputs},
   year = {2010},
}
]
Paper List of Y after removed: []
Paper List of Peter Schrammel after removed: [@article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
, @article{Schrammel2010,
   abstract = {Acceleration methods are commonly used for computing precisely the effects of loops in the reachability analysis of counter machine models. Applying these methods on synchronous data-flow programs with Boolean and numerical variables, e.g. Lustre programs, firstly requires the enumeration of the Boolean states in order to obtain a control graph with numerical variables only. Secondly, acceleration methods have to deal with the non-determinism introduced by numerical input variables. In this article we address the latter problem by extending the concept of abstract acceleration of Gonnord et al. to numerical input variables. © 2010 Elsevier B.V. All rights reserved.},
   author = {Peter Schrammel and Bertrand Jeannet},
   doi = {10.1016/j.entcs.2010.09.009},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Static analysis,abstract interpretation,acceleration,linear relation analysis},
   title = {Extending abstract acceleration methods to data-flow programs with numerical inputs},
   year = {2010},
}
]
Keywords of Y: 
Keywords of Peter Schrammel: Static analysisabstract interpretationaccelerationlinear relation analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Peter O Hearn : [@article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Paper List of Y after removed: []
Paper List of Peter O Hearn after removed: [@article{Calcagno2009,
   author = {Cristiano Calcagno and Dino Distefano and Peter O Hearn},
   keywords = {a program analysis is,compo-,languages,or program,parts,program,reliability,result of a composite,similarly,sitional if the analysis,the meanings of its,theory,verification},
   title = {Popl09},
   year = {2009},
}
]
Keywords of Y: 
Keywords of Peter O Hearn: a program analysis iscompo-languagesor programpartsprogramreliabilityresult of a compositesimilarlysitional if the analysisthe meanings of itstheoryverification
Similarity = 0.0


Paper List of Y: []
Paper List of Natasha Sharygina : [@article{Sharygina2003,
   author = {Natasha Sharygina and James C. Browne},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Model checking software via abstraction of loop transitions},
   year = {2003},
}
]
Paper List of Y after removed: []
Paper List of Natasha Sharygina after removed: [@article{Sharygina2003,
   author = {Natasha Sharygina and James C. Browne},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Model checking software via abstraction of loop transitions},
   year = {2003},
}
]
Keywords of Y: 
Keywords of Natasha Sharygina: 
Similarity = 0.0


Paper List of Y: []
Paper List of Ping Yu : [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Ping Yu after removed: [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Ping Yu: Build systemBypath compilationIncremental build
Similarity = 0.0


Paper List of Y: []
Paper List of Christina Jansen : [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
, @article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Paper List of Y after removed: []
Paper List of Christina Jansen after removed: [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
, @article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Keywords of Y: 
Keywords of Christina Jansen: Dynamic data structuresHyperedge replacement grammarsJava bytecodeVerification
Similarity = 0.0


Paper List of Y: []
Paper List of Corinne Ancourt : [@article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Paper List of Y after removed: []
Paper List of Corinne Ancourt after removed: [@article{Ancourt2010,
   abstract = {Modular static analyzers use procedure abstractions, a.k.a. summarizations, to ensure that their execution time increases linearly with the size of analyzed programs. A similar abstraction mechanism is also used within a procedure to perform a bottom-up analysis. For instance, a sequence of instructions is abstracted by combining the abstractions of its components, or a loop is abstracted using the abstraction of its loop body: fixed point iterations for a loop can be replaced by a direct computation of the transitive closure of the loop body abstraction. More specifically, our abstraction mechanism uses affine constraints, i.e. polyhedra, to specify pre- and post-conditions as well as state transformers. We present an algorithm to compute the transitive closure of such a state transformer, and we illustrate its performance on various examples. Our algorithm is simple, based on discrete differentiation and integration: it is very different from the usual abstract interpretation fixed point computation based on widening. Experiments are carried out using previously published examples. We obtain the same results directly, without using any heuristic. © 2010 Elsevier B.V. All rights reserved.},
   author = {Corinne Ancourt and Fabien Coelho and François Irigoin},
   doi = {10.1016/j.entcs.2010.09.002},
   journal = {Electronic Notes in Theoretical Computer Science},
   keywords = {Abstract interpretation,fixed point computation,loop invariant},
   title = {A modular static analysis approach to affine loop invariants detection},
   year = {2010},
}
]
Keywords of Y: 
Keywords of Corinne Ancourt: Abstract interpretationfixed point computationloop invariant
Similarity = 0.0


Paper List of Y: []
Paper List of Rastislav Bodik : [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Rastislav Bodik after removed: [@article{Zhou2022,
   abstract = {Analytical SQL is widely used in modern database applications and data analysis. However, its partitioning and grouping operators are challenging for novice users. Unfortunately, programming by example, shown effective on standard SQL, are less attractive because examples for analytical queries are more laborious to solve by hand. To make demonstrations easier to create, we designed a new end-user specification, programming by computation demonstration, that allows the user to demonstrate the task using a (possibly incomplete) cell-level computation trace. This specification is exploited in a new abstraction-based synthesis algorithm to prove that a partially formed query cannot be completed to satisfy the specification, allowing us to prune the search space. We implemented our approach in a tool named Sickle and tested it on 80 real-world analytical SQL tasks. Results show that even from small demonstrations, Sickle can solve 76 tasks, in 12.8 seconds on average, while the prior approaches can solve only 60 tasks and are on average 22.5x slower. Our user study with 13 participants reveals that our specification increases user efficiency and confidence on challenging tasks.},
   author = {Xiangyu Zhou and Rastislav Bodik and Alvin Cheung and Chenglong Wang},
   doi = {10.1145/3519939.3523712},
   title = {Synthesizing analytical SQL queries from computation demonstration},
   year = {2022},
}
, @article{Wang2017,
   abstract = {SQL is the de facto language for manipulating relational data. Though powerful, many users find it difficult to write SQL queries due to highly expressive constructs. While using the programming-by-example paradigm to help users write SQL queries is an attractive proposition, as evidenced by online help forums such as Stack Overflow, developing techniques for synthesizing SQL queries from given input-output (I/O) examples has been difficult, due to the large space of SQL queries as a result of its rich set of operators. In this paper, we present a new scalable and efficient algorithm for synthesizing SQL queries based on I/O examples. The key innovation of our algorithm is development of a language for abstract queries, i.e., queries with uninstantiated operators, that can be used to express a large space of SQL queries efficiently. Using abstract queries to represent the search space nicely decomposes the synthesis problem into two tasks: 1) searching for abstract queries that can potentially satisfy the given I/O examples, and 2) instantiating the found abstract queries and ranking the results. We have implemented this algorithm in a new tool called Scythe and evaluated it using 193 benchmarks collected from Stack Overflow. Our evaluation shows that Scythe can efficiently solve 74% of the benchmarks, most in just a few seconds, and the queries range from simple ones involving a single selection to complex queries with 6 nested subqueires.},
   author = {Chenglong Wang and Alvin Cheung and Rastislav Bodik},
   doi = {10.1145/3062341.3062365},
   journal = {ACM SIGPLAN Notices},
   keywords = {Program Synthesis,Query by Example,SQL},
   title = {Synthesizing highly expressive SQL queries from input-output examples},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Rastislav Bodik: Program SynthesisQuery by ExampleSQL
Similarity = 0.0


Paper List of Y: []
Paper List of Cong Yan : [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Paper List of Y after removed: []
Paper List of Cong Yan after removed: [@article{Liu2022,
   abstract = {Exploiting the relationships among data, such as primary and foreign keys, is a classical query optimization technique. As persistent data is increasingly being created and maintained programmatically (e.g., web applications), prior work that focuses on inferring data relationships by tabulating statistics from the stored data misses an important opportunity. We present ConstrOpt, the first tool that identifies data relationships by analyzing the programs that generate and maintain the persistent data. Once identified, ConstrOpt leverages the found constraints to optimize the application's physical design and query execution by rewriting queries. Instead of developing a fixed set of predefined rewriting rules, ConstrOpt employs an enumerate-test-verify technique to automatically exploit the discovered data constraints to improve query execution. Each resulting rewrite is provably semantically equivalent to the original query. Using 14 real-world web applications, our experiments show that ConstrOpt can discover over 4306 data constraints by analyzing application source code. On 3 of the evaluated applications, among queries with at least one constrained column, 42% can benefit from data layout optimization, and 35% are optimized by changing the application code. Finally, ConstrOpt's constraint-driven optimizer improves the performance of 826 queries, 9.8% of which has over 2x speedup.},
   author = {Xiaoxuan Liu and Shuxian Wang and Mengzhu Sun and Sharon Lee and Sicheng Pan and Joshua Wu and Cong Yan and Junwen Yang and Shan Lu and Alvin Cheung},
   title = {Leveraging Application Data Constraints to OptimizeDatabase-Backed Web Applications},
   year = {2022},
   url = {http://arxiv.org/abs/2205.02954},
}
]
Keywords of Y: 
Keywords of Cong Yan: 
Similarity = 0.0


Paper List of Y: []
Paper List of Minghui Yang : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Minghui Yang after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Minghui Yang: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Josh Berdine : [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Paper List of Y after removed: []
Paper List of Josh Berdine after removed: [@article{Manevich2008,
   abstract = {We demonstrate shape analyses that can achieve a state space reduction exponential in the number of threads compared to the state-of-the-art analyses, while retaining sufficient precision to verify sophisticated properties such as linearizability. The key idea is to abstract the global heap by decomposing it into (not necessarily disjoint) subheaps, abstracting away some correlations between them. These new shape analyses are instances of an analysis framework based on heap decomposition. This framework allows rapid prototyping of complex static analyses by providing efficient abstract transformers given user-specified decomposition schemes. Initial experiments confirm the value of heap decomposition in scaling concurrent shape analyses.},
   author = {Roman Manevich and Tal Lev-Ami and Mooly Sagiv and Ganesan Ramalingam and Josh Berdine},
   doi = {10.1007/978-3-540-69166-2_24},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Heap decomposition for concurrent shape analysis},
   year = {2008},
}
, @article{Berdine2007,
   abstract = {An invariance assertion for a program location l is a statement that always holds at l during execution of the program. Program invariance analyses infer invariance assertions that can be useful when trying to prove safety properties. We use the term variance assertion to mean a statement that holds between any state at l and any previous state that was also at l. This paper is concerned with the development of analyses for variance assertions and their application to proving termination and liveness properties. We describe a method of constructing program variance analyses from invariance analyses. If we change the underlying invariance analysis, we get a different variance analysis. We describe several applications of the method, including variance analyses using linear arithmetic and shape analysis. Using experimental results we demonstrate that these variance analyses give rise to a new breed of termination provers which are competitive with and sometimes better than today's state-of-the-art termination provers.},
   author = {Josh Berdine and Aziem Chawdhary and Byron Cook and Dino Distefano and Peter O'Hearn},
   doi = {10.1145/1190216.1190249},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Formal verification,Liveness,Program analysis,Software model checking,Termination},
   title = {Variance analyses from invariance analyses},
   year = {2007},
}
, @article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Keywords of Y: 
Keywords of Josh Berdine: Formal verificationLivenessProgram analysisSoftware model checkingTerminationabstract interpretationconcurrent programmingshape analysisstatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Ton Chanh Le : [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Ton Chanh Le after removed: [@article{Le2019,
   abstract = {We introduce a new dynamic analysis technique to discover invariants in separation logic for heap-manipulating programs. First, we use a debugger to obtain rich program execution traces at locations of interest on sample inputs. These traces consist of heap and stack information of variables that point to dynamically allocated data structures. Next, we iteratively analyze separate memory regions related to each pointer variable and search for a formula over predefined heap predicates in separation logic to model these regions. Finally, we combine the computed formulae into an invariant that describes the shape of explored memory regions. We present SLING, a tool that implements these ideas to automatically generate invariants in separation logic at arbitrary locations in C programs, e.g., program pre and postconditions and loop invariants. Preliminary results on existing benchmarks show that SLING can efficiently generate correct and useful invariants for programs that manipulate a wide variety of complex data structures.},
   author = {Ton Chanh Le and Guolong Zheng and Thanh Vu Nguyen},
   doi = {10.1145/3314221.3314634},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Dynamic invariant analysis,Separation logic},
   title = {SLinG: Using dynamic analysis to infer program invariants in separation logic},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Ton Chanh Le: Dynamic invariant analysisSeparation logic
Similarity = 0.0


Paper List of Y: []
Paper List of Xin Chen : [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Paper List of Y after removed: []
Paper List of Xin Chen after removed: [@article{Qin2013,
   abstract = {Automated verification of memory safety and functional correctness for heap-manipulating programs has been a challenging task, especially when dealing with complex data structures with strong invariants involving both shape and numerical properties. Existing verification systems usually rely on users to supply annotations to guide the verification, which can be cumbersome and error-prone by hand and can significantly restrict the usability of the verification system. In this paper, we reduce the need for some user annotations by automatically inferring loop invariants over an abstract domain with both shape and numerical information. Our loop invariant synthesis is conducted automatically by a fixed-point iteration process, equipped with newly designed abstraction mechanism, together with join and widening operators over the combined domain. We have also proven the soundness and termination of our approach. Initial experiments confirm that we can synthesise loop invariants with non-trivial constraints. © 2012 Elsevier B.V.},
   author = {Shengchao Qin and Guanhua He and Chenguang Luo and Wei Ngan Chin and Xin Chen},
   doi = {10.1016/j.jsc.2012.08.007},
   journal = {Journal of Symbolic Computation},
   keywords = {Abstraction,Combining analysis,Fixpoint analysis,Loop invariant,Numerical analysis,Separation logic,Shape analysis},
   title = {Loop invariant synthesis in a combined abstract domain},
   year = {2013},
}
]
Keywords of Y: 
Keywords of Xin Chen: AbstractionCombining analysisFixpoint analysisLoop invariantNumerical analysisSeparation logicShape analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Giancarlo Fortino : [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Giancarlo Fortino after removed: [@article{Li2016,
   abstract = {© 2017 EAI. In this paper, from the perspective of human ergonomics, we analyze the movement of the joints in the process of human body movements, and we establish a dynamic model according to the human skeleton structure. On this basis, from the rigid body dynamics point of view, combined with the principle of inertial navigation, a body sensor network based on MEMS inertial sensors is built to capture human body motion in real time. On the basis of space trajectory of human body movement and traditional human motion solution strategy, a human motion solution strategy based on particle filter fusion solution is proposed to realize the prediction of human motion analysis. Therefore, we evaluate the performance of the designed system by comparing with the real motion. Finally, in order to verify the human motion data, the motion capture data verification platforms are established. Experimental results show that the proposed joint attitude solution algorithm can achieve a relatively smooth tracking effect and provides a certain reference value.},
   author = {Jie Li and Zhe Long Wang and Hongyu Zhao and Raffaele Gravina and Giancarlo Fortino and Yongmei Jiang and Kai Tang},
   doi = {10.1145/0000000.0000000},
   journal = {BodyNets International Conference on Body Area Networks},
   keywords = {Body sensor network,Inertial navigation,Motion capture,Particle filter},
   title = {Networked human motion capture system based on quaternion navigation},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Giancarlo Fortino: Body sensor networkInertial navigationMotion captureParticle filter
Similarity = 0.0


Paper List of Y: []
Paper List of Cristian Cadar : [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Paper List of Y after removed: []
Paper List of Cristian Cadar after removed: [@article{Kapus2019,
   abstract = {Analysing and comprehending C programs that use strings is hard: Using standard library functions for manipulating strings is not enforced and programs often use complex loops for the same purpose. We introduce the notion of memoryless loops that capture some of these string loops and present a counterexample-guided inductive synthesis approach to summarise memoryless string loops using C standard library functions, which has applications to testing, optimization and refactoring. We prove our summarization is correct for arbitrary input strings and evaluate it on a database of loops we gathered from a set of 13 open-source programs. Our approach can summarize over two thirds of memoryless loops in less than 5 minutes of computation time per loop. We then show that these summaries can be used to (1) enhance symbolic execution testing, where we observed median speedups of 79x when employing a string constraint solver, (2) optimize native code, where certain summarizations led to significant performance gains, and (3) refactor code, where we had several patches accepted in the codebases of popular applications such as patch and wget.},
   author = {Timotej Kapus and Oren Ish-Shalom and Shachar Itzhaky and Noam Rinetzky and Cristian Cadar},
   doi = {10.1145/3314221.3314610},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {Loop Summarisation,Optimisation,Refactoring,Strings,Symbolic Execution,Synthesis},
   title = {Computing summaries of string loops in C for better testing and refactoring},
   year = {2019},
}
]
Keywords of Y: 
Keywords of Cristian Cadar: Loop SummarisationOptimisationRefactoringStringsSymbolic ExecutionSynthesis
Similarity = 0.0


Paper List of Y: []
Paper List of Francois Berenger : [@article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Francois Berenger after removed: [@article{Li2017,
   abstract = {© 2017 ACM. To infer complex structural invariants, shape analyses rely on expressive families of logical properties. Many such analyses manipulate abstract memory states that consist of separating conjunctions of basic predicates describing atomic blocks or summaries. Moreover, they use finite disjunctions of abstract memory states in order to account for dissimilar shapes. Disjunctions should be kept small for scalability, though precision often requires keeping additional case splits. In this context, deciding when and how to merge case splits and to replace them with summaries is critical both for precision and efficiency. Existing techniques use sets of syntactic rules, which are tedious to design and prone to failure. In this paper, we design a semantic criterion to clump abstract states based on their silhouette, which applies not only to the conservative union of disjuncts but also to the weakening of separating conjunctions of memory predicates into inductive summaries. Our approach allows us to define union and widening operators that aim at preserving the case splits that are required for the analysis to succeed. We implement this approach in the MemCAD analyzer and evaluate it on real-world C codes from existing libraries dealing with doubly-linked lists, red-black trees, AVL-trees and splay-trees.},
   author = {Huisong Li and Francois Berenger and Bor Yuh Evan Chang and Xavier Rival},
   doi = {10.1145/3009837.3009881},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Abstract interpretation,Clumping of disjuncts,Disjunctions,Heap abstraction,Separation logics,Silhouette,Static analysis},
   title = {Semantic-directed clumping of disjunctive abstract states},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Francois Berenger: Abstract interpretationClumping of disjunctsDisjunctionsHeap abstractionSeparation logicsSilhouetteStatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Haiping Zhao : [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Paper List of Y after removed: []
Paper List of Haiping Zhao after removed: [@article{Zhao2012,
   abstract = {Scripting languages are widely used to quickly accomplish a variety of tasks because of the high productivity they enable. Among other reasons, this increased productivity results from a combination of extensive libraries, fast development cycle, dynamic typing, and polymorphism. The dynamic features of scripting languages are traditionally associated with interpreters, which is the approach used to implement most scripting languages. Although easy to implement, interpreters are generally slow, which makes scripting languages prohibitive for implementing large, CPU-intensive applications. This efficiency problem is particularly important for PHP given that it is the most commonly used language for server-side web development. This paper presents the design, implementation, and an evaluation of the HipHop compiler for PHP. HipHop goes against the standard practice and implements a very dynamic language through static compilation. After describing the most challenging PHP features to support through static compilation, this paper presents HipHop's design and techniques that support almost all PHP features. We then present a thorough evaluation of HipHop running both standard benchmarks and the Facebook web site. Overall, our experiments demonstrate that HipHop is about 5.5x faster than standard, interpreted PHP engines. As a result, HipHop has reduced the number of servers needed to run Facebook and other web sites by a factor between 4 and 6, thus drastically cutting operating costs. },
   author = {Haiping Zhao and Iain Proctor and Minghui Yang and Xin Qi and Mark Williams and Qi Gao and Guilherme Ottoni and Andrew Paroski and Scott Mac Vicar and Jason Evans and Stephen Tu},
   doi = {10.1145/2398857.2384658},
   journal = {ACM SIGPLAN Notices},
   keywords = {C++,Compilation,Dynamic languages,PHP},
   title = {The HipHop compiler for PHP},
   year = {2012},
}
]
Keywords of Y: 
Keywords of Haiping Zhao: C++CompilationDynamic languagesPHP
Similarity = 0.0


Paper List of Y: []
Paper List of Patrick Lam : [@article{Albiz2009,
   author = {Syed S Albiz and Patrick Lam},
   title = {Implementation and Use of Data Structures in Java Programs},
   year = {2009},
}
]
Paper List of Y after removed: []
Paper List of Patrick Lam after removed: [@article{Albiz2009,
   author = {Syed S Albiz and Patrick Lam},
   title = {Implementation and Use of Data Structures in Java Programs},
   year = {2009},
}
]
Keywords of Y: 
Keywords of Patrick Lam: 
Similarity = 0.0


Paper List of Y: []
Paper List of Rongxin Wu : [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Paper List of Y after removed: []
Paper List of Rongxin Wu after removed: [@article{Shi2021,
   abstract = {Sparse program analysis is fast as it propagates data flow facts via data dependence, skipping unnecessary control flows. However, when path-sensitively checking millions of lines of code, it is still prohibitively expensive because a huge number of path conditions have to be computed and solved via an SMT solver. This paper presents Fusion, a fused approach to inter-procedurally path-sensitive sparse analysis. In Fusion, the SMT solver does not work as a standalone tool on path conditions but directly on the program together with the sparse analysis. Such a fused design allows us to determine the path feasibility without explicitly computing path conditions, not only saving the cost of computing path conditions but also providing an opportunity to enhance the SMT solving algorithm. To the best of our knowledge, Fusion, for the first time, enables whole program bug detection on millions of lines of code in a common personal computer, with the precision of inter-procedural path-sensitivity. Compared to two state-of-the-art tools, Fusion is 10× faster but consumes only 10% of memory on average. Fusion has detected over a hundred bugs in mature open-source software, some of which have even been assigned CVE identifiers due to their security impact.},
   author = {Qingkai Shi and Peisen Yao and Rongxin Wu and Charles Zhang},
   doi = {10.1145/3453483.3454086},
   journal = {Proceedings of the ACM SIGPLAN Conference on Programming Language Design and Implementation (PLDI)},
   keywords = {SMT solving,Sparse analysis,path sensitivity,program dependence graph},
   title = {Path-sensitive sparse analysis without path conditions},
   year = {2021},
}
]
Keywords of Y: 
Keywords of Rongxin Wu: SMT solvingSparse analysispath sensitivityprogram dependence graph
Similarity = 0.0


Paper List of Y: []
Paper List of Neville Grech : [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Neville Grech after removed: [@article{Grech2018,
   abstract = {Traditional whole-program static analysis (e.g., a points-to analysis that models the heap) encounters scalability problems for realistic applications. We propose a łfeatherweightž analysis that combines a dynamic snapshot of the heap with otherwise full static analysis of program behavior. The analysis is extremely scalable, offering speedups of well over 3x, with complexity empirically evaluated to grow linearly relative to the number of reachable methods. The analysis is also an excellent tradeoff of precision and recall (relative to different dynamic executions): while it can never fully capture all program behaviors (i.e., it cannot match the near-perfect recall of a full static analysis) it often approaches it closely while achieving much higher (3.5x) precision.},
   author = {Neville Grech and George Fourtounis and Adrian Francalanza and Yannis Smaragdakis},
   doi = {10.1145/3213846.3213860},
   journal = {ISSTA 2018 - Proceedings of the 27th ACM SIGSOFT International Symposium on Software Testing and Analysis},
   keywords = {Heap Snapshots,Program Analysis,Scalability},
   title = {Shooting from the heap: Ultra-scalable static analysis with heap snapshots},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Neville Grech: Heap SnapshotsProgram AnalysisScalability
Similarity = 0.0


Paper List of Y: []
Paper List of Patrick Cousot : [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
, @article{Cousot2014,
   abstract = {Abstract interpretation is a theory of abstraction and constructive approximation of the mathematical structures used in the formal description of complex or infinite systems and the inference or verification of their combinatorial or undecidable properties. Developed in the late seventies, it has been since then used, implicitly or explicitly, to many aspects of computer science (such as static analysis and verification, contract inference, type inference, termination inference, model-checking, abstraction/refinement, program transformation (including watermarking, obfuscation, etc), combination of decision procedures, security, malware detection, database queries, etc) and more recently, to system biology and SAT/SMT solvers. Production-quality verification tools based on abstract interpretation are available and used in the advanced software, hardware, transportation, communication, and medical industries. The talk will consist in an introduction to the basic notions of abstract interpretation and the induced methodology for the systematic development of sound abstract interpretation-based tools. Examples of abstractions will be provided, from semantics to typing, grammars to safety, reachability to potential/definite termination, numerical to protein-protein abstractions, as well as applications (including those in industrial use) to software, hardware and system biology. This paper is a general discussion of abstract interpretation, with selected publications, which unfortunately are far from exhaustive both in the considered themes and the corresponding references.},
   author = {Patrick Cousot and Radhia Cousot},
   doi = {10.1145/2603088.2603165},
   journal = {Proceedings of the Joint Meeting of the 23rd EACSL Annual Conference on Computer Science Logic, CSL 2014 and the 29th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2014},
   keywords = {Abstract interpretation,Proof,Semantics,Static Analysis,Verification},
   title = {Abstract interpretation: Past, present and future},
   year = {2014},
}
]
Paper List of Y after removed: []
Paper List of Patrick Cousot after removed: [@article{Cousot2019,
   abstract = {The fundamental idea of Abstract 2 Interpretation (A 2 I), also called meta-abstract interpretation, is to apply abstract interpretation to abstract interpretation-based static program analyses. A 2 I is generally meant to use abstract interpretation to analyse properties of program analysers. A 2 I can be either offline or online. Offline A 2 I is performed either before the program analysis, such as variable packing used by the Astrée program analyser, or after the program analysis, such as in alarm diagnosis. Online A 2 I is performed during the program analysis, such as Venet's cofibred domains or Halbwachs et al. 's and Singh et al. 's variable partitioning techniques for fast polyhedra/numerical abstract domains. We formalize offline and online meta-abstract interpretation and illustrate this notion with the design of widenings and the decomposition of relational abstract domains to speed-up program analyses. This shows how novel static analyses can be extracted as meta-abstract interpretations to design efficient and precise program analysis algorithms.},
   author = {Patrick Cousot and Roberto Giacobazzi and Francesco Ranzato},
   doi = {10.1145/3290355},
   journal = {Proceedings of the ACM on Programming Languages},
   title = {A²I: abstract² interpretation},
   year = {2019},
}
, @article{Cousot2014,
   abstract = {Abstract interpretation is a theory of abstraction and constructive approximation of the mathematical structures used in the formal description of complex or infinite systems and the inference or verification of their combinatorial or undecidable properties. Developed in the late seventies, it has been since then used, implicitly or explicitly, to many aspects of computer science (such as static analysis and verification, contract inference, type inference, termination inference, model-checking, abstraction/refinement, program transformation (including watermarking, obfuscation, etc), combination of decision procedures, security, malware detection, database queries, etc) and more recently, to system biology and SAT/SMT solvers. Production-quality verification tools based on abstract interpretation are available and used in the advanced software, hardware, transportation, communication, and medical industries. The talk will consist in an introduction to the basic notions of abstract interpretation and the induced methodology for the systematic development of sound abstract interpretation-based tools. Examples of abstractions will be provided, from semantics to typing, grammars to safety, reachability to potential/definite termination, numerical to protein-protein abstractions, as well as applications (including those in industrial use) to software, hardware and system biology. This paper is a general discussion of abstract interpretation, with selected publications, which unfortunately are far from exhaustive both in the considered themes and the corresponding references.},
   author = {Patrick Cousot and Radhia Cousot},
   doi = {10.1145/2603088.2603165},
   journal = {Proceedings of the Joint Meeting of the 23rd EACSL Annual Conference on Computer Science Logic, CSL 2014 and the 29th Annual ACM/IEEE Symposium on Logic in Computer Science, LICS 2014},
   keywords = {Abstract interpretation,Proof,Semantics,Static Analysis,Verification},
   title = {Abstract interpretation: Past, present and future},
   year = {2014},
}
]
Keywords of Y: 
Keywords of Patrick Cousot: Abstract interpretationProofSemanticsStatic AnalysisVerification
Similarity = 0.0


Paper List of Y: []
Paper List of David Friggens : [@article{Friggens2015,
   abstract = {Canonical abstraction is a static analysis technique that represents states as 3-valued logical structures, and produces finite abstract systems. Despite providing a finite bound, these abstractions may still suffer from the state explosion problem. Notably, for concurrent programs with arbitrary interleaving, if threads in a state are abstracted based on their location, then the number of locations will be a combinatorial factor in the size of the statespace. We present an approach using canonical abstraction that avoids this state explosion by "collapsing" all of the threads in a state into a single abstract representative. Properties of threads that would be lost by the abstraction, but are needed for verification, are retained by defining conditional "soft invariant" instrumentation predicates. This technique is used to adapt previous models for verifying linearizability of nonblocking concurrent data structure algorithms, resulting in exponentially smaller statespaces.},
   author = {David Friggens and Lindsay Groves},
   title = {Collapsing Threads Safely with Soft Invariants},
   year = {2015},
   url = {http://arxiv.org/abs/1512.09186},
}
]
Paper List of Y after removed: []
Paper List of David Friggens after removed: [@article{Friggens2015,
   abstract = {Canonical abstraction is a static analysis technique that represents states as 3-valued logical structures, and produces finite abstract systems. Despite providing a finite bound, these abstractions may still suffer from the state explosion problem. Notably, for concurrent programs with arbitrary interleaving, if threads in a state are abstracted based on their location, then the number of locations will be a combinatorial factor in the size of the statespace. We present an approach using canonical abstraction that avoids this state explosion by "collapsing" all of the threads in a state into a single abstract representative. Properties of threads that would be lost by the abstraction, but are needed for verification, are retained by defining conditional "soft invariant" instrumentation predicates. This technique is used to adapt previous models for verifying linearizability of nonblocking concurrent data structure algorithms, resulting in exponentially smaller statespaces.},
   author = {David Friggens and Lindsay Groves},
   title = {Collapsing Threads Safely with Soft Invariants},
   year = {2015},
   url = {http://arxiv.org/abs/1512.09186},
}
]
Keywords of Y: 
Keywords of David Friggens: 
Similarity = 0.0


Paper List of Y: []
Paper List of Rastislav Bodík : [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Paper List of Y after removed: []
Paper List of Rastislav Bodík after removed: [@article{Mandelin2005,
   abstract = {Reuse of existing code from class libraries and frameworks is often difficult because APIs are complex and the client code required to use the APIs can be hard to write. We observed that a common scenario is that the programmer knows what type of object he needs, but does not know how to write the code to get the object. In order to help programmers write API client code more easily, we developed techniques for synthesizing jungloid code fragments automatically given a simple query that describes that desired code in terms of input and output types. A jungloid is simply a unary expression; jungloids are simple, enabling synthesis, but are also versatile, covering many coding problems, and composable, combining to form more complex code fragments. We synthesize jun-gloids using both API method signatures and jungloids mined from a corpus of sample client programs. We implemented a tool, PROSPECTOR, based on these techniques. PROSPECTOR is integrated with the Eclipse IDE code assistance feature, and it infers queries from context so there is no need for the programmer to write queries. We tested PROSPECTOR on a set of real programming problems involving APIs; PROSPECTOR found the desired solution for 18 of 20 problems. We also evaluated PROSPECTOR in a user study, finding that programmers solved programming problems more quickly and with more reuse when using PROSPECTOR than without PROSPECTOR.},
   author = {David Mandelin and Lin Xu and Rastislav Bodík and Doug Kimelman},
   keywords = {D213 [Software Engineering]: Reusable Software-Reuse Models,D26 [Software Engineer-ing]: Programming Environments-Integrated Environments,I22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation, Languages Keywords reuse, program synthesis, mining *},
   title = {Jungloid Mining: Helping to Navigate the API Jungle *},
   year = {2005},
   url = {www.cs.berkeley.edu/~mandelin/prospector},
}
]
Keywords of Y: 
Keywords of Rastislav Bodík: D213 [Software Engineering]: Reusable Software-Reuse ModelsD26 [Software Engineer-ing]: Programming Environments-Integrated EnvironmentsI22 [Artificial Intelligence]: Automatic Programming-Program synthesis General Terms Experimentation Languages Keywords reuse program synthesis mining *
Similarity = 0.0


Paper List of Y: []
Paper List of Martin Kellogg : [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Paper List of Y after removed: []
Paper List of Martin Kellogg after removed: [@article{Kellogg2020,
   abstract = {In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction-the builder pattern, dependency injection, or factory methods. However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of wellformed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems. This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden. Our implementation and experimental data are publicly available.},
   author = {Martin Kellogg and Manli Ran and Manu Sridharan and Martin Schaf and Michael D. Ernst},
   doi = {10.1145/3377811.3380341},
   journal = {Proceedings - International Conference on Software Engineering},
   keywords = {Ami sniping,Autovalue,Builder pattern,Lightweight verification,Lombok,Pluggable type systems},
   title = {Verifying object construction},
   year = {2020},
}
, @article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Keywords of Y: 
Keywords of Martin Kellogg: Ami snipingAutovalueBuilder patternLightweight verificationLombokPluggable type systemsTypestatefinite-state property
Similarity = 0.0


Paper List of Y: []
Paper List of Elisa Ricci : [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Paper List of Y after removed: []
Paper List of Elisa Ricci after removed: [@article{Bagnara2003,
   abstract = {In the context of static analysis via abstract interpretation, convex polyhedra constitute the most used abstract domain among those capturing numerical relational information. Since the domain of convex polyhedra admits infinite ascending chains, it has to be used in conjunction with appropriate mechanisms for enforcing and accelerating the convergence of fixpoint computations. Widening operators provide a simple and general characterization for such mechanisms. For the domain of convex polyhedra, the original widening operator proposed by Cousot and Halbwachs amply deserves the name of standard widening since most analysis and verification tools that employ convex polyhedra also employ that operator. Nonetheless, there is an unfulfilled demand for more precise widening operators. In this paper, after a formal introduction to the standard widening where we clarify some aspects that are often overlooked, we embark on the challenging task of improving on it. We present a framework for the systematic definition of new widening operators that are never less precise than a given widening. The framework is then instantiated on the domain of convex polyhedra so as to obtain a new widening operator that improves on the standard widening by combining several heuristics. A preliminary experimental evaluation has yielded promising results. We also suggest an improvement to the well-known widening delay technique that allows one to gain precision while preserving its overall simplicity. © 2005 Elsevier B.V. All rights reserved.},
   author = {Roberto Bagnara and Patricia M. Hill and Elisa Ricci and Enea Zaffanella},
   doi = {10.1016/j.scico.2005.02.003},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Precise widening operators for convex polyhedra},
   year = {2003},
}
]
Keywords of Y: 
Keywords of Elisa Ricci: 
Similarity = 0.0


Paper List of Y: []
Paper List of Christoph Matheja : [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Christoph Matheja after removed: [@article{Arndt2018,
   author = {Hannah Arndt and Christina Jansen and Joost-Pieter Katoen and Christoph Matheja and Thomas Noll},
   doi = {10.1007/978-3-319-96142-2_1},
   title = {Let this Graph Be Your Witness!},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Christoph Matheja: 
Similarity = 0.0


Paper List of Y: []
Paper List of Xiaoxing Ma : [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Xiaoxing Ma after removed: [@article{Zhang2016,
   abstract = {Software building is recurring and time-consuming. Based on the finding that a significant portion of compilations in incremental build is unnecessary, we propose bypath compilation, an efficient build technique that avoids unnecessary recompila- tion with automated detection of redundant dependencies and unessential changes in source files. The technique is lightweight and transparent to software developers, and can be easily applied to existing build systems. We evaluated our approach on a set of real-world open source projects. The results show that 83% ~ 97% of the recompilations are unnecessary and our approach can accelerate the incremental build up to 44.20%.},
   author = {Ying Zhang and Yanyan Jiang and Chang Xu and Xiaoxing Ma and Ping Yu},
   doi = {10.1109/APSEC.2015.27},
   journal = {Proceedings - Asia-Pacific Software Engineering Conference, APSEC},
   keywords = {Build system,Bypath compilation,Incremental build},
   title = {ABC: Accelerated building of C/C++ projects},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Xiaoxing Ma: Build systemBypath compilationIncremental build
Similarity = 0.0


Paper List of Y: []
Paper List of Joost Pieter Katoen : [@article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Paper List of Y after removed: []
Paper List of Joost Pieter Katoen after removed: [@article{Heinen2015,
   abstract = {This paper argues that graph grammars naturally model dynamic data structures such as lists, trees and combinations thereof. These grammars can be exploited to obtain finite abstractions of pointer-manipulating programs, thus enabling model checking. Experimental results for verifying Lindstrom's variant of the Deutsch-Schorr-Waite tree traversal algorithm illustrate this.},
   author = {Jonathan Heinen and Christina Jansen and Joost Pieter Katoen and Thomas Noll},
   doi = {10.1016/j.scico.2013.11.012},
   journal = {Science of Computer Programming},
   keywords = {Dynamic data structures,Hyperedge replacement grammars,Java bytecode,Verification},
   title = {Verifying pointer programs using graph grammars},
   year = {2015},
   url = {http://dx.doi.org/10.1016/j.scico.2013.11.012},
}
]
Keywords of Y: 
Keywords of Joost Pieter Katoen: Dynamic data structuresHyperedge replacement grammarsJava bytecodeVerification
Similarity = 0.0


Paper List of Y: []
Paper List of Uday P. Khedker : [@article{Kanvar2017,
   abstract = {A points-To analysis computes a sound abstraction of heap memory conventionally using a name-based abstraction that summarizes runtime memory by grouping locations using the names of allocation sites: All concrete heap locations allocated by the same statement are grouped together. The locations in the same group are treated alike i.e., a pointer to any one location of the group is assumed to point to every location in the group leading to an over-Approximation of points-To relations. We propose an access-based abstraction that partitions each name-based group of locations into equivalence classes at every program point using an additional criterion of the sets of access paths (chains of pointer indirections) reaching the locations in the memory. The intuition is that the locations that are both allocated and accessed alike should be grouped into the same equivalence class. Since the access paths in the memory could reach different locations at different program points, our groupings change flow sensitively unlike the name-based groupings. This creates a more precise view of the memory. Theoretically, it is strictly more precise than the name-based abstraction except in some trivial cases; practically it is far more precise. Our empirical measurements show the benefits of our tool Access-Based Heap Analyzer (ABHA) on SPEC CPU 2006 and heap manipulating SV-COMP benchmarks. ABHA, which is field-, flow-, and context-sensitive, scales to 20 kLoC and can improve the precision even up to 99% (in terms of the number of aliases). Additionally, ABHA allows any user-defined summarization of an access path to be plugged in; we have implemented and evaluated four summarization techniques. ABHA can also act as a front-end to TVLA, a parametrized shape analyzer, in order to automate its parametrization by generating predicates that capture the program behaviour more accurately.},
   author = {Vini Kanvar and Uday P. Khedker},
   doi = {10.1145/3092255.3092267},
   journal = {International Symposium on Memory Management, ISMM},
   keywords = {Access path,Alias,Allocation site,Heap abstraction,Static points-To analysis,Summarization},
   title = {What's in a name? Going beyond allocation site names in heap analysis},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of Uday P. Khedker after removed: [@article{Kanvar2017,
   abstract = {A points-To analysis computes a sound abstraction of heap memory conventionally using a name-based abstraction that summarizes runtime memory by grouping locations using the names of allocation sites: All concrete heap locations allocated by the same statement are grouped together. The locations in the same group are treated alike i.e., a pointer to any one location of the group is assumed to point to every location in the group leading to an over-Approximation of points-To relations. We propose an access-based abstraction that partitions each name-based group of locations into equivalence classes at every program point using an additional criterion of the sets of access paths (chains of pointer indirections) reaching the locations in the memory. The intuition is that the locations that are both allocated and accessed alike should be grouped into the same equivalence class. Since the access paths in the memory could reach different locations at different program points, our groupings change flow sensitively unlike the name-based groupings. This creates a more precise view of the memory. Theoretically, it is strictly more precise than the name-based abstraction except in some trivial cases; practically it is far more precise. Our empirical measurements show the benefits of our tool Access-Based Heap Analyzer (ABHA) on SPEC CPU 2006 and heap manipulating SV-COMP benchmarks. ABHA, which is field-, flow-, and context-sensitive, scales to 20 kLoC and can improve the precision even up to 99% (in terms of the number of aliases). Additionally, ABHA allows any user-defined summarization of an access path to be plugged in; we have implemented and evaluated four summarization techniques. ABHA can also act as a front-end to TVLA, a parametrized shape analyzer, in order to automate its parametrization by generating predicates that capture the program behaviour more accurately.},
   author = {Vini Kanvar and Uday P. Khedker},
   doi = {10.1145/3092255.3092267},
   journal = {International Symposium on Memory Management, ISMM},
   keywords = {Access path,Alias,Allocation site,Heap abstraction,Static points-To analysis,Summarization},
   title = {What's in a name? Going beyond allocation site names in heap analysis},
   year = {2017},
}
]
Keywords of Y: 
Keywords of Uday P. Khedker: Access pathAliasAllocation siteHeap abstractionStatic points-To analysisSummarization
Similarity = 0.0


Paper List of Y: []
Paper List of Mayur Naik : [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Paper List of Y after removed: []
Paper List of Mayur Naik after removed: [@article{Lee2018,
   abstract = {A key challenge in program synthesis concerns how to efficiently search for the desired program in the space of possible programs. We propose a general approach to accelerate search-based program synthesis by biasing the search towards likely programs. Our approach targets a standard formulation, syntax-guided synthesis (SyGuS), by extending the grammar of possible programs with a probabilistic model dictating the likelihood of each program. We develop a weighted search algorithm to efficiently enumerate programs in order of their likelihood. We also propose a method based on transfer learning that enables to effectively learn a powerful model, called probabilistic higher-order grammar, from known solutions in a domain. We have implemented our approach in a tool called Euphony and evaluate it on SyGuS benchmark problems from a variety of domains. We show that Euphony can learn good models using easily obtainable solutions, and achieves significant performance gains over existing general-purpose as well as domain-specific synthesizers.},
   author = {Woosuk Lee and Kihong Heo and Rajeev Alur and Mayur Naik},
   doi = {10.1145/3192366.3192410},
   journal = {ACM SIGPLAN Notices},
   keywords = {Domain-specific languages,Statistical methods,Synthesis,Transfer learning},
   title = {Accelerating search-based program synthesis using learned probabilistic models},
   year = {2018},
}
]
Keywords of Y: 
Keywords of Mayur Naik: Domain-specific languagesStatistical methodsSynthesisTransfer learning
Similarity = 0.0


Paper List of Y: []
Paper List of Alexey Gotsman : [@article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Paper List of Y after removed: []
Paper List of Alexey Gotsman after removed: [@article{Gotsman2007,
   author = {Alexey Gotsman and Josh Berdine and Byron Cook},
   keywords = {abstract interpretation,concurrent programming,shape analysis,static analysis},
   title = {Thread-Modular Shape Analysis},
   year = {2007},
}
]
Keywords of Y: 
Keywords of Alexey Gotsman: abstract interpretationconcurrent programmingshape analysisstatic analysis
Similarity = 0.0


Paper List of Y: []
Paper List of Long H. Pham : [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Paper List of Y after removed: []
Paper List of Long H. Pham after removed: [@article{Pham2019,
   abstract = {Analyzing and verifying heap-manipulating programs automatically is challenging. A key for fighting the complexity is to develop compositional methods. For instance, many existing verifiers for heap-manipulating programs require user-provided specification for each function in the program in order to decompose the verification problem. The requirement, however, often hinders the users from applying such tools. To overcome the issue, we propose to automatically learn heap-related program invariants in a property-guided way for each function call. The invariants are learned based on the memory graphs observed during test execution and improved through memory graph mutation. We implemented a prototype of our approach and integrated it with two existing program verifiers. The experimental results show that our approach enhances existing verifiers effectively in automatically verifying complex heap-manipulating programs with multiple function calls.},
   author = {Long H. Pham and Jun Sun and Quang Loc Le},
   title = {Compositional Verification of Heap-Manipulating Programs through Property-Guided Learning},
   year = {2019},
   url = {http://arxiv.org/abs/1908.10051},
}
]
Keywords of Y: 
Keywords of Long H. Pham: 
Similarity = 0.0


Paper List of Y: []
Paper List of Bengt Jonsson : [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Paper List of Y after removed: []
Paper List of Bengt Jonsson after removed: [@article{Abdulla2016,
   author = {Parosh Aziz Abdulla and Lukáš Holík and Bengt Jonsson and Ondřej Lengál and Cong Quy Trinh and Tomáš Vojnar},
   doi = {10.1007/s00236-015-0235-0},
   journal = {Acta Informatica},
   title = {Verification of heap manipulating programs with ordered data by extended forest automata},
   year = {2016},
}
]
Keywords of Y: 
Keywords of Bengt Jonsson: 
Similarity = 0.0


Paper List of Y: []
Paper List of Ramesh Krishnamurti : [@article{Krishnamurti2011,
   abstract = {Using the artifice of the i-device as an analogue, this paper examines issues in making design software more accessible through projects on computer-aided sus-tainable design, panelization for design and fabrication, and parametric shape grammar interpretation. In each case accessibility is improved by transitioning design from a representational concern to one that is more process oriented through the use of localized semantics.},
   author = {Ramesh Krishnamurti},
   journal = {SDC’10: NSF International Workshop on Studying Visual and Spatial Reasoning for Design Creativity},
   title = {Bridging parametric shape and parametric design”},
   year = {2011},
}
]
Paper List of Y after removed: []
Paper List of Ramesh Krishnamurti after removed: [@article{Krishnamurti2011,
   abstract = {Using the artifice of the i-device as an analogue, this paper examines issues in making design software more accessible through projects on computer-aided sus-tainable design, panelization for design and fabrication, and parametric shape grammar interpretation. In each case accessibility is improved by transitioning design from a representational concern to one that is more process oriented through the use of localized semantics.},
   author = {Ramesh Krishnamurti},
   journal = {SDC’10: NSF International Workshop on Studying Visual and Spatial Reasoning for Design Creativity},
   title = {Bridging parametric shape and parametric design”},
   year = {2011},
}
]
Keywords of Y: 
Keywords of Ramesh Krishnamurti: 
Similarity = 0.0


Paper List of Y: []
Paper List of Narges Shadab : [@article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Paper List of Y after removed: []
Paper List of Narges Shadab after removed: [@article{Kellogg2022,
   abstract = {A typestate specification indicates which behaviors of an object are permitted in each of the object's states. In the general case, soundly checking a typestate specification requires precise information about aliasing (i.e., an alias or pointer analysis), which is computationally expensive. This requirement has hindered the adoption of sound typestate analyses in practice. This paper identifies accumulation typestate specifications, which are the subset of typestate specifications that can be soundly checked without any information about aliasing. An accumulation typestate specification can be checked instead by an accumulation analysis: a simple, fast dataflow analysis that conservatively approximates the operations that have been performed on an object. This paper formalizes the notions of accumulation analysis and accumulation typestate specification. It proves that accumulation typestate specifications are exactly those typestate specifications that can be checked soundly without aliasing information. Further, 41% of the typestate specifications that appear in the research literature are accumulation typestate specifications.},
   author = {Martin Kellogg and Narges Shadab and Manu Sridharan and Michael D. Ernst},
   doi = {10.4230/LIPIcs.ECOOP.2022.10},
   journal = {Leibniz International Proceedings in Informatics, LIPIcs},
   keywords = {Typestate,finite-state property},
   title = {Accumulation Analysis},
   year = {2022},
}
]
Keywords of Y: 
Keywords of Narges Shadab: Typestatefinite-state property
Similarity = 0.0


Paper List of Y: []
Paper List of E N Informatique : [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Paper List of Y after removed: []
Paper List of E N Informatique after removed: [@article{Doctoral2017,
   author = {Programme Doctoral and E N Informatique and E T Communications},
   title = {Algorithmic Resource Verification},
   year = {2017},
}
]
Keywords of Y: 
Keywords of E N Informatique: 
Similarity = 0.0


Paper List of Y: []
Paper List of Mattia Monga : [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Paper List of Y after removed: []
Paper List of Mattia Monga after removed: [@article{Casero2004,
   abstract = {Most modern object oriented programming languages do not offer constructs to specify dependencies among members of a class. Public interfaces are written using member types and method signatures only, which are not capable of expressing such kind of relationships. We show that stating which dependencies exist between class members, i.e. which methods could be affected by a change in the implementation of the others, constitutes a relevant information to be shipped to inheritors in order to help them in subclassing without inconsistencies. In this paper we present a tool that supports developers in this task by exploiting C# attributes, that are annotations accessible at runtime. The tool will be integrated in the popular developer environment Visual Studio .NET.},
   author = {Riccardo Casero and Mirko Cesarini and Mattia Monga},
   doi = {10.5381/jot.2004.3.2.a5},
   journal = {Journal of Object Technology},
   title = {Managing code dependencies in C#},
   year = {2004},
}
]
Keywords of Y: 
Keywords of Mattia Monga: 
Similarity = 0.0


Paper List of Y: []
Paper List of Sriram Sankaranarayanan : [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
, @article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
, @article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
]
Paper List of Y after removed: []
Paper List of Sriram Sankaranarayanan after removed: [@article{Balakrishnan2009,
   abstract = {We present a simple yet useful technique for refining the control structure of loops that occur in imperative programs. Loops containing complex control flow are common in synchronous embedded controllers derived from modeling languages such as Lustre, Esterel, and Simulink/Stateflow. Our approach uses a set of labels to distinguish different control paths inside a given loop. The iterations of the loop are abstracted as a finite state automaton over these labels. Subsequently, we use static analysis techniques to identify infeasible iteration sequences and subtract such forbidden sequences from the initial language to obtain a refinement. In practice, the refinement of control flow sequences often simplifies the control flow patterns in the loop. We have applied the refinement technique to improve the precision of abstract interpretation in the presence of widening. Our experiments on a set of complex reactive loop benchmarks clearly show the utility of our refinement techniques. Abstraction interpretation with our refinement technique was able to verify all the properties for 10 out of the 13 benchmarks, while abstraction interpretation without refinement was able to verify only four. Other potentially useful applications include termination analysis and reverse engineering models from source code.},
   author = {Gogul Balakrishnan and Sriram Sankaranarayanan and Franjo Ivančić and Aarti Gupta},
   doi = {10.1145/1629335.1629343},
   journal = {Embedded Systems Week 2009 - Proceedings of the 7th ACM International Conference on Embedded Software, EMSOFT '09},
   keywords = {Abstract interpretation,Loop refinement,Model checking,Path-sensitive analysis,Program understanding,Program verification,Static analysis,Synchronous sytems},
   title = {Refining the control structure of loops using static analysis},
   year = {2009},
}
, @article{Sankaranarayanan2004,
   abstract = {We present a new technique for the generation of non-linear (algebraic) invariants of a program. Our technique uses the theory of ideals over polynomial rings to reduce the non-linear invariant generation problem to a numerical constraint solving problem. So far, the literature on invariant generation has been focussed on the construction of linear invariants for linear programs. Consequently, there has been little progress toward non-linear invariant generation. In this paper, we demonstrate a technique that encodes the conditions for a given template assertion being an invariant into a set of constraints, such that all the solutions to these constraints correspond to non-linear (algebraic) loop invariants of the program. We discuss some trade-offs between the completeness of the technique and the tractability of the constraint-solving problem generated. The application of the technique is demonstrated on a few examples.},
   author = {Sriram Sankaranarayanan and Henny B. Sipma and Zohar Manna},
   journal = {Conference Record of the Annual ACM Symposium on Principles of Programming Languages},
   keywords = {Constraint Programming,Gröbner Bases,Ideals,Invariant Generation,Program Analysis,Symbolic Computation,Verification},
   title = {Non-linear loop invariant generation using gröbner bases},
   year = {2004},
}
, @article{Jeannet2014,
   abstract = {We present abstract acceleration techniques for computing loop invariants for numerical programs with linear assignments and conditionals. Whereas abstract interpretation techniques typically over-approximate the set of reachable states iteratively, abstract acceleration captures the effect of the loop with a single, non-iterative transfer function applied to the initial states at the loop head. In contrast to previous acceleration techniques, our approach applies to any linear loop without restrictions. Its novelty lies in the use of the Jordan normal form decomposition of the loop body to derive symbolic expressions for the entries of the matrix modeling the effect of n>=0 iterations of the loop. The entries of such a matrix depend on $n$ through complex polynomial, exponential and trigonometric functions. Therefore, we introduces an abstract domain for matrices that captures the linear inequality relations between these complex expressions. This results in an abstract matrix for describing the fixpoint semantics of the loop. Our approach integrates smoothly into standard abstract interpreters and can handle programs with nested loops and loops containing conditional branches. We evaluate it over small but complex loops that are commonly found in control software, comparing it with other tools for computing linear loop invariants. The loops in our benchmarks typically exhibit polynomial, exponential and oscillatory behaviors that present challenges to existing approaches. Our approach finds non-trivial invariants to prove useful bounds on the values of variables for such loops, clearly outperforming the existing approaches in terms of precision while exhibiting good performance.},
   author = {Bertrand Jeannet and Peter Schrammel and Sriram Sankaranarayanan},
   journal = {ACM SIGPLAN Notices},
   title = {Abstract acceleration of general linear loops},
   year = {2014},
}
]
Keywords of Y: 
Keywords of Sriram Sankaranarayanan: Abstract interpretationLoop refinementModel checkingPath-sensitive analysisProgram understandingProgram verificationStatic analysisSynchronous sytemsConstraint ProgrammingGröbner BasesIdealsInvariant GenerationProgram AnalysisSymbolic ComputationVerification
Similarity = 0.0


Paper List of Y: []
Paper List of Techopedia : [@article{Techopedia2016,
   author = {Techopedia},
   journal = {Career: Analysis and Design},
   keywords = {@Career},
   title = {What is a Use Case?},
   year = {2016},
   url = {https://www.techopedia.com/definition/25813/use-case},
}
]
Paper List of Y after removed: []
Paper List of Techopedia after removed: [@article{Techopedia2016,
   author = {Techopedia},
   journal = {Career: Analysis and Design},
   keywords = {@Career},
   title = {What is a Use Case?},
   year = {2016},
   url = {https://www.techopedia.com/definition/25813/use-case},
}
]
Keywords of Y: 
Keywords of Techopedia: @Career
Similarity = 0.0


Paper List of Y: []
Paper List of Shraddha Barke : [@article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
]
Paper List of Y after removed: []
Paper List of Shraddha Barke after removed: [@article{Barke2020,
   abstract = {A key challenge in program synthesis is the astronomical size of the search space the synthesizer has to explore. In response to this challenge, recent work proposed to guide synthesis using learned probabilistic models. Obtaining such a model, however, might be infeasible for a problem domain where no high-quality training data is available. In this work we introduce an alternative approach to guided program synthesis: instead of training a model ahead of time we show how to bootstrap one just in time, during synthesis, by learning from partial solutions encountered along the way. To make the best use of the model, we also propose a new program enumeration algorithm we dub guided bottom-up search, which extends the efficient bottom-up search with guidance from probabilistic models. We implement this approach in a tool called Probe, which targets problems in the popular syntax-guided synthesis (SyGuS) format. We evaluate Probe on benchmarks from the literature and show that it achieves significant performance gains both over unguided bottom-up search and over a state-of-the-art probability-guided synthesizer, which had been trained on a corpus of existing solutions. Moreover, we show that these performance gains do not come at the cost of solution quality: programs generated by Probe are only slightly more verbose than the shortest solutions and perform no unnecessary case-splitting.},
   author = {Shraddha Barke and Hila Peleg and Nadia Polikarpova},
   doi = {10.1145/3428295},
   journal = {Proceedings of the ACM on Programming Languages},
   keywords = {Domain-specific languages,Probabilistic models,Program Synthesis},
   title = {Just-in-time learning for bottom-up enumerative synthesis},
   year = {2020},
}
]
Keywords of Y: 
Keywords of Shraddha Barke: Domain-specific languagesProbabilistic modelsProgram Synthesis
Similarity = 0.0


Paper List of Y: []
Paper List of Thomas Jensen : [@article{Blazy2015,
   abstract = {Summary: This book constitutes the refereed proceedings of the 22nd International Static Analysis Symposium, SAS 2015, held in Saint-Malo, France, in September 2015. The 18 papers presented in this volume were carefully reviewed and selected from 44 submissions. All fields of static analysis as a fundamental tool for program verification, bug detection, compiler optimization, program understanding, and software maintenance are addressed, featuring theoretical, practical, and application advances in the area.},
   author = {Sandrine Blazy and Thomas Jensen},
   doi = {10.1007/978-3-662-48288-9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static Analysis: 22nd International Symposium, SAS 2015 Saint-Malo, France, September 9-11, 2015 Proceedings},
   year = {2015},
}
]
Paper List of Y after removed: []
Paper List of Thomas Jensen after removed: [@article{Blazy2015,
   abstract = {Summary: This book constitutes the refereed proceedings of the 22nd International Static Analysis Symposium, SAS 2015, held in Saint-Malo, France, in September 2015. The 18 papers presented in this volume were carefully reviewed and selected from 44 submissions. All fields of static analysis as a fundamental tool for program verification, bug detection, compiler optimization, program understanding, and software maintenance are addressed, featuring theoretical, practical, and application advances in the area.},
   author = {Sandrine Blazy and Thomas Jensen},
   doi = {10.1007/978-3-662-48288-9},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Static Analysis: 22nd International Symposium, SAS 2015 Saint-Malo, France, September 9-11, 2015 Proceedings},
   year = {2015},
}
]
Keywords of Y: 
Keywords of Thomas Jensen: 
Similarity = 0.0


Paper List of Y: []
Paper List of Pascal Sotin : [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
]
Paper List of Y after removed: []
Paper List of Pascal Sotin after removed: [@article{Sotin2011,
   abstract = {Policy Iteration is an algorithm for the exact solving of optimization and game theory problems, formulated as equations on min max affine expressions. It has been shown that the problem of finding the least fixpoint of semantic equations on some abstract domains can be reduced to such optimization problems. This enables the use of Policy Iteration to solve such equations, instead of the traditional Kleene iteration that performs approximations to ensure convergence. We first show in this paper that the concept of Policy Iteration can be integrated into numerical abstract domains in a generic way. This allows to widen considerably its applicability in static analysis. We then consider the verification of programs manipulating Boolean and numerical variables, and we provide an efficient method to integrate the concept of policy in a logico-numerical abstract domain that mixes Boolean and numerical properties. Our experiments show the benefit of our approach compared to a naive application of Policy Iteration to such programs. ? 2011 Springer-Verlag.},
   author = {Pascal Sotin and Bertrand Jeannet and Franck Védrine and Eric Goubault},
   doi = {10.1007/978-3-642-24372-1_21},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   title = {Policy iteration within logico-numerical abstract domains},
   year = {2011},
}
]
Keywords of Y: 
Keywords of Pascal Sotin: 
Similarity = 0.0


Guilherme Ottoni
Diomidis Spinellis
P. Deloo
Adrian Francalanza
Michael B. James
Neil Mitchell
Zheng Guo
Kai Tang
Charles Zhang
Martin Schaf
Zhe Long Wang
P. Pellegrino
Peter O'Hearn
Peisen Yao
Daniele Cono D'elia
Wei Ngan Chin
Agostino Cortesi
Roberto Baldoni
Isil Dillig
Patrice Godefroid
John Field
Franjo Ivančić
Thomas Noll
Bor Yuh Evan Chang
Aarti Gupta
David Justo
Thodoris Sotiropoulos
Liang Zou
Chenglong Wang
Yannis Smaragdakis
Deepak Goyal
Bihuan Chen
Huisong Li
Emmanuel Geay
Rajeev Alur
Axel Simon
Camil Demetrescu
Michael James
Lin Xu
Stefanos Chaliasos
Stephen J. Fink
Cristiano Calcagno
Santanu Kumar Dash
Daniel Luchaup
V. A. Kreknin
Xiaohong Li
Radhia Cousot
Qingkai Shi
Jacob Van Geffen
Irene Finocchi
Yu Feng
Wei Le
Mark Williams
Hongxu Chen
Rahul Sharma
Noam Rinetzky
Qi Gao
Xiaofei Xie
Nadia Polikarpova
Shang Wei Lin
Bertrand Jeannet
Timotej Kapus
Chang Xu
Swarat Chaudhuri
Ruzica Piskac
Alvin Cheung
François Irigoin
Doug Kimelman
Dino Distefano
Xavier Rival
Hongyu Zhao
Radu Rugina
Reinhard Wilhelm
Oren Ish-Shalom
Kihong Heo
Andy King
Vini Kanvar
Herbert Bos
Andrew Paroski
Jonathan Heinen
Dimitris Mitropoulos
Alex Aiken
David Mandelin
Ruben Martins
Miltiadis Allamanis
Mikolas Janota
Sarah Spall
Emilio Coppa
Jie Li
Jason Evans
Yanyan Jiang
Jörg Bauer
Nurit Dor
Byron Cook
Mooly Sagiv
Thanh Vu Nguyen
Shivani Doshi
Henny B. Sipma
Thomas Dillig
Yang Liu
N. Riva
Jiaxiao Zhou
Manu Sridharan
Mark Santolucito
Fabien Coelho
]]></system-out>
  <system-err><![CDATA[]]></system-err>
</testsuite>
